# Nginx configuration for cluster.ringrift.ai
# This config is for the AWS EC2 proxy instance that routes traffic
# to the current P2P cluster leader via Tailscale.
#
# REQUIREMENTS:
# - Tailscale installed and authenticated on the proxy instance
# - Route 53 RINGRIFT_ROUTE53_ZONE_ID set on cluster nodes
# - SSL certificate for cluster.ringrift.ai (use certbot)
#
# DEPLOYMENT:
# 1. Install on AWS EC2 instance with public IP
# 2. Copy this to /etc/nginx/sites-available/cluster.ringrift.ai
# 3. ln -s /etc/nginx/sites-available/cluster.ringrift.ai /etc/nginx/sites-enabled/
# 4. sudo nginx -t && sudo systemctl reload nginx

# Upstream to cluster leader (dynamically resolved via DNS or discovery endpoint)
# The Route 53 DNS (cluster.ringrift.ai) points directly to the leader's Tailscale IP
# so Nginx just needs to forward to that resolved address.

upstream cluster_backend {
    # Leader P2P endpoints - nginx will failover automatically
    # These are the nodes that can run as cluster leader
    server 100.97.104.89:8770 max_fails=2 fail_timeout=10s;    # lambda-2xh100 (primary)
    server 100.78.101.123:8770 backup max_fails=2 fail_timeout=10s; # lambda-h100
    server 100.107.168.125:8770 backup max_fails=2 fail_timeout=10s; # mac-studio

    # Health check settings
    keepalive 32;
}

# Monitoring upstreams with failover support
# The P2P leader runs Prometheus/Grafana. When leader changes, these fail over.
# Use multiple cluster nodes as potential monitoring hosts with health checks.

upstream prometheus_backend {
    # Primary: current leader (typically runs monitoring)
    server 100.97.104.89:9090 max_fails=2 fail_timeout=10s;    # lambda-2xh100
    server 100.105.151.58:9090 backup max_fails=2 fail_timeout=10s; # mac-studio
    server 100.120.69.5:9090 backup max_fails=2 fail_timeout=10s;   # lambda-h100

    # Health check: connections kept alive for performance
    keepalive 4;
}

upstream grafana_backend {
    # Primary: current leader (typically runs monitoring)
    server 100.97.104.89:3000 max_fails=2 fail_timeout=10s;    # lambda-2xh100
    server 100.105.151.58:3000 backup max_fails=2 fail_timeout=10s; # mac-studio
    server 100.120.69.5:3000 backup max_fails=2 fail_timeout=10s;   # lambda-h100

    # Health check: connections kept alive for Grafana sessions
    keepalive 8;
}

upstream fastapi_backend {
    # FastAPI app (app/main.py) serving admin endpoints
    server 100.78.101.123:8000 max_fails=2 fail_timeout=10s;    # lambda-h100

    keepalive 4;
}

# Alternative: Use resolver for dynamic DNS resolution
# (Uncomment if you want Nginx to re-resolve DNS on each request)
# resolver 8.8.8.8 valid=30s;

server {
    listen 80;
    server_name cluster.ringrift.ai;

    # Redirect HTTP to HTTPS
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name cluster.ringrift.ai;

    # SSL certificates (managed by certbot)
    ssl_certificate /etc/letsencrypt/live/cluster.ringrift.ai/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/cluster.ringrift.ai/privkey.pem;

    # SSL settings
    ssl_session_timeout 1d;
    ssl_session_cache shared:SSL:50m;
    ssl_session_tickets off;

    # Modern SSL configuration
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;

    # HSTS
    add_header Strict-Transport-Security "max-age=63072000" always;

    # Logging
    access_log /var/log/nginx/cluster.ringrift.ai.access.log;
    error_log /var/log/nginx/cluster.ringrift.ai.error.log;

    # Main dashboard location
    location / {
        proxy_pass http://cluster_backend;
        proxy_http_version 1.1;

        # Required headers
        proxy_set_header Host $host;
        proxy_set_header Authorization $http_authorization;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # WebSocket support (for future dashboard features)
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";

        # Timeouts
        proxy_connect_timeout 30s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;

        # Buffering settings for dashboard responsiveness
        proxy_buffering off;
        proxy_buffer_size 4k;

        # Allow nginx to use backup when primary fails
        proxy_next_upstream error timeout http_502 http_503 http_504;
        proxy_next_upstream_tries 3;
    }

    # API endpoints
    location /api/ {
        proxy_pass http://cluster_backend;
        proxy_http_version 1.1;

        proxy_set_header Host $host;
        proxy_set_header Authorization $http_authorization;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Longer timeout for API calls (some may be heavy)
        proxy_connect_timeout 60s;
        proxy_send_timeout 120s;
        proxy_read_timeout 120s;

        proxy_next_upstream error timeout http_502 http_503 http_504;
        proxy_next_upstream_tries 3;
    }

    # Leader discovery endpoint (Failover Option 3)
    # This endpoint always returns info about the current leader
    # Can be used by external services to find the leader
    location = /api/leader {
        proxy_pass http://cluster_backend;
        proxy_http_version 1.1;

        proxy_set_header Host $host;
        proxy_set_header Authorization $http_authorization;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Quick response expected
        proxy_connect_timeout 10s;
        proxy_send_timeout 10s;
        proxy_read_timeout 10s;

        proxy_next_upstream error timeout http_502 http_503 http_504;
        proxy_next_upstream_tries 3;
    }

    # Health check endpoint
    location = /health {
        proxy_pass http://cluster_backend;
        proxy_http_version 1.1;

        proxy_set_header Host $host;
        proxy_set_header Authorization $http_authorization;
        proxy_set_header X-Real-IP $remote_addr;

        # Quick health checks
        proxy_connect_timeout 5s;
        proxy_send_timeout 5s;
        proxy_read_timeout 5s;

        proxy_next_upstream error timeout http_502 http_503 http_504;
        proxy_next_upstream_tries 3;
    }

    # Status page (simple text response for uptime monitoring)
    location = /nginx_status {
        stub_status on;
        access_log off;
        allow 127.0.0.1;
        allow 10.0.0.0/8;      # AWS internal
        allow 100.64.0.0/10;   # Tailscale CGNAT range
        deny all;
    }

    # =========================================================================
    # Monitoring endpoints with resilient failover
    # =========================================================================

    # Prometheus - with failover to backup nodes
    location /prometheus/ {
        proxy_pass http://prometheus_backend/;
        proxy_http_version 1.1;

        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Connection settings
        proxy_connect_timeout 5s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;

        # Allow nginx to use backup when primary fails
        proxy_next_upstream error timeout http_502 http_503 http_504;
        proxy_next_upstream_tries 3;
    }

    # Prometheus API passthrough
    location /prometheus/api/ {
        proxy_pass http://prometheus_backend/api/;
        proxy_http_version 1.1;

        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        proxy_connect_timeout 5s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;

        proxy_next_upstream error timeout http_502 http_503 http_504;
        proxy_next_upstream_tries 3;
    }

    # Grafana - with failover to backup nodes
    location /grafana/ {
        proxy_pass http://grafana_backend/;
        proxy_http_version 1.1;

        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # WebSocket support for Grafana live features
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";

        proxy_connect_timeout 5s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;

        # Allow nginx to use backup when primary fails
        proxy_next_upstream error timeout http_502 http_503 http_504;
        proxy_next_upstream_tries 3;
    }

    # Grafana API passthrough
    location /grafana/api/ {
        proxy_pass http://grafana_backend/api/;
        proxy_http_version 1.1;

        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        proxy_connect_timeout 5s;
        proxy_send_timeout 120s;
        proxy_read_timeout 120s;

        proxy_next_upstream error timeout http_502 http_503 http_504;
        proxy_next_upstream_tries 3;
    }

    # Direct Grafana access (alternative path)
    location = /grafana {
        return 301 /grafana/;
    }

    # =========================================================================
    # Custom Dashboards (served by P2P orchestrator on port 8770)
    # =========================================================================

    # Work Queue Dashboard
    location = /work_queue {
        proxy_pass http://cluster_backend;
        proxy_http_version 1.1;

        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Cache-busting headers
        add_header Cache-Control "no-store, no-cache, must-revalidate";
        proxy_cache_bypass 1;

        proxy_next_upstream error timeout http_502 http_503 http_504;
        proxy_next_upstream_tries 3;
    }

    # Work queue API endpoints
    location /work/ {
        proxy_pass http://cluster_backend;
        proxy_http_version 1.1;

        proxy_set_header Host $host;
        proxy_set_header Authorization $http_authorization;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        proxy_connect_timeout 30s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;

        proxy_next_upstream error timeout http_502 http_503 http_504;
        proxy_next_upstream_tries 3;
    }

    # Main cluster dashboard
    location = /dashboard {
        proxy_pass http://cluster_backend;
        proxy_http_version 1.1;

        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        add_header Cache-Control "no-store, no-cache, must-revalidate";
        proxy_cache_bypass 1;

        proxy_next_upstream error timeout http_502 http_503 http_504;
        proxy_next_upstream_tries 3;
    }

    # Model dashboard
    location = /model_dashboard {
        proxy_pass http://cluster_backend;
        proxy_http_version 1.1;

        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        add_header Cache-Control "no-store, no-cache, must-revalidate";
        proxy_cache_bypass 1;

        proxy_next_upstream error timeout http_502 http_503 http_504;
        proxy_next_upstream_tries 3;
    }

    # =========================================================================
    # FastAPI Admin Endpoints (served by app/main.py on port 8000)
    # =========================================================================

    # Elo Velocity Dashboard
    location /admin/ {
        proxy_pass http://fastapi_backend;
        proxy_http_version 1.1;

        proxy_set_header Host $host;
        proxy_set_header Authorization $http_authorization;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        add_header Cache-Control "no-store, no-cache, must-revalidate";
        proxy_cache_bypass 1;

        proxy_connect_timeout 30s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;

        proxy_next_upstream error timeout http_502 http_503 http_504;
        proxy_next_upstream_tries 3;
    }
}
