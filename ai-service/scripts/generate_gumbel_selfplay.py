#!/usr/bin/env python3
"""Generate selfplay games with Gumbel MCTS for KL divergence training.

This script generates games using Gumbel MCTS which produces visit distribution
soft targets suitable for KL divergence loss training.

Uses unified SelfplayConfig for configuration (December 2025).

Usage:
    python scripts/generate_gumbel_selfplay.py \
        --num-games 500 \
        --board square8 \
        --output data/gumbel_selfplay/sq8_gumbel.jsonl
"""

import json
import logging
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Optional

# Add project root to path
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

from app.ai.gumbel_mcts_ai import GumbelMCTSAI
from app.models import AIConfig, BoardType
from app.rules.default_engine import DefaultRulesEngine
from app.training.env import RingRiftEnv
from app.training.selfplay_config import EngineMode, SelfplayConfig, create_argument_parser

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
logger = logging.getLogger(__name__)


def parse_board_type(board_str: str) -> BoardType:
    """Parse board type string to enum."""
    board_str = board_str.lower()
    if "square8" in board_str or "sq8" in board_str:
        return BoardType.SQUARE8
    elif "square19" in board_str or "sq19" in board_str:
        return BoardType.SQUARE19
    elif "hex8" in board_str:
        return BoardType.HEX8
    elif "hex" in board_str or "hexagonal" in board_str:
        return BoardType.HEXAGONAL
    return BoardType.SQUARE8


def find_move_index(move, legal_moves: list) -> int:
    """Find the index of a move in the legal moves list.

    This ensures the mcts_policy indices match what the policy network expects
    during training, which uses engine.get_valid_moves() ordering.
    """
    move_type = getattr(move, 'type', None)
    move_from = getattr(move, 'from_pos', None)
    move_to = getattr(move, 'to', None)

    for i, legal in enumerate(legal_moves):
        legal_type = getattr(legal, 'type', None)
        legal_from = getattr(legal, 'from_pos', None)
        legal_to = getattr(legal, 'to', None)

        if move_type != legal_type:
            continue
        if move_from is not None and legal_from is not None:
            if move_from.x != legal_from.x or move_from.y != legal_from.y:
                continue
        elif move_from is not None or legal_from is not None:
            continue
        if move_to is not None and legal_to is not None:
            if move_to.x != legal_to.x or move_to.y != legal_to.y:
                continue
        elif move_to is not None or legal_to is not None:
            continue
        return i
    return -1


def serialize_state(state) -> dict[str, Any]:
    """Serialize GameState to JSON-compatible dict."""
    data = state.model_dump() if hasattr(state, 'model_dump') else state.dict()
    # Convert datetime objects to ISO strings
    for key, value in data.items():
        if hasattr(value, 'isoformat'):
            data[key] = value.isoformat()
    return data


def serialize_move(move, mcts_policy: dict[str, float] | None = None) -> dict[str, Any]:
    """Serialize a Move object to a JSON-compatible dict.

    Positions include z coordinate for hex boards (cube coordinates).
    """
    move_data = {
        "type": move.type.value,
        "player": move.player,
    }
    # Only include mcts_policy for non-bookkeeping moves
    if mcts_policy:
        move_data["mcts_policy"] = mcts_policy
    if move.from_pos:
        pos_dict = {"x": move.from_pos.x, "y": move.from_pos.y}
        if move.from_pos.z is not None:
            pos_dict["z"] = move.from_pos.z
        move_data["from"] = pos_dict
    if move.to:
        pos_dict = {"x": move.to.x, "y": move.to.y}
        if move.to.z is not None:
            pos_dict["z"] = move.to.z
        move_data["to"] = pos_dict
    if move.capture_target:
        pos_dict = {"x": move.capture_target.x, "y": move.capture_target.y}
        if move.capture_target.z is not None:
            pos_dict["z"] = move.capture_target.z
        move_data["capture_target"] = pos_dict
    return move_data


def generate_game(
    env: RingRiftEnv,
    ai_players: dict[int, GumbelMCTSAI],
    game_idx: int,
    max_moves: int = 500,
) -> dict[str, Any] | None:
    """Generate a single game with Gumbel MCTS visit distributions.

    Per RR-CANON-R075, this records ALL moves including bookkeeping moves
    (no_placement_action, no_line_action, no_territory_action, etc.) that are
    auto-generated by the env to satisfy canonical replay requirements.

    The mcts_policy indices are aligned with engine.get_valid_moves() ordering
    so they match what the policy network training code expects for KL loss.
    """
    state = env.reset()
    # Save initial state for extraction
    initial_state = serialize_state(state)
    moves_data = []
    done = False
    move_count = 0

    # Create rules engine for getting legal moves in training-compatible order
    engine = DefaultRulesEngine()

    while not done and move_count < max_moves:
        current_player = state.current_player
        ai = ai_players.get(current_player)
        if ai is None:
            break

        # Get legal moves in the same order as training uses
        legal_moves = engine.get_valid_moves(state, current_player)

        # Get move from Gumbel MCTS
        move = ai.select_move(state)

        # Get visit distribution (soft targets) with corrected indices
        mcts_policy = {}
        if hasattr(ai, 'get_visit_distribution') and legal_moves:
            gumbel_moves, probs = ai.get_visit_distribution()
            # Map each Gumbel move to its index in the training-compatible legal_moves list
            for mv, prob in zip(gumbel_moves, probs, strict=False):
                if prob > 1e-6:
                    # Find this move's index in the legal_moves list
                    idx = find_move_index(mv, legal_moves)
                    if idx >= 0:
                        mcts_policy[str(idx)] = float(prob)

        # Record move with MCTS policy
        moves_data.append(serialize_move(move, mcts_policy if mcts_policy else None))

        # Apply move - env.step() returns (state, reward, done, info)
        # The info dict contains auto_generated_moves for bookkeeping moves
        state, _, done, step_info = env.step(move)
        move_count += 1

        # Record any auto-generated bookkeeping moves per RR-CANON-R075/R076.
        # These include no_line_action, no_territory_action, no_placement_action, etc.
        # Canonical recordings must include all phase transitions for replay parity.
        auto_moves = step_info.get("auto_generated_moves", [])
        for auto_move in auto_moves:
            moves_data.append(serialize_move(auto_move))
            move_count += 1

    # Build game record
    # Use canonical sizes from BOARD_CONFIGS: sq8=8, sq19=19, hex8=9, hexagonal=13
    if env.board_type == BoardType.SQUARE8:
        board_size = 8
    elif env.board_type == BoardType.SQUARE19:
        board_size = 19
    elif env.board_type == BoardType.HEX8:
        board_size = 9
    else:
        board_size = 13  # hexagonal
    return {
        "game_id": f"gumbel_{env.board_type.value}_{env.num_players}p_{game_idx}_{int(time.time())}",
        "board_type": env.board_type.value,
        "board_size": board_size,
        "num_players": env.num_players,
        "winner": state.winner,
        "move_count": move_count,
        "game_status": state.game_status.value if hasattr(state.game_status, 'value') else str(state.game_status),
        "victory_type": getattr(state, 'victory_type', None),
        "engine_mode": "gumbel_mcts",
        "moves": moves_data,
        "initial_state": initial_state,
        "timestamp": datetime.now().isoformat(),
        "source": "generate_gumbel_selfplay.py",
    }


def main():
    # Use unified argument parser from SelfplayConfig
    parser = create_argument_parser(
        description="Generate Gumbel MCTS selfplay games",
        include_gpu=False,  # Gumbel MCTS runs on CPU
        include_ramdrive=False,
    )
    # Add script-specific arguments
    parser.add_argument("--output", type=str, required=True, help="Output JSONL file")
    parser.add_argument("--gumbel-sims", type=int, default=64, help="Gumbel MCTS simulations")
    parser.add_argument("--max-moves", type=int, default=500, help="Max moves per game")
    parser.add_argument("--model-id", type=str, default=None, help="Neural network model ID (e.g., ringrift_best_sq8_2p)")
    parsed = parser.parse_args()

    # Create config from parsed args
    config = SelfplayConfig(
        board_type=parsed.board,
        num_players=parsed.num_players,
        num_games=parsed.num_games,
        mcts_simulations=parsed.gumbel_sims,
        engine_mode=EngineMode.GUMBEL_MCTS,
        source='generate_gumbel_selfplay.py',
    )

    # Build args for backwards compatibility
    args = type('Args', (), {
        'num_games': config.num_games,
        'board_type': config.board_type,
        'num_players': config.num_players,
        'output': parsed.output,
        'gumbel_sims': parsed.gumbel_sims,
        'max_moves': parsed.max_moves,
        'model_id': parsed.model_id,
    })()

    # Setup
    board_type = parse_board_type(args.board_type)
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    logger.info(f"Generating {args.num_games} Gumbel MCTS games")
    logger.info(f"Board: {board_type.value}, Players: {args.num_players}")
    logger.info(f"Output: {output_path}")

    # Create environment
    env = RingRiftEnv(board_type=board_type, num_players=args.num_players)

    # Create AI players
    ai_players = {}
    for pn in range(1, args.num_players + 1):
        ai_config = AIConfig(
            difficulty=5,
            self_play=True,
            nn_model_id=args.model_id,
        )
        ai_players[pn] = GumbelMCTSAI(
            player_number=pn,
            config=ai_config,
            board_type=board_type,
        )
    if args.model_id:
        logger.info(f"Using neural network model: {args.model_id}")

    # Generate games
    start_time = time.time()
    games_generated = 0
    moves_with_policy = 0

    with open(output_path, 'w') as f:
        for game_idx in range(args.num_games):
            try:
                game = generate_game(env, ai_players, game_idx, args.max_moves)
                if game:
                    # Count moves with MCTS policy
                    policy_count = sum(1 for m in game["moves"] if m.get("mcts_policy"))
                    moves_with_policy += policy_count

                    f.write(json.dumps(game) + "\n")
                    games_generated += 1

                    if (game_idx + 1) % 10 == 0:
                        elapsed = time.time() - start_time
                        rate = games_generated / elapsed
                        eta = (args.num_games - games_generated) / rate if rate > 0 else 0
                        logger.info(f"Game {game_idx + 1}/{args.num_games} ({rate:.2f} games/s, ETA: {eta:.0f}s)")
            except Exception as e:
                logger.warning(f"Failed game {game_idx}: {e}")

    elapsed = time.time() - start_time
    logger.info("=" * 60)
    logger.info("GENERATION COMPLETE")
    logger.info("=" * 60)
    logger.info(f"Games generated: {games_generated}")
    logger.info(f"Moves with MCTS policy: {moves_with_policy}")
    logger.info(f"Time: {elapsed:.1f}s ({games_generated/elapsed:.2f} games/s)")
    logger.info(f"Output: {output_path}")


if __name__ == "__main__":
    main()
