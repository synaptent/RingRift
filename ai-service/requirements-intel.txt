# AI service Python dependencies for Intel (x86_64) Macs
# Use this file instead of requirements.txt on Intel Macs.
#
# Key differences from requirements.txt (Apple Silicon):
# - numpy 1.26.x instead of 2.x (numpy 2.x has x86_64 issues)
# - torch 2.2.x instead of 2.6.x (latest torch optimized for ARM)
# - scipy 1.12.x instead of 1.15.x (compatible with numpy 1.26)
# - sdnotify excluded (systemd is Linux-only, not needed on macOS)

# Core FastAPI dependencies
fastapi==0.122.0
uvicorn[standard]==0.38.0
pydantic==2.10.5

# Utilities
python-dotenv==1.2.1
aiohttp==3.13.2
redis==7.1.0
httpx==0.28.1
prometheus_client==0.23.1

# Development tools
pytest==9.0.1
pytest-asyncio==1.3.0
pytest-timeout==2.4.0
pytest-cov==6.0.0
hypothesis==6.116.0
black==25.12.0
flake8==7.3.0
mypy==1.13.0
vulture==2.14

# Core ML/Data Science libraries (Intel-compatible versions)
numpy==1.26.4
scipy==1.15.3
scikit-learn==1.6.1

# Deep Learning (Intel-compatible versions)
torch==2.9.1
torchvision==0.24.1

# TensorBoard
tensorboard==2.18.0
tensorboardX==2.6.4

# CMA-ES for heuristic weight optimization
cma>=3.3.0

# Model serialization
cloudpickle==3.1.0
h5py==3.13.0

# Data processing
pandas==2.2.3
matplotlib==3.10.0

# Memory optimization
msgpack==1.1.0
lz4==4.4.5

# Progress bars
tqdm==4.67.1

# System monitoring
psutil==7.1.3

# Distributed training (cluster worker)
zeroconf>=0.100.0

# Dashboard server
flask==3.1.3
flask-cors==5.0.0

# OpenTelemetry for distributed tracing
opentelemetry-api==1.29.0
opentelemetry-sdk==1.29.0
opentelemetry-exporter-otlp==1.29.0
# Note: Jaeger Thrift exporter deprecated; use OTLP with Jaeger's native endpoint
opentelemetry-exporter-jaeger==1.21.0
opentelemetry-instrumentation-fastapi==0.50b0
