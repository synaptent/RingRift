# Minimal Dockerfile for AI inference serving
# Optimized for low latency and small image size
#
# Build:
#   docker build -f docker/Dockerfile.inference -t ringrift-ai-inference .
#
# Run:
#   docker run -p 8001:8001 -v ./models:/app/models ringrift-ai-inference

FROM python:3.11-slim AS builder

WORKDIR /app

# Install build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .

# Install only inference dependencies
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

RUN pip install --no-cache-dir \
    fastapi==0.122.0 \
    "uvicorn[standard]==0.38.0" \
    pydantic==2.10.5 \
    numpy>=1.26.0 \
    scipy>=1.12.0 \
    torch>=2.0.0 \
    httpx>=0.27.0 \
    prometheus_client>=0.17.0

# ============================================================================
# Production stage
# ============================================================================
FROM python:3.11-slim AS inference

ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PATH="/opt/venv/bin:$PATH" \
    AI_SERVICE_PORT=8001

WORKDIR /app

# Copy virtual environment
COPY --from=builder /opt/venv /opt/venv

# Copy application code
COPY app/__init__.py ./app/
COPY app/main.py ./app/
COPY app/models/ ./app/models/
COPY app/rules/ ./app/rules/
COPY app/ai/ ./app/ai/
COPY app/game_engine.py ./app/
COPY app/board_manager.py ./app/
COPY app/routes/ ./app/routes/
COPY app/metrics.py ./app/

# Create models directory
RUN mkdir -p /app/models

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD python -c "import os, httpx; port = os.getenv('AI_SERVICE_PORT', '8001'); r = httpx.get(f'http://localhost:{port}/health', timeout=2.0); exit(0 if r.status_code == 200 else 1)"

EXPOSE 8001

CMD ["sh", "-c", "uvicorn app.main:app --host 0.0.0.0 --port ${AI_SERVICE_PORT}"]
