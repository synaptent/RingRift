INFO:app.p2p.swim_adapter:swim-p2p loaded successfully (SWIM membership available, TCP+UDP transports)
INFO:app.config.unified_config:Loaded unified config from /Users/armand/Development/RingRift/ai-service/config/unified_loop.yaml
INFO:app.config.unified_config:  Training threshold: 200
INFO:app.config.unified_config:  Elo DB: data/unified_elo.db
Latency tracker module loaded
Bandwidth monitor module loaded
Lifeguard enhancement module loaded
Metrics collector module loaded
2026-01-13 09:05:53,488 - app.coordination.safeguards - INFO - Safeguards initialized
/Users/armand/.pyenv/versions/3.10.13/lib/python3.10/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.
  "cipher": algorithms.TripleDES,
/Users/armand/.pyenv/versions/3.10.13/lib/python3.10/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.
  "class": algorithms.TripleDES,
2026-01-13 09:05:53,747 - p2p_orchestrator - INFO - [P2P] Acquired singleton lock (PID 54190)
2026-01-13 09:05:53,811 - p2p_orchestrator - WARNING - [NODE-ID] Falling back to hostname 'MacBook-Pro-5' - this may not match distributed_hosts.yaml! Set RINGRIFT_NODE_ID environment variable or pass --node-id explicitly to avoid cluster partition issues.
2026-01-13 09:05:53,812 - p2p_orchestrator - INFO - Auto-detected node-id: MacBook-Pro-5
2026-01-13 09:05:53,812 - p2p_orchestrator - INFO - Initializing P2P orchestrator: node_id=MacBook-Pro-5
2026-01-13 09:05:53,812 - p2p_orchestrator - INFO - Bootstrap seeds: 0 CLI + 5 hardcoded = 5 total
2026-01-13 09:05:53,865 - p2p_orchestrator - INFO - Auto-detected storage: RAMDRIVE (RAM: 128GB, Disk: 156GB free / 83% used)
2026-01-13 09:05:53,878 - app.utils.ramdrive - INFO - ============================================================
2026-01-13 09:05:53,878 - app.utils.ramdrive - INFO - STORAGE AUTO-DETECTION REPORT
2026-01-13 09:05:53,879 - app.utils.ramdrive - INFO - ============================================================
2026-01-13 09:05:53,879 - app.utils.ramdrive - INFO - System RAM:     128.0GB total, 89.6GB available
2026-01-13 09:05:53,879 - app.utils.ramdrive - INFO - Disk:           926.4GB total, 155.6GB free (83.2% used)
2026-01-13 09:05:53,879 - app.utils.ramdrive - INFO - Ramdrive:       /tmp - 155.6GB free
2026-01-13 09:05:53,879 - app.utils.ramdrive - INFO - RAM-rich:       Yes
2026-01-13 09:05:53,879 - app.utils.ramdrive - INFO - Disk-limited:   Yes
2026-01-13 09:05:53,879 - app.utils.ramdrive - INFO - Recommendation: USE RAMDRIVE
2026-01-13 09:05:53,879 - app.utils.ramdrive - INFO - ============================================================
2026-01-13 09:05:54,135 - p2p_orchestrator - INFO - [P2P] advertise_host changed: fd7a:115c:a1e0::dc01:a487 -> 100.69.164.58 (ipv6_to_ipv4_switch)
[P2P] Voter quorum enabled: voters=8, quorum=3 (mac-studio, MacBook-Pro-5, lambda-gh200-training, hetzner-cpu1, hetzner-cpu2, hetzner-cpu3, vultr-a100-20gb, nebius-h100-3)
2026-01-13 09:05:54,162 - scripts.p2p.leadership_state_machine - INFO - LeadershipStateMachine initialized: node_id=MacBook-Pro-5, state=follower, epoch=0
2026-01-13 09:05:54,162 - p2p_orchestrator - INFO - MonitoringManager initialized
2026-01-13 09:05:54,272 - app.coordination.database_sync_manager - INFO - [EloSyncManager] Initialized for elo db=/Users/armand/Development/RingRift/ai-service/data/unified_elo.db, coordinator=nebius-backbone-1
2026-01-13 09:05:54,272 - p2p_orchestrator - INFO - EloSyncManager initialized (db: /Users/armand/Development/RingRift/ai-service/data/unified_elo.db)
2026-01-13 09:05:54,272 - p2p_orchestrator - INFO - PFSP opponent pools initialized for 4 configs
2026-01-13 09:05:54,272 - p2p_orchestrator - INFO - CMA-ES auto-tuners initialized for 4 configs
2026-01-13 09:05:54,272 - p2p_orchestrator - INFO - P2P protocols: MEMBERSHIP_MODE=hybrid (SWIM=available), CONSENSUS_MODE=hybrid (Raft=available)
2026-01-13 09:05:54,272 - scripts.p2p.consensus_mixin - WARNING - Raft consensus unavailable: no Raft partners available
2026-01-13 09:05:54,286 - scripts.p2p.transport_cascade - INFO - Registered transport: http_direct (tier TIER_1_FAST)
2026-01-13 09:05:54,286 - scripts.p2p.transport_cascade - INFO - Registered transport: tailscale (tier TIER_2_RELIABLE)
2026-01-13 09:05:54,286 - scripts.p2p.transport_cascade - INFO - Registered transport: ssh_tunnel (tier TIER_3_TUNNELED)
2026-01-13 09:05:54,286 - scripts.p2p.transport_cascade - INFO - Registered transport: cloudflare_tunnel (tier TIER_3_TUNNELED)
2026-01-13 09:05:54,314 - scripts.p2p.p2p_mixin_base - INFO - [peer_manager] Multi-relay failover enabled with 7 relays: nebius-h100-3, hetzner-cpu2, vultr-a100-20gb... (preferred: nebius-backbone-1)
2026-01-13 09:05:54,314 - scripts.p2p.transport_cascade - INFO - Registered transport: p2p_relay (tier TIER_4_RELAY)
2026-01-13 09:05:54,314 - scripts.p2p.p2p_mixin_base - INFO - [peer_manager] Failover system initialized successfully
2026-01-13 09:05:54,314 - p2p_orchestrator - INFO - Failover system initialized (transport cascade + union discovery)
2026-01-13 09:05:54,316 - scripts.p2p.managers.state_manager - INFO - Loaded cluster epoch: 3916
2026-01-13 09:05:54,317 - p2p_orchestrator - INFO - Safeguards: rate_limit=5/min, load_max=2.0x, agent_mode=False
2026-01-13 09:05:54,319 - scripts.p2p.managers.state_manager - INFO - P0.5: Invalidated expired leader lease on startup. Old leader: aws-staging, expired at: 0, now: 1768316754
2026-01-13 09:05:54,319 - scripts.p2p.managers.state_manager - INFO - Loaded state: 42 peers, 15 jobs
2026-01-13 09:05:54,319 - scripts.p2p.managers.state_manager - INFO - [StateManager] Cleaned stale state: removed 0 jobs, 41 peers
2026-01-13 09:05:54,319 - p2p_orchestrator - INFO - Loaded state: 1 peers, 15 jobs
2026-01-13 09:05:54,319 - p2p_orchestrator - INFO - [P2P] Startup state validation passed
2026-01-13 09:05:54,320 - scripts.p2p.managers.state_manager - INFO - [StateManager] Loaded 44 peer health records
2026-01-13 09:05:54,320 - p2p_orchestrator - INFO - [P2P] Loaded 44 peer health records
2026-01-13 09:05:55,327 - p2p_orchestrator - WARNING - [P2P] GPU node MacBook-Pro-5 is marked as coordinator - this may be a misconfiguration. GPU: Apple MPS. Unset RINGRIFT_IS_COORDINATOR or remove role:coordinator from YAML to enable training capabilities.
2026-01-13 09:05:55,327 - p2p_orchestrator - INFO - [P2P] Coordinator-only mode: no selfplay/training/cmaes capabilities
2026-01-13 09:05:55,520 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Subscribed to HOST_OFFLINE
2026-01-13 09:05:55,520 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Subscribed to NODE_RECOVERED
2026-01-13 09:05:55,520 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Subscribed to HOST_ONLINE
2026-01-13 09:05:55,520 - p2p_orchestrator - WARNING - Cannot create ramdrive at /dev/shm/ringrift/data: [Errno 1] Operation not permitted: '/dev/shm'. Falling back to disk storage.
2026-01-13 09:05:55,520 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to LEADER_ELECTED
2026-01-13 09:05:55,520 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to NODE_RECOVERED
2026-01-13 09:05:55,520 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to HOST_ONLINE
2026-01-13 09:05:55,520 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Event subscriptions complete (3 events)
2026-01-13 09:05:55,521 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to SELFPLAY_RATE_CHANGED
2026-01-13 09:05:55,521 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to EXPLORATION_BOOST
2026-01-13 09:05:55,521 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to TRAINING_COMPLETED
2026-01-13 09:05:55,521 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to ELO_VELOCITY_CHANGED
2026-01-13 09:05:55,521 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to NPZ_EXPORT_COMPLETE
2026-01-13 09:05:55,521 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to TRAINING_STARTED
2026-01-13 09:05:55,521 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to EVALUATION_COMPLETED
2026-01-13 09:05:55,521 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to PLATEAU_DETECTED
2026-01-13 09:05:55,521 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to EVALUATION_BACKPRESSURE
2026-01-13 09:05:55,521 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to EVALUATION_BACKPRESSURE_RELEASED
2026-01-13 09:05:55,521 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to TRAINING_BLOCKED_BY_QUALITY
2026-01-13 09:05:55,521 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to HYPERPARAMETER_UPDATED
2026-01-13 09:05:55,521 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to QUALITY_SCORE_UPDATED
2026-01-13 09:05:55,521 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to ARCHITECTURE_WEIGHTS_UPDATED
2026-01-13 09:05:55,521 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to DATA_STARVATION_CRITICAL
2026-01-13 09:05:55,521 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Event subscriptions complete (15 events)
2026-01-13 09:05:55,535 - p2p_orchestrator - INFO - [P2P] Seeded SelfplayScheduler with 3 config game counts from canonical DBs
2026-01-13 09:05:55,536 - p2p_orchestrator - INFO - [P2P] Underserved config: hex8_4p = 4 games
2026-01-13 09:05:55,536 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to HOST_OFFLINE
2026-01-13 09:05:55,536 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to HOST_ONLINE
2026-01-13 09:05:55,536 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to NODE_RECOVERED
2026-01-13 09:05:55,536 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Event subscriptions complete (3 events)
2026-01-13 09:05:55,536 - p2p_orchestrator - INFO - [P2P] Spawn verification wired: JobManager <-> SelfplayScheduler
2026-01-13 09:05:55,536 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to SELFPLAY_COMPLETE
2026-01-13 09:05:55,536 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to DATA_SYNC_COMPLETED
2026-01-13 09:05:55,536 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to EVALUATION_COMPLETED
2026-01-13 09:05:55,536 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to REGRESSION_DETECTED
2026-01-13 09:05:55,536 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to TASK_ABANDONED
2026-01-13 09:05:55,536 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Subscribed to P2P_NODE_DEAD
2026-01-13 09:05:55,536 - scripts.p2p.p2p_mixin_base - INFO - [EventSubscriptionMixin] Event subscriptions complete (6 events)
2026-01-13 09:05:55,536 - p2p_orchestrator - INFO - [P2P] JobOrchestrationManager initialized
2026-01-13 09:05:55,536 - p2p_orchestrator - INFO - WorkDiscoveryManager: initialized with 4 discovery channels
2026-01-13 09:05:55,551 - app.coordination.cross_process_events - INFO - [CrossProcessEventPoller] Resuming from event_id 49649
2026-01-13 09:05:55,551 - app.coordination.curriculum_integration - INFO - [MomentumToCurriculumBridge] Subscribed to EVALUATION_COMPLETED, SELFPLAY_RATE_CHANGED, ELO_SIGNIFICANT_CHANGE, SELFPLAY_ALLOCATION_UPDATED, MODEL_PROMOTED, TIER_PROMOTION, CROSSBOARD_PROMOTION, CURRICULUM_ADVANCEMENT_NEEDED, ELO_VELOCITY_CHANGED, CURRICULUM_ADVANCED, CURRICULUM_PROPAGATE, REGRESSION_DETECTED, TRAINING_LOSS_ANOMALY, QUORUM_RECOVERY_STARTED, CURRICULUM_ROLLBACK
2026-01-13 09:05:55,551 - app.coordination.curriculum_integration - INFO - [MomentumToCurriculumBridge] Started (event-driven mode)
2026-01-13 09:05:55,552 - app.coordination.curriculum_integration - INFO - [PFSPWeaknessWatcher] Started
2026-01-13 09:05:55,552 - app.coordination.curriculum_router - INFO - [promotion_failed_curriculum_watcher] Subscribed to ['PROMOTION_FAILED']
2026-01-13 09:05:55,552 - app.coordination.curriculum_integration - INFO - [PromotionCompletedToCurriculumWatcher] Subscribed to PROMOTION_COMPLETED
2026-01-13 09:05:55,552 - app.coordination.curriculum_router - INFO - [quality_penalty_curriculum_watcher] Subscribed to ['QUALITY_PENALTY_APPLIED']
2026-01-13 09:05:55,552 - app.coordination.curriculum_router - INFO - [regression_critical_curriculum_watcher] Subscribed to ['REGRESSION_CRITICAL']
2026-01-13 09:05:55,554 - app.coordination.curriculum_router - INFO - [architecture_curriculum_bridge] Subscribed to ['ARCHITECTURE_WEIGHTS_UPDATED']
2026-01-13 09:05:55,554 - app.coordination.curriculum_integration - INFO - [QualityToTemperatureWatcher] Subscribed to quality events
2026-01-13 09:05:55,554 - app.training.curriculum_feedback - INFO - [CurriculumFeedback] Subscribed to CURRICULUM_ADVANCED + TRAINING_EARLY_STOPPED events
2026-01-13 09:05:55,554 - app.training.curriculum_feedback - INFO - [EloToCurriculumWatcher] Subscribed to ELO_UPDATED events
2026-01-13 09:05:55,554 - app.training.curriculum_feedback - INFO - [wire_elo_to_curriculum] ELO events wired to curriculum rebalance (threshold=30.0)
2026-01-13 09:05:55,554 - app.training.curriculum_feedback - INFO - [PlateauToCurriculumWatcher] Subscribed to PLATEAU_DETECTED events
2026-01-13 09:05:55,555 - app.training.curriculum_feedback - INFO - [wire_plateau_to_curriculum] PLATEAU_DETECTED events wired to curriculum rebalance (cooldown=600.0s, boost=0.3)
2026-01-13 09:05:55,555 - app.training.curriculum_feedback - INFO - [TournamentToCurriculumWatcher] Subscribed to EVALUATION_COMPLETED events
2026-01-13 09:05:55,555 - app.training.curriculum_feedback - INFO - [wire_tournament_to_curriculum] EVALUATION_COMPLETED events wired to curriculum (low=0.45, high=0.65)
2026-01-13 09:05:55,555 - app.training.curriculum_feedback - INFO - [PromotionToCurriculumWatcher] Subscribed to MODEL_PROMOTED events
2026-01-13 09:05:55,556 - app.training.curriculum_feedback - INFO - [wire_promotion_to_curriculum] PROMOTION_COMPLETE events wired to curriculum (failure_urgency=high)
2026-01-13 09:05:55,556 - app.training.curriculum_feedback - INFO - [QualityFeedbackWatcher] Subscribed to QUALITY_SCORE_UPDATED events
2026-01-13 09:05:55,556 - app.training.curriculum_feedback - INFO - [wire_quality_to_curriculum] Quality events wired to selfplay budget adjustment (window=100)
2026-01-13 09:05:55,560 - app.training.curriculum_feedback - INFO - [wire_epoch_to_curriculum] EPOCH_COMPLETED events wired to curriculum (check_interval=5 epochs)
2026-01-13 09:05:55,566 - app.training.curriculum_feedback - INFO - CurriculumFeedback: OpponentWinRateTracker integrated
2026-01-13 09:05:55,566 - app.training.curriculum_feedback - INFO - Wired OpponentWinRateTracker to CurriculumFeedback
2026-01-13 09:05:55,566 - app.training.curriculum_feedback - INFO - [wire_all_curriculum_feedback] Wired opponent tracker to curriculum
2026-01-13 09:05:55,566 - app.training.curriculum_feedback - INFO - [EarlyStopToCurriculumWatcher] Subscribed to TRAINING_EARLY_STOPPED events
2026-01-13 09:05:55,567 - app.training.curriculum_feedback - INFO - [wire_early_stop_to_curriculum] TRAINING_EARLY_STOPPED events wired to curriculum boost
2026-01-13 09:05:55,567 - app.training.curriculum_feedback - INFO - [wire_all_curriculum_feedback] Wired 8 curriculum feedback integrations
2026-01-13 09:05:55,567 - app.coordination.curriculum_integration - INFO - [wire_all_feedback_loops] Wired 9 feedback integrations: momentum_bridge, pfsp_weakness, promotion_failed_curriculum, promotion_completed_curriculum, quality_penalty_curriculum, regression_critical_curriculum, architecture_curriculum, quality_temperature, curriculum_feedback
2026-01-13 09:05:55,567 - p2p_orchestrator - WARNING - Feedback loops: partial wiring - Unknown error
2026-01-13 09:05:55,567 - p2p_orchestrator - INFO - Subscribed to daemon status events
2026-01-13 09:05:55,567 - p2p_orchestrator - INFO - Subscribed to training feedback signals
2026-01-13 09:05:55,567 - p2p_orchestrator - INFO - Subscribed to manager lifecycle and health events
2026-01-13 09:05:55,567 - p2p_orchestrator - INFO - [P2P] Event subscriptions: daemon=✓, feedback=✓, manager=✓
[P2P] Initialized node MacBook-Pro-5 on 0.0.0.0:8770 (advertise 100.69.164.58:8770)
2026-01-13 09:05:55,567 - p2p_orchestrator - INFO - RingRift path: /Users/armand/Development/RingRift
2026-01-13 09:05:55,567 - p2p_orchestrator - INFO - Version: main@75ebe0abe
2026-01-13 09:05:55,567 - p2p_orchestrator - INFO - Known peers: ['100.94.174.19:8770', '100.67.131.72:8770', '100.94.201.92:8770', '100.126.21.102:8770', '100.110.28.41:8770']
2026-01-13 09:05:55,567 - p2p_orchestrator - INFO - Auth: disabled (set RINGRIFT_CLUSTER_AUTH_TOKEN to enable)
2026-01-13 09:05:55,567 - p2p_orchestrator - INFO - HybridTransport: enabled (HTTP with SSH fallback for Vast)
2026-01-13 09:05:55,567 - app.p2p.swim_adapter - INFO - SWIM seeds from cluster_config: [('100.107.168.125', 7947), ('100.68.208.43', 7947), ('100.94.174.19', 7947), ('100.67.131.72', 7947), ('100.126.21.102', 7947), ('100.94.201.92', 7947), ('100.109.195.71', 7947)]
2026-01-13 09:05:55,567 - p2p_orchestrator - INFO - SWIM membership manager initialized for MacBook-Pro-5
2026-01-13 09:05:55,567 - p2p_orchestrator - INFO - LoopManager: initialized for extracted background loops
2026-01-13 09:05:55,568 - p2p_orchestrator - INFO - [P2P] Manager health: 0/8 healthy, 8 starting (grace period: 58s remaining)
2026-01-13 09:05:55,569 - p2p_orchestrator - INFO - P2P orchestrator initialized successfully: MacBook-Pro-5
2026-01-13 09:05:55,569 - p2p_orchestrator - INFO - [P2P] Event emitters available - P2P events will be published
2026-01-13 09:05:55,569 - p2p_orchestrator - INFO - Starting P2P orchestrator main loop: MacBook-Pro-5
2026-01-13 09:05:55,569 - p2p_orchestrator - INFO - Started isolated health server thread (port 8772)
2026-01-13 09:05:55,570 - p2p_orchestrator - INFO - [Startup Validation] SWIM protocol available (membership_mode=hybrid)
2026-01-13 09:05:55,570 - p2p_orchestrator - INFO - [Startup Validation] Raft protocol available (consensus_mode=hybrid)
2026-01-13 09:05:55,570 - p2p_orchestrator - INFO - [Startup Validation] Protocol config: membership=hybrid, consensus=hybrid
2026-01-13 09:05:55,570 - p2p_orchestrator - INFO - Isolated health server started on 0.0.0.0:8772
2026-01-13 09:05:58,148 - p2p_orchestrator - INFO - [Startup Validation] Voter quorum OK: 6/8 voters reachable
2026-01-13 09:05:58,148 - scripts.p2p.resource_detector - WARNING - [ResourceDetector] GPU detected (Apple MPS) but PyTorch has no CUDA support. Fix: pip install torch --index-url https://download.pytorch.org/whl/cu128
2026-01-13 09:05:58,148 - p2p_orchestrator - WARNING - [Startup Validation] GPU detected (Apple MPS) but PyTorch has no CUDA support. Fix: pip install torch --index-url https://download.pytorch.org/whl/cu128
/Users/armand/Development/RingRift/ai-service/scripts/p2p_orchestrator.py:28444: DeprecationWarning: get_event_bus() from data_events is deprecated. Use get_router() from app.coordination.event_router instead.
  get_event_bus().emit(
2026-01-13 09:05:58,148 - p2p_orchestrator - WARNING - [Startup Validation] Completed with 1 warnings. Managers: 2/3 available
2026-01-13 09:05:58,154 - scripts.p2p.routes - WARNING - Missing 2 handlers: ['handle_probe_vast_nodes', 'handle_gpu_rankings']...
2026-01-13 09:05:58,154 - p2p_orchestrator - INFO - Registered 187 HTTP routes from route registry
2026-01-13 09:05:58,157 - scripts.p2p.handlers.file_download - INFO - Registered 4 file download routes
2026-01-13 09:05:58,157 - p2p_orchestrator - INFO - Registered 4 file download routes for HTTP-based sync
2026-01-13 09:05:58,157 - scripts.p2p.handlers.network_health - INFO - Registered network health routes: /network/health, /network/reconnect, /network/status
2026-01-13 09:05:58,157 - scripts.p2p.handlers.models - INFO - [ModelHandler] Registered 2 model routes
2026-01-13 09:05:58,157 - p2p_orchestrator - INFO - Registered 2 model inventory routes
2026-01-13 09:05:58,173 - scripts.verify_nfs_sync - WARNING - Could not auto-detect NFS root. Set RINGRIFT_NFS_PATH environment variable.
2026-01-13 09:05:58,173 - scripts.verify_nfs_sync - INFO - NFS not configured, skipping sync verification
2026-01-13 09:05:58,175 - app.distributed.cluster_manifest - INFO - ClusterManifest initialized: node=MacBook-Pro-5.local, db=/Users/armand/Development/RingRift/ai-service/data/cluster_manifest.db
2026-01-13 09:05:58,175 - app.distributed.cluster_manifest - INFO - [ClusterManifest] Subscribed to real-time events (NEW_GAMES_AVAILABLE, GAMES_UPLOADED_TO_S3, GAMES_UPLOADED_TO_OWC, BACKUP_COMPLETED)
2026-01-13 09:05:58,175 - app.coordination.sync_router - INFO - [SyncRouter] External storage configured: mac-studio -> /Volumes/RingRift-Data
2026-01-13 09:05:58,175 - app.coordination.sync_router - INFO - SyncRouter initialized: 23 nodes
2026-01-13 09:05:58,175 - p2p_orchestrator - INFO - SyncRouter: initialized for intelligent data routing
2026-01-13 09:05:58,175 - app.coordination.sync_router - INFO - [SyncRouter] Wired to event router (NEW_GAMES_AVAILABLE, TRAINING_STARTED, HOST_ONLINE/OFFLINE, NODE_RECOVERED, CLUSTER_CAPACITY_CHANGED, MODEL_SYNC_REQUESTED, SYNC_STALLED, SYNC_FAILURE_CRITICAL, BACKPRESSURE_ACTIVATED/RELEASED, CONFIG_UPDATED)
2026-01-13 09:05:58,175 - p2p_orchestrator - INFO - SyncRouter: wired to event system
2026-01-13 09:05:58,175 - p2p_orchestrator - INFO - ULSM: Leadership state machine broadcast callback wired
2026-01-13 09:05:58,175 - p2p_orchestrator - INFO - HTTP server started on 0.0.0.0:8770 (IPv4, backlog=1024)
2026-01-13 09:05:58,176 - p2p_orchestrator - INFO - HTTP server also listening on [::]:8770 (IPv6)
2026-01-13 09:05:58,855 - app.coordination.resource_optimizer - INFO - Loaded PID config from /Users/armand/Development/RingRift/ai-service/config/unified_loop.yaml: kp=0.3, ki=0.05, kd=0.1
2026-01-13 09:05:58,856 - app.coordination.resource_optimizer - INFO - ResourceOptimizer initialized: node=MacBook-Pro-5.local, target=60.0-80.0%
2026-01-13 09:05:59,419 - p2p_orchestrator - INFO - [P2P] Startup announcement discovered peer: hetzner-cpu1
2026-01-13 09:06:05,910 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:06:05 -0600] "GET /api/cluster/status HTTP/1.1" 200 3099 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:06:06,619 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:06:05 -0600] "GET /api/cluster/status HTTP/1.1" 200 3087 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:06:06,694 - app.coordination.node_policies - INFO - Loaded 5 node policies, 0 overrides
2026-01-13 09:06:06,696 - app.coordination.work_queue - INFO - Work queue database initialized at /Users/armand/Development/RingRift/ai-service/data/work_queue.db
2026-01-13 09:06:06,751 - app.coordination.work_queue - INFO - Loaded 3863 work items from database
2026-01-13 09:06:06,753 - app.coordination.work_queue - INFO - [WorkQueue] Restored backpressure active state from DB (pending=3863)
2026-01-13 09:06:06,896 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:06:06 -0600] "GET /status HTTP/1.1" 200 12400 "-" "Python-urllib/3.10"
2026-01-13 09:06:07,033 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:06:06 -0600] "GET /status HTTP/1.1" 200 12381 "-" "curl/8.7.1"
2026-01-13 09:06:18,094 - aiohttp.access - INFO - 100.106.87.89 [13/Jan/2026:09:06:18 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:06:18,103 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:06:18 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:06:31,514 - app.distributed.hosts - INFO - Loaded 23 remote host(s) from /Users/armand/Development/RingRift/ai-service/config/distributed_hosts.yaml
2026-01-13 09:06:31,514 - app.distributed.dynamic_registry - INFO - Loaded 23 hosts into dynamic registry
2026-01-13 09:06:31,515 - app.distributed.dynamic_registry - INFO - Loaded dynamic registry state from /Users/armand/Development/RingRift/ai-service/logs/p2p_orchestrator/dynamic_registry.json
2026-01-13 09:06:35,221 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:06:35 -0600] "GET /status HTTP/1.1" 200 12405 "-" "Python-urllib/3.10"
2026-01-13 09:06:35,715 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:06:35 -0600] "GET /status HTTP/1.1" 200 12386 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:06:35,964 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:06:35 -0600] "GET /status HTTP/1.1" 200 12387 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:06:36,400 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:06:36 -0600] "GET /status HTTP/1.1" 200 12412 "-" "Python-urllib/3.10"
2026-01-13 09:06:37,412 - p2p_orchestrator - INFO - First-contact peer registered: 192-222-50-48 (caps: ['selfplay', 'training', 'cmaes', 'large_boards'])
2026-01-13 09:06:38,074 - aiohttp.access - INFO - 100.106.87.89 [13/Jan/2026:09:06:37 -0600] "POST /heartbeat HTTP/1.1" 200 1927 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:06:38,074 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 192-222-50-48, invalidating cluster manifest
2026-01-13 09:06:38,075 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 192-222-50-48, node available for jobs
2026-01-13 09:06:38,075 - app.coordination.sync_router - INFO - [SyncRouter] Added new node: 100.106.87.89
2026-01-13 09:06:39,479 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:06:39 -0600] "GET /status HTTP/1.1" 200 16292 "-" "curl/8.7.1"
2026-01-13 09:06:47,128 - aiohttp.access - INFO - 100.106.87.89 [13/Jan/2026:09:06:46 -0600] "POST /heartbeat HTTP/1.1" 200 1933 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:06:48,612 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:06:48 -0600] "GET /health HTTP/1.1" 200 711 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:06:52,630 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:06:52 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:06:53,817 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:06:53 -0600] "GET /status HTTP/1.1" 200 16307 "-" "curl/8.7.1"
2026-01-13 09:06:54,171 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:06:54 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:07:01,250 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:07:01,252 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:07:00 -0600] "GET /status HTTP/1.1" 200 16308 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:07:01,400 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:07:01,415 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:07:01 -0600] "GET /status HTTP/1.1" 200 16307 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:07:04,693 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:07:04 -0600] "GET /health HTTP/1.1" 200 712 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:07:06,214 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:07:06 -0600] "GET /health HTTP/1.1" 200 712 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:07:06,215 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:07:06 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:07:06,805 - p2p_orchestrator - INFO - Adopting higher cluster epoch: 3918 (was 3916)
2026-01-13 09:07:06,816 - p2p_orchestrator - INFO - [LeaderSet] follower->follower, leader_id=None->hetzner-cpu2, reason=higher_epoch_leader
2026-01-13 09:07:07,450 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: aws-staging at 54.198.219.106:8770
2026-01-13 09:07:08,056 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: hetzner-cpu3 at 100.126.21.102:8770
2026-01-13 09:07:08,745 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: lambda-gh200-training at 100.68.208.43:8770
2026-01-13 09:07:09,413 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: hetzner-cpu2 at 100.67.131.72:8770
2026-01-13 09:07:10,034 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: lambda-gh200-2 at 100.110.143.119:8770
2026-01-13 09:07:10,645 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: lambda-gh200-1 at 100.71.89.91:8770
2026-01-13 09:07:11,246 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: lambda-gh200-3 at 100.69.101.108:8770
2026-01-13 09:07:11,859 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: lambda-gh200-4 at 100.77.186.124:8770
2026-01-13 09:07:12,451 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: lambda-gh200-5 at 100.83.177.16:8770
2026-01-13 09:07:13,068 - aiohttp.access - INFO - fd7a:115c:a1e0::4f01:ae13 [13/Jan/2026:09:07:06 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:07:13,069 - p2p_orchestrator - INFO - First-contact peer registered: aws-staging (caps: ['selfplay', 'large_boards'])
2026-01-13 09:07:13,702 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:07:13 -0600] "POST /heartbeat HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:07:14,351 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:07:13 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:07:14,352 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: aws-staging, invalidating cluster manifest
2026-01-13 09:07:14,352 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: aws-staging, node available for jobs
2026-01-13 09:07:15,562 - app.coordination.sync_router - INFO - [SyncRouter] Added new node: 100.115.97.24
2026-01-13 09:07:15,563 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: hetzner-cpu3 at 100.126.21.102:8770
2026-01-13 09:07:16,150 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: lambda-gh200-training at 100.68.208.43:8770
2026-01-13 09:07:16,740 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: hetzner-cpu2 at 100.67.131.72:8770
2026-01-13 09:07:17,334 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: lambda-gh200-2 at 100.110.143.119:8770
2026-01-13 09:07:17,923 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: lambda-gh200-1 at 100.71.89.91:8770
2026-01-13 09:07:18,530 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: lambda-gh200-3 at 100.69.101.108:8770
2026-01-13 09:07:19,172 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: lambda-gh200-4 at 100.77.186.124:8770
2026-01-13 09:07:19,816 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: lambda-gh200-5 at 100.83.177.16:8770
2026-01-13 09:07:20,437 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: lambda-gh200-training at 100.68.208.43:8770
2026-01-13 09:07:21,041 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: lambda-gh200-1 at 100.71.89.91:8770
2026-01-13 09:07:21,654 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: lambda-gh200-5 at 100.83.177.16:8770
2026-01-13 09:07:22,265 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 192-222-51-29 at 100.69.101.108:8770
2026-01-13 09:07:22,878 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: hetzner-cpu2 at 100.67.131.72:8770
2026-01-13 09:07:23,481 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: hetzner-cpu3 at 100.126.21.102:8770
2026-01-13 09:07:24,122 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 192-222-58-171 at 100.83.177.16:8770
2026-01-13 09:07:24,826 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 192-222-51-60 at 100.127.168.116:8770
2026-01-13 09:07:25,477 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: lambda-gh200-3 at 100.69.101.108:8770
2026-01-13 09:07:26,135 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: lambda-gh200-2 at 100.110.143.119:8770
2026-01-13 09:07:26,759 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: local-mac at 127.0.0.1:8770
2026-01-13 09:07:27,344 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: nebius-h100-1 at 127.0.0.1:8770
2026-01-13 09:07:27,928 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: d6928e099d99 at 127.0.0.1:8770
2026-01-13 09:07:28,536 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: MacBook-Pro-2.local at 127.0.0.1:8770
2026-01-13 09:07:29,124 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: computeinstance-e00gyg7x6xhkc7fs5x at 127.0.0.1:8770
2026-01-13 09:07:29,782 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: ringrift-cpu1 at 100.94.174.19:8770
2026-01-13 09:07:30,406 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: computeinstance-e00hcbnn7s7p0c7bbp at 127.0.0.1:8770
2026-01-13 09:07:31,021 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: b148b1697229 at 127.0.0.1:8770
2026-01-13 09:07:31,615 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: vast-29031159 at 127.0.0.1:8770
2026-01-13 09:07:32,218 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: lambda-gh200-4 at 100.77.186.124:8770
2026-01-13 09:07:32,822 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 46.62.217.168:7947 at 46.62.217.168:8770
2026-01-13 09:07:33,443 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 100.127.168.116:7947 at 100.127.168.116:8770
2026-01-13 09:07:34,066 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 100.94.174.19:7947 at 100.94.174.19:8770
2026-01-13 09:07:34,698 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 46.62.147.150:7947 at 46.62.147.150:8770
2026-01-13 09:07:35,399 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:07:13 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:07:35,400 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:07:13 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:07:35,403 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: aws-staging
2026-01-13 09:07:35,406 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-training
2026-01-13 09:07:35,410 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-4
2026-01-13 09:07:35,413 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-2
2026-01-13 09:07:35,415 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-1
2026-01-13 09:07:35,418 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-3
2026-01-13 09:07:35,424 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:07:35 -0600] "GET /health HTTP/1.1" 200 757 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:07:36,727 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:07:36 -0600] "POST /heartbeat HTTP/1.1" 200 1955 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:07:37,342 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:07:36 -0600] "POST /heartbeat HTTP/1.1" 200 1951 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:07:37,960 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:07:36 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:07:38,626 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:07:36 -0600] "POST /heartbeat HTTP/1.1" 200 1955 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:07:39,345 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:07:36 -0600] "POST /heartbeat HTTP/1.1" 200 1945 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:07:40,060 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:07:36 -0600] "POST /heartbeat HTTP/1.1" 200 1956 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:07:40,764 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:07:36 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:07:41,434 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:07:36 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:07:41,615 - app.distributed.hybrid_transport - INFO - [Transport] hetzner-cpu2: Switching to SSH after 3 HTTP failures
2026-01-13 09:07:41,631 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:07:35 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:07:41,631 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-training
2026-01-13 09:07:41,636 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-2
2026-01-13 09:07:41,639 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-1
2026-01-13 09:07:41,650 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-3
2026-01-13 09:07:41,655 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-5
2026-01-13 09:07:41,658 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-3
2026-01-13 09:07:41,662 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-4
2026-01-13 09:07:41,665 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-5
2026-01-13 09:07:41,669 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:07:41,669 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:07:41,669 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:07:41,669 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:07:41,670 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:07:41,670 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:07:41,670 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:07:41,670 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:07:41,965 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-4
2026-01-13 09:07:41,977 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-training
2026-01-13 09:07:41,995 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-2
2026-01-13 09:07:42,007 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-5
2026-01-13 09:07:42,017 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-1
2026-01-13 09:07:42,037 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-3
2026-01-13 09:07:42,250 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-5
2026-01-13 09:07:43,199 - app.tournament.unified_elo_db - INFO - EloDatabase initialized at /Users/armand/Development/RingRift/ai-service/data/unified_elo.db
2026-01-13 09:07:43,328 - p2p_orchestrator - WARNING - [VoterHealth] Voter hetzner-cpu1 went OFFLINE (2/8 alive, quorum=3)
2026-01-13 09:07:43,328 - p2p_orchestrator - INFO - [VoterHealth] Voter lambda-gh200-training came ONLINE (2/8 alive, quorum=3)
2026-01-13 09:07:43,328 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:07:43,329 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:07:43 -0600] "GET /status HTTP/1.1" 200 18447 "-" "curl/8.7.1"
2026-01-13 09:07:57,496 - app.distributed.hybrid_transport - INFO - [Transport] hetzner-cpu3: Switching to SSH after 3 HTTP failures
2026-01-13 09:08:04,372 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:08:04 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:08:06,509 - app.distributed.hybrid_transport - INFO - [Transport] hetzner-cpu1: Switching to SSH after 3 HTTP failures
2026-01-13 09:08:09,138 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 192-222-51-29 at 100.69.101.108:8770
2026-01-13 09:08:09,796 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:08:08 -0600] "POST /gossip HTTP/1.1" 200 2103 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:08:09,797 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:08:09 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:08:10,132 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: lambda-gh200-3
2026-01-13 09:08:16,592 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:08:16 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:08:16,593 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:08:16 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:08:28,732 - p2p_orchestrator - INFO - [P2P] Startup announcement discovered peer: ringrift-gpu
2026-01-13 09:08:31,092 - aiohttp.access - INFO - 100.121.230.110 [13/Jan/2026:09:08:31 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:08:34,452 - p2p_orchestrator - INFO - [VoterHealth] Voter vultr-a100-20gb came ONLINE (3/8 alive, quorum=3)
2026-01-13 09:08:34,453 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'nebius-h100-3']
2026-01-13 09:08:34,454 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:08:34 -0600] "GET /status HTTP/1.1" 200 16747 "-" "curl/8.7.1"
2026-01-13 09:08:39,006 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 192-222-50-174 at 100.121.230.110:8770
2026-01-13 09:08:39,686 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:08:38 -0600] "POST /gossip HTTP/1.1" 200 1875 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:08:39,847 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'nebius-h100-3']
2026-01-13 09:08:39,848 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:08:39 -0600] "GET /status HTTP/1.1" 200 16764 "-" "curl/8.7.1"
2026-01-13 09:08:40,197 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: 192-222-50-174
2026-01-13 09:08:46,835 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'nebius-h100-3']
2026-01-13 09:08:46,836 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:08:46 -0600] "GET /status HTTP/1.1" 200 15160 "-" "curl/8.7.1"
2026-01-13 09:08:52,215 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'nebius-h100-3']
2026-01-13 09:08:52,216 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:08:52 -0600] "GET /status HTTP/1.1" 200 15163 "-" "curl/8.7.1"
2026-01-13 09:08:56,000 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:08:55 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:08:57,196 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'nebius-h100-3']
2026-01-13 09:08:57,197 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:08:57 -0600] "GET /status HTTP/1.1" 200 15163 "-" "curl/8.7.1"
2026-01-13 09:08:57,211 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:08:57 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:08:57,782 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:08:57 -0600] "GET /health HTTP/1.1" 200 737 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:08:57,828 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:08:57 -0600] "GET /health HTTP/1.1" 200 737 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:08:59,062 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:08:59 -0600] "GET /health HTTP/1.1" 200 735 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:08:59,463 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:08:59 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:00,034 - aiohttp.access - INFO - fd7a:115c:a1e0::d201:656d [13/Jan/2026:09:08:59 -0600] "POST /gossip HTTP/1.1" 200 2002 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:00,408 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:09:00 -0600] "GET /health HTTP/1.1" 200 759 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:00,440 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 192-222-50-174, invalidating cluster manifest
2026-01-13 09:09:00,440 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 192-222-50-174, node available for jobs
2026-01-13 09:09:00,440 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 192-222-51-195, invalidating cluster manifest
2026-01-13 09:09:00,440 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 192-222-51-195, node available for jobs
2026-01-13 09:09:00,441 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: mac-studio, invalidating cluster manifest
2026-01-13 09:09:00,441 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: mac-studio, node available for jobs
2026-01-13 09:09:00,441 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 192-222-57-184, invalidating cluster manifest
2026-01-13 09:09:00,441 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 192-222-57-184, node available for jobs
2026-01-13 09:09:00,442 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 192-222-51-60, invalidating cluster manifest
2026-01-13 09:09:00,442 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 192-222-51-60, node available for jobs
2026-01-13 09:09:00,442 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 192-222-58-171, invalidating cluster manifest
2026-01-13 09:09:00,442 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 192-222-58-171, node available for jobs
2026-01-13 09:09:00,442 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: ringrift-gpu, invalidating cluster manifest
2026-01-13 09:09:00,442 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: ringrift-gpu, node available for jobs
2026-01-13 09:09:00,443 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: vultr-a100-20gb-2, invalidating cluster manifest
2026-01-13 09:09:00,443 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: vultr-a100-20gb-2, node available for jobs
2026-01-13 09:09:00,470 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-11, invalidating cluster manifest
2026-01-13 09:09:00,471 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-11, node available for jobs
2026-01-13 09:09:00,476 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: vultr-a100-20gb, invalidating cluster manifest
2026-01-13 09:09:00,476 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: vultr-a100-20gb, node available for jobs
2026-01-13 09:09:01,170 - aiohttp.access - INFO - fd7a:115c:a1e0::d201:656d [13/Jan/2026:09:09:00 -0600] "POST /gossip/anti-entropy HTTP/1.1" 200 17739 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:01,185 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:09:01 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:01,857 - aiohttp.access - INFO - fd7a:115c:a1e0::5901:8f96 [13/Jan/2026:09:09:01 -0600] "POST /gossip HTTP/1.1" 200 2044 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:01,858 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:09:01 -0600] "GET /health HTTP/1.1" 200 758 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:02,452 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'nebius-h100-3']
2026-01-13 09:09:02,452 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:09:02 -0600] "GET /status HTTP/1.1" 200 15169 "-" "curl/8.7.1"
2026-01-13 09:09:04,461 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:09:04 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:09:06,859 - aiohttp.access - INFO - fd7a:115c:a1e0::1c01:ba91 [13/Jan/2026:09:09:06 -0600] "POST /gossip HTTP/1.1" 200 2121 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:06,859 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:09:06 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:07,275 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'nebius-h100-3']
2026-01-13 09:09:07,276 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:09:07 -0600] "GET /status HTTP/1.1" 200 15155 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:09:07,461 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'nebius-h100-3']
2026-01-13 09:09:07,470 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:09:07 -0600] "GET /status HTTP/1.1" 200 15155 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:09:07,482 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:09:07 -0600] "GET /health HTTP/1.1" 200 757 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:08,298 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'nebius-h100-3']
2026-01-13 09:09:08,300 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:09:07 -0600] "GET /status HTTP/1.1" 200 15150 "-" "curl/8.7.1"
2026-01-13 09:09:26,216 - p2p_orchestrator - INFO - [P2P] Startup announcements: 2/5 peers reachable
2026-01-13 09:09:26,216 - p2p_orchestrator - INFO - [P2P] Local canonical DBs empty, fetching game counts from peers...
2026-01-13 09:09:26,229 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:09:26 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:26,229 - p2p_orchestrator - INFO - [P2P] Fetched 3 game counts from fallback MacBook-Pro-5
2026-01-13 09:09:26,230 - p2p_orchestrator - INFO - [P2P] Seeded SelfplayScheduler with 3 config game counts from peers
2026-01-13 09:09:26,230 - p2p_orchestrator - INFO - [P2P] Underserved config (from peers): hex8_4p = 4 games
2026-01-13 09:09:26,230 - p2p_orchestrator - INFO - [LoopManager] Phase 4 startup: EXTRACTED_LOOPS_ENABLED=True
2026-01-13 09:09:26,230 - p2p_orchestrator - INFO - [LoopManager] _register_extracted_loops called, already_registered=False
2026-01-13 09:09:26,230 - p2p_orchestrator - INFO - [LoopManager] Got manager: <scripts.p2p.loops.base.LoopManager object at 0x122cf43d0>
2026-01-13 09:09:26,230 - p2p_orchestrator - INFO - [P2P] SpawnVerificationLoop enabled for job spawn tracking
2026-01-13 09:09:26,230 - p2p_orchestrator - INFO - [P2P] PredictiveScalingLoop enabled for proactive job spawning
2026-01-13 09:09:26,230 - p2p_orchestrator - INFO - [P2P] JobReassignmentLoop enabled for faster orphaned job recovery
2026-01-13 09:09:26,236 - scripts.p2p.adapters.scale_adapters - INFO - CompositeScaleAdapter initialized with providers: []
2026-01-13 09:09:26,236 - p2p_orchestrator - INFO - [P2P] AutoScalingLoop enabled with reluctant termination
2026-01-13 09:09:26,237 - p2p_orchestrator - INFO - ModelFetchLoop: registered for training node model fetching
2026-01-13 09:09:26,237 - p2p_orchestrator - INFO - [LoopManager] TailscalePeerDiscoveryLoop registered
2026-01-13 09:09:26,237 - p2p_orchestrator - INFO - [LoopManager] PeerCleanupLoop registered
2026-01-13 09:09:26,237 - p2p_orchestrator - INFO - [LoopManager] GossipStateCleanupLoop registered
2026-01-13 09:09:26,237 - p2p_orchestrator - INFO - [LoopManager] QuorumCrisisDiscoveryLoop registered
2026-01-13 09:09:26,237 - p2p_orchestrator - INFO - [LoopManager] WorkerPullLoop registered (with work discovery manager)
2026-01-13 09:09:26,237 - p2p_orchestrator - INFO - [LoopManager] RemoteP2PRecoveryLoop registered (node: MacBook-Pro-5, leader-only execution)
2026-01-13 09:09:26,237 - p2p_orchestrator - INFO - [LoopManager] LeaderProbeLoop registered (fast leader recovery)
2026-01-13 09:09:26,237 - p2p_orchestrator - INFO - [P2P] TrainingSyncLoop registered (critical for training pipeline)
2026-01-13 09:09:26,237 - p2p_orchestrator - INFO - [P2P] DataAggregationLoop registered (important for training data)
2026-01-13 09:09:26,237 - p2p_orchestrator - INFO - [P2P] HealthAggregationLoop registered with auto-recovery (Session 17.26)
2026-01-13 09:09:26,237 - p2p_orchestrator - INFO - [P2P] IpDiscoveryLoop registered (handles dynamic IPs)
2026-01-13 09:09:26,237 - p2p_orchestrator - INFO - [P2P] TailscaleRecoveryLoop registered (handles Tailscale failures)
2026-01-13 09:09:26,237 - p2p_orchestrator - INFO - [P2P] TailscaleKeepaliveLoop registered (userspace_mode=True, interval=30.0s)
2026-01-13 09:09:26,238 - p2p_orchestrator - INFO - [P2P] ClusterHealingLoop registered (interval=300.0s, max_heal=5)
2026-01-13 09:09:26,238 - p2p_orchestrator - INFO - [P2P] UdpDiscoveryLoop registered (LAN peer discovery)
2026-01-13 09:09:26,238 - p2p_orchestrator - INFO - [P2P] SplitBrainDetectionLoop registered (partition detection)
2026-01-13 09:09:26,238 - p2p_orchestrator - INFO - [P2P] AutonomousQueuePopulationLoop registered (fallback queue population)
2026-01-13 09:09:26,238 - p2p_orchestrator - INFO - [P2P] HttpServerHealthLoop registered (with graceful restart support)
2026-01-13 09:09:26,238 - p2p_orchestrator - INFO - [P2P] ComprehensiveEvaluationLoop registered (6-hour model evaluation cycle)
2026-01-13 09:09:26,238 - p2p_orchestrator - INFO - [P2P] TournamentDataPipelineLoop registered (hourly tournament data export)
2026-01-13 09:09:26,238 - p2p_orchestrator - INFO - LoopManager: registered 38 loops
2026-01-13 09:09:26,238 - scripts.p2p.loops.base - INFO - [p2p_loops] Starting 38 loops in order: ['queue_populator', 'elo_sync', 'job_reaper', 'idle_detection', 'spawn_verification', 'predictive_scaling', 'job_reassignment', 'auto_scaling', 'work_queue_maintenance', 'nat_management', 'manifest_collection', 'data_management', 'model_sync', 'model_fetch', 'validation', 'tailscale_peer_discovery', 'peer_cleanup', 'gossip_state_cleanup', 'quorum_crisis_discovery', 'worker_pull', 'follower_discovery', 'self_healing', 'remote_p2p_recovery', 'leader_probe', 'predictive_monitoring', 'training_sync', 'data_aggregation', 'health_aggregation', 'ip_discovery', 'tailscale_recovery', 'tailscale_keepalive', 'cluster_healing', 'udp_discovery', 'split_brain_detection', 'autonomous_queue_population', 'http_server_health', 'comprehensive_evaluation', 'tournament_data_pipeline']
2026-01-13 09:09:26,238 - p2p_orchestrator - INFO - Sending initial heartbeat burst to known peers
2026-01-13 09:09:26,931 - p2p_orchestrator - INFO - Starting voter heartbeat loop (interval=10s)
2026-01-13 09:09:26,960 - app.p2p.swim_adapter - INFO - SWIM using TCP transport (attempt 1)
2026-01-13 09:09:26,960 - p2p_orchestrator - INFO - Vast IP update loop started
2026-01-13 09:09:26,960 - p2p_orchestrator - INFO - AWS IP update loop started
2026-01-13 09:09:26,960 - p2p_orchestrator - INFO - Tailscale IP update loop started
2026-01-13 09:09:26,960 - scripts.p2p.loops.base - INFO - [queue_populator] Starting loop (interval=60.0s)
2026-01-13 09:09:26,961 - scripts.p2p.loops.base - INFO - [elo_sync] Starting loop (interval=300.0s)
2026-01-13 09:09:26,962 - swim.transport.tcp - INFO - TCP transport bound to all interfaces (0.0.0.0:7947), identifying as 0.0.0.0:7947
2026-01-13 09:09:26,962 - swim.protocol.node - INFO - Transport successfully bound to 0.0.0.0:7947
2026-01-13 09:09:26,962 - swim.protocol.member - INFO - Added new member: 0.0.0.0:7947 (method: self)
2026-01-13 09:09:26,962 - swim.protocol.member - INFO - Created member list with self at 0.0.0.0:7947
2026-01-13 09:09:26,962 - swim.protocol.member - INFO - Added new member: 100.107.168.125:7947 (method: unknown)
2026-01-13 09:09:26,963 - swim.protocol.member - INFO - Added new member: 100.68.208.43:7947 (method: unknown)
2026-01-13 09:09:26,963 - swim.protocol.member - INFO - Added new member: 100.94.174.19:7947 (method: unknown)
2026-01-13 09:09:26,963 - swim.protocol.member - INFO - Added new member: 100.67.131.72:7947 (method: unknown)
2026-01-13 09:09:26,963 - swim.protocol.member - INFO - Added new member: 100.126.21.102:7947 (method: unknown)
2026-01-13 09:09:26,963 - swim.protocol.member - INFO - Added new member: 100.94.201.92:7947 (method: unknown)
2026-01-13 09:09:26,963 - swim.protocol.member - INFO - Added new member: 100.109.195.71:7947 (method: unknown)
2026-01-13 09:09:26,963 - swim.protocol.node - INFO - Added 7 seed nodes to member list
2026-01-13 09:09:26,963 - swim.protocol.failure_detector - INFO - Failure detector initialized with Lifeguard enhancements
2026-01-13 09:09:26,963 - swim.protocol.disseminator - INFO - Gossip service initialized with push-pull synchronization
2026-01-13 09:09:26,963 - swim.protocol.sync - INFO - Sync service initialized
2026-01-13 09:09:26,963 - swim.protocol.node - INFO - Push-pull sync service enabled
2026-01-13 09:09:26,964 - swim.protocol.node - INFO - Metrics collection enabled for node 0.0.0.0:7947
2026-01-13 09:09:26,964 - swim.lifeguard.awareness - INFO - Awareness service initialized (min=0, max=8)
2026-01-13 09:09:26,964 - swim.lifeguard.timing - INFO - Timing service initialized with adaptive adjustments
2026-01-13 09:09:26,964 - swim.lifeguard.probe_rate - INFO - Probe rate service initialized with adaptive control
2026-01-13 09:09:26,964 - swim.protocol.node - INFO - Lifeguard enhancements enabled
2026-01-13 09:09:26,964 - swim.protocol.node - INFO - Node initialized at 0.0.0.0:7947 with enhanced reliability features
2026-01-13 09:09:26,964 - swim.protocol.node - INFO - Node created successfully at 0.0.0.0:7947
2026-01-13 09:09:26,964 - swim.transport.tcp - INFO - TCP receiver task started
2026-01-13 09:09:26,964 - swim.protocol.node - INFO - Node started at 0.0.0.0:7947
2026-01-13 09:09:26,964 - app.p2p.swim_adapter - INFO - SWIM bootstrapped from 7 seeds
2026-01-13 09:09:26,964 - app.p2p.swim_adapter - INFO - SWIM membership started on 0.0.0.0:7947 (failure_timeout=15.0s)
2026-01-13 09:09:26,964 - p2p_orchestrator - INFO - SWIM membership loop: started successfully
2026-01-13 09:09:26,964 - scripts.p2p.consensus_mixin - INFO - Deferred Raft init: found 2 partners, attempting initialization
2026-01-13 09:09:26,965 - scripts.p2p.consensus_mixin - INFO - Initializing Raft consensus: self=100.69.164.58:4321, partners=['100.68.208.43:4321', '100.94.174.19:4321'], mode=hybrid
2026-01-13 09:09:26,966 - scripts.p2p.consensus_mixin - INFO - Raft consensus initialized successfully
2026-01-13 09:09:26,966 - scripts.p2p.consensus_mixin - INFO - Deferred Raft initialization succeeded with partners: ['100.68.208.43:4321', '100.94.174.19:4321']
2026-01-13 09:09:26,967 - swim.protocol.sync - INFO - Sync service started
2026-01-13 09:09:27,300 - p2p_orchestrator - WARNING - [VoterHealth] Voter lambda-gh200-training went OFFLINE (2/8 alive, quorum=3)
2026-01-13 09:09:27,300 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'nebius-h100-3']
2026-01-13 09:09:27,302 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:09:26 -0600] "GET /status HTTP/1.1" 200 34507 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:27,303 - app.coordination.database_sync_manager - INFO - [elo] Discovered 0 nodes from P2P
2026-01-13 09:09:27,304 - scripts.p2p.loops.base - INFO - [job_reaper] Starting loop (interval=300.0s)
2026-01-13 09:09:27,316 - app.tournament.elo_sync_manager - INFO - EloSyncManager initialized: 1425 local matches
2026-01-13 09:09:27,317 - scripts.p2p.loops.elo_sync_loop - INFO - [elo_sync] Started with interval 300.0s (attempt 1/5)
2026-01-13 09:09:27,337 - p2p_orchestrator - INFO - DB consolidation: 12 DBs with 75 games to merge
2026-01-13 09:09:27,354 - p2p_orchestrator - INFO - Started DB merge (PID: 65255)
2026-01-13 09:09:27,405 - scripts.p2p.loops.base - INFO - [idle_detection] Starting loop (interval=30.0s)
2026-01-13 09:09:27,506 - scripts.p2p.loops.base - INFO - [spawn_verification] Starting loop (interval=5.0s)
2026-01-13 09:09:28,312 - p2p_orchestrator - INFO - LOCAL: Disk at 83% - triggering cleanup
2026-01-13 09:09:28,312 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:09:28,903 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:09:28,904 - p2p_orchestrator - WARNING - LOCAL: Memory CRITICAL at 91% - emergency cleanup
2026-01-13 09:09:29,398 - p2p_orchestrator - INFO - Restarting stuck local selfplay jobs...
2026-01-13 09:09:29,606 - p2p_orchestrator - INFO - Killed 0 processes, cleared 0 job records
2026-01-13 09:09:30,274 - p2p_orchestrator - INFO - Emergency memory cleanup: cleared 28 gossip states, 0 manifests, ran gc.collect()
2026-01-13 09:09:31,190 - p2p_orchestrator - INFO - LOCAL: Disk at 83% - skipping job starts
2026-01-13 09:09:31,191 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:09:31,798 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:09:31,798 - p2p_orchestrator - INFO - LOCAL: Memory at 92% - skipping GPU auto-scale
2026-01-13 09:09:31,799 - scripts.p2p.managers.sync_planner - INFO - Loaded manifest from cache (age: 322s)
2026-01-13 09:09:32,512 - swim.transport.tcp - ERROR - Failed to establish connection to 100.67.131.72:7947: [Errno 61] Connect call failed ('100.67.131.72', 7947)
2026-01-13 09:09:32,520 - swim.transport.tcp - ERROR - Connection refused to 100.67.131.72:7947
2026-01-13 09:09:32,521 - swim.protocol.disseminator - ERROR - [b7881138] Error sending heartbeat to 100.67.131.72:7947: [Errno 61] Connect call failed ('100.67.131.72', 7947)
2026-01-13 09:09:32,643 - scripts.p2p.loops.base - INFO - [predictive_scaling] Starting loop (interval=30.0s)
2026-01-13 09:09:32,645 - scripts.p2p.loops.base - INFO - [job_reassignment] Starting loop (interval=60.0s)
2026-01-13 09:09:33,402 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:09:32 -0600] "GET /api/cluster/status HTTP/1.1" 200 10854 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:34,097 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:09:32 -0600] "GET /api/cluster/status HTTP/1.1" 200 10850 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:34,180 - scripts.p2p.loops.base - INFO - [auto_scaling] Starting loop (interval=120.0s)
2026-01-13 09:09:34,181 - scripts.p2p.loops.coordination_loops - INFO - [AutoScaling] Scaling up by 3 nodes
2026-01-13 09:09:34,181 - scripts.p2p.loops.coordination_loops - INFO - [AutoScaling] Added 0 nodes: []
2026-01-13 09:09:35,089 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'nebius-h100-3']
2026-01-13 09:09:35,090 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:09:32 -0600] "GET /status HTTP/1.1" 200 34583 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:35,237 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'nebius-h100-3']
2026-01-13 09:09:35,238 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:09:32 -0600] "GET /status HTTP/1.1" 200 34582 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:35,238 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:09:32 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:35,239 - scripts.p2p.loops.base - INFO - [work_queue_maintenance] Starting loop (interval=300.0s)
2026-01-13 09:09:35,247 - scripts.p2p.loops.job_loops - INFO - Work queue maintenance loop starting...
2026-01-13 09:09:35,266 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:09:35 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:09:35,341 - scripts.p2p.loops.base - INFO - [nat_management] Starting loop (interval=60.0s)
2026-01-13 09:09:35,342 - scripts.p2p.loops.network_loops - INFO - Starting advanced NAT management loop
2026-01-13 09:09:35,442 - scripts.p2p.loops.base - INFO - [manifest_collection] Starting loop (interval=300.0s)
2026-01-13 09:09:35,443 - scripts.p2p.loops.manifest_collection_loop - INFO - [manifest_collection] Starting (first collection in 60.0s)
2026-01-13 09:09:35,543 - scripts.p2p.loops.base - INFO - [data_management] Starting loop (interval=300.0s)
2026-01-13 09:09:35,544 - scripts.p2p.loops.data_loops - INFO - [data_management] Starting (first run in 30.0s)
2026-01-13 09:09:36,357 - scripts.p2p.loops.base - INFO - [model_sync] Starting loop (interval=120.0s)
2026-01-13 09:09:36,458 - scripts.p2p.loops.base - INFO - [model_fetch] Starting loop (interval=60.0s)
2026-01-13 09:09:36,558 - scripts.p2p.loops.base - INFO - [validation] Starting loop (interval=300.0s)
2026-01-13 09:09:36,559 - scripts.p2p.loops.validation_loop - INFO - Validation loop: initial delay before first check
2026-01-13 09:09:36,659 - scripts.p2p.loops.base - INFO - [tailscale_peer_discovery] Starting loop (interval=60.0s)
2026-01-13 09:09:36,659 - scripts.p2p.loops.network_loops - INFO - [TailscalePeerDiscovery] Starting ALL-NODE peer discovery loop (bootstrap=60.0s, maintenance=120.0s, min_peers=5)
2026-01-13 09:09:36,760 - scripts.p2p.loops.base - INFO - [peer_cleanup] Starting loop (interval=300.0s)
2026-01-13 09:09:36,760 - scripts.p2p.loops.peer_cleanup_loop - INFO - [PeerCleanup] Purged 1 stale peers (tier2: 1, tier3: 0). Health ratio: 100.0% → 100.0%
2026-01-13 09:09:36,861 - scripts.p2p.loops.base - INFO - [gossip_state_cleanup] Starting loop (interval=300.0s)
2026-01-13 09:09:36,861 - scripts.p2p.loops.gossip_state_cleanup_loop - INFO - [GossipStateCleanup] Purged 10 entries: states=0, manifests=0, recovery=0, reputation=0, endpoints=10, promotion=0, jobs=0
2026-01-13 09:09:36,962 - scripts.p2p.loops.base - INFO - [quorum_crisis_discovery] Starting loop (interval=10.0s)
2026-01-13 09:09:36,962 - scripts.p2p.loops.quorum_crisis_discovery_loop - INFO - [QuorumCrisis] Started (crisis_interval: 10.0s, tcp_timeout: 3.0s, http_timeout: 5.0s)
2026-01-13 09:09:37,062 - scripts.p2p.loops.base - INFO - [worker_pull] Starting loop (interval=10.0s)
2026-01-13 09:09:37,062 - scripts.p2p.loops.job_loops - INFO - Worker pull loop starting...
2026-01-13 09:09:37,163 - scripts.p2p.loops.base - INFO - [follower_discovery] Starting loop (interval=60.0s)
2026-01-13 09:09:37,263 - scripts.p2p.loops.base - INFO - [self_healing] Starting loop (interval=60.0s)
2026-01-13 09:09:37,263 - scripts.p2p.loops.resilience_loops - INFO - Self-healing loop starting...
2026-01-13 09:09:37,364 - scripts.p2p.loops.base - INFO - [remote_p2p_recovery] Starting loop (interval=60.0s)
2026-01-13 09:09:37,465 - scripts.p2p.loops.base - INFO - [leader_probe] Starting loop (interval=10.0s)
2026-01-13 09:09:37,657 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'nebius-h100-3']
2026-01-13 09:09:37,658 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:09:37 -0600] "GET /status HTTP/1.1" 200 42184 "-" "curl/8.7.1"
2026-01-13 09:09:37,658 - scripts.p2p.loops.base - INFO - [predictive_monitoring] Starting loop (interval=300.0s)
2026-01-13 09:09:37,658 - scripts.p2p.loops.resilience_loops - INFO - Predictive monitoring loop starting...
2026-01-13 09:09:37,758 - scripts.p2p.loops.base - INFO - [training_sync] Starting loop (interval=300.0s)
2026-01-13 09:09:37,859 - scripts.p2p.loops.base - INFO - [data_aggregation] Starting loop (interval=300.0s)
2026-01-13 09:09:37,959 - scripts.p2p.loops.base - INFO - [health_aggregation] Starting loop (interval=30.0s)
2026-01-13 09:09:38,059 - scripts.p2p.loops.base - INFO - [ip_discovery] Starting loop (interval=300.0s)
2026-01-13 09:09:38,159 - scripts.p2p.loops.base - INFO - [tailscale_recovery] Starting loop (interval=120.0s)
2026-01-13 09:09:38,260 - scripts.p2p.loops.base - INFO - [tailscale_keepalive] Starting loop (interval=30.0s)
2026-01-13 09:09:38,360 - scripts.p2p.loops.base - INFO - [cluster_healing] Starting loop (interval=300.0s)
2026-01-13 09:09:38,386 - scripts.p2p.loops.cluster_healing_loop - WARNING - [ClusterHealing] Failed to load hosts YAML: 'str' object has no attribute 'get'
2026-01-13 09:09:38,461 - scripts.p2p.loops.base - INFO - [udp_discovery] Starting loop (interval=30.0s)
2026-01-13 09:09:39,462 - scripts.p2p.loops.base - INFO - [split_brain_detection] Starting loop (interval=60.0s)
2026-01-13 09:09:39,462 - scripts.p2p.loops.resilience_loops - INFO - Split-brain detection loop starting...
2026-01-13 09:09:39,475 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:09:39 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:39,475 - aiohttp.access - INFO - 100.83.177.16 [13/Jan/2026:09:09:39 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:39,562 - scripts.p2p.loops.autonomous_queue_loop - INFO - [AutonomousQueue] Started with config: no_leader_threshold=60.0s, starvation_threshold=10, check_interval=30.0s
2026-01-13 09:09:39,563 - scripts.p2p.loops.base - INFO - [autonomous_queue_population] Starting loop (interval=30.0s)
2026-01-13 09:09:39,664 - scripts.p2p.loops.base - INFO - [http_server_health] Starting loop (interval=10.0s)
2026-01-13 09:09:39,764 - scripts.p2p.loops.base - INFO - [comprehensive_evaluation] Starting loop (interval=21600s)
2026-01-13 09:09:39,764 - scripts.p2p.loops.comprehensive_evaluation_loop - WARNING - [comprehensive_evaluation] Failed to get role: 'P2POrchestrator' object has no attribute '_role'
2026-01-13 09:09:39,865 - scripts.p2p.loops.base - INFO - [tournament_data_pipeline] Starting loop (interval=3600s)
2026-01-13 09:09:39,866 - scripts.p2p.loops.tournament_data_pipeline_loop - WARNING - [tournament_data_pipeline] Failed to get role: 'P2POrchestrator' object has no attribute '_role'
2026-01-13 09:09:39,966 - scripts.p2p.loops.base - INFO - [p2p_loops] All 38 loops verified running
2026-01-13 09:09:39,966 - p2p_orchestrator - INFO - LoopManager: started 38/38 loops, job_reaper=running
2026-01-13 09:09:40,533 - p2p_orchestrator - INFO - Bootstrap: imported 12 new peers from 100.94.174.19:8770
2026-01-13 09:09:42,385 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:09:41 -0600] "GET /api/cluster/status HTTP/1.1" 200 19077 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:42,490 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:09:42 -0600] "GET /status/peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:42,738 - p2p_orchestrator - INFO - [VoterHealth] Voter lambda-gh200-training came ONLINE (3/8 alive, quorum=3)
2026-01-13 09:09:42,738 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'nebius-h100-3']
2026-01-13 09:09:42,740 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:09:42 -0600] "GET /status HTTP/1.1" 200 53191 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:43,033 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'nebius-h100-3']
2026-01-13 09:09:43,046 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:09:42 -0600] "GET /status HTTP/1.1" 200 53188 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:09:52,561 - p2p_orchestrator - INFO - Voter lambda-gh200-training (key=lambda-gh200-training) NAT-blocked status cleared (heartbeat succeeded)
2026-01-13 09:09:56,961 - p2p_orchestrator - INFO - Starting dead peer reconnection loop (Phase 1 P2P stability fix)
2026-01-13 09:09:57,600 - scripts.p2p.loops.queue_populator_loop - INFO - [queue_populator] Starting with 30.0s initial delay
2026-01-13 09:09:57,682 - app.coordination.cluster_status_monitor - INFO - Loaded 23 hosts via cluster_config
2026-01-13 09:10:07,741 - app.core.ssh - WARNING - [SSHMetrics] Failure recorded: host=100.92.222.49, transport=tailscale, category=timeout, error=ssh: connect to host 100.92.222.49 port 22: Operation timed out

2026-01-13 09:10:07,795 - app.core.ssh - WARNING - [SSHMetrics] Failure recorded: host=192.222.58.241, transport=tailscale, category=timeout, error=Command timed out after 10s
2026-01-13 09:10:07,835 - app.core.ssh - WARNING - [SSHMetrics] Failure recorded: host=89.169.114.223, transport=tailscale, category=timeout, error=Command timed out after 10s
2026-01-13 09:10:07,852 - app.core.ssh - WARNING - [SSHMetrics] Failure recorded: host=89.169.111.107, transport=tailscale, category=timeout, error=Command timed out after 10s
2026-01-13 09:10:07,858 - app.core.ssh - WARNING - [SSHMetrics] Failure recorded: host=208.167.249.164, transport=tailscale, category=timeout, error=Command timed out after 10s
2026-01-13 09:10:07,864 - app.core.ssh - WARNING - [SSHMetrics] Failure recorded: host=89.169.96.55, transport=tailscale, category=timeout, error=Command timed out after 10s
2026-01-13 09:10:07,865 - app.coordination.unified_queue_populator - INFO - [QueuePopulator] Scaled queue depth: 50 -> 50 (for 16 active nodes)
2026-01-13 09:10:07,866 - app.coordination.unified_queue_populator - INFO - Loaded existing Elo for hex8_2p: 1537.0 (model: hex8_2p_improved, games: 137)
2026-01-13 09:10:07,866 - app.coordination.unified_queue_populator - INFO - Loaded existing Elo for hex8_3p: 1590.0 (model: ringrift_best_hex8_3p, games: 10)
2026-01-13 09:10:07,866 - app.coordination.unified_queue_populator - INFO - Loaded existing Elo for hex8_4p: 1619.6 (model: ringrift_best_hex8_4p, games: 20)
2026-01-13 09:10:07,866 - app.coordination.unified_queue_populator - INFO - Loaded existing Elo for hexagonal_2p: 1514.3 (model: heuristic, games: 20)
2026-01-13 09:10:07,866 - app.coordination.unified_queue_populator - INFO - Loaded existing Elo for hexagonal_3p: 1500.5 (model: canonical_hexagonal_3p:gumbel_mcts:b800, games: 150)
2026-01-13 09:10:07,866 - app.coordination.unified_queue_populator - INFO - Loaded existing Elo for hexagonal_4p: 1532.6 (model: heuristic, games: 10)
2026-01-13 09:10:07,866 - app.coordination.unified_queue_populator - INFO - Loaded existing Elo for square19_2p: 1506.0 (model: canonical_square19_2p:gumbel_mcts:b800, games: 50)
2026-01-13 09:10:07,866 - app.coordination.unified_queue_populator - INFO - Loaded existing Elo for square19_3p: 1500.0 (model: ringrift_best_square19_3p, games: 0)
2026-01-13 09:10:07,866 - app.coordination.unified_queue_populator - INFO - Loaded existing Elo for square19_3p: 1500.0 (model: canonical_square19_3p:gumbel_mcts:b800, games: 50)
2026-01-13 09:10:07,866 - app.coordination.unified_queue_populator - INFO - Loaded existing Elo for square19_4p: 1500.0 (model: ringrift_best_square19_4p, games: 0)
2026-01-13 09:10:07,866 - app.coordination.unified_queue_populator - INFO - Loaded existing Elo for square8_2p: 1502.0 (model: canonical_square8_2p:gumbel_mcts:b800, games: 50)
2026-01-13 09:10:07,866 - app.coordination.unified_queue_populator - INFO - Loaded existing Elo for square8_3p: 1590.0 (model: ringrift_best_square8_3p, games: 10)
2026-01-13 09:10:07,866 - app.coordination.unified_queue_populator - INFO - Loaded existing Elo for square8_4p: 1619.6 (model: ringrift_best_square8_4p, games: 20)
2026-01-13 09:10:07,866 - app.coordination.unified_queue_populator - INFO - Loaded Elo data: 0/12 configs at target (2000.0+ Elo)
2026-01-13 09:10:07,867 - app.coordination.unified_queue_populator - INFO - [QueuePopulator] Loaded curriculum weights
2026-01-13 09:10:08,134 - app.coordination.unified_queue_populator - INFO - [QueuePopulator] Loaded game counts from canonical DBs: 24,157 total across 12 configs
2026-01-13 09:10:08,134 - app.coordination.unified_queue_populator - WARNING - [QueuePopulator] Low game count configs (starvation candidates): hexagonal_3p:1, square19_2p:2, square19_3p:2, hexagonal_2p:2, hexagonal_4p:2
2026-01-13 09:10:08,135 - app.coordination.unified_queue_populator - INFO - [QueuePopulator] SelfplayScheduler integration enabled
2026-01-13 09:10:08,135 - scripts.p2p.loops.queue_populator_loop - INFO - [queue_populator] QueuePopulator initialized
2026-01-13 09:10:08,307 - scripts.p2p.loops.data_loops - INFO - [data_management] Disk at 83.2% (warning: 70.0%), triggering cleanup
2026-01-13 09:10:08,308 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:10:09,009 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:10:10,034 - scripts.p2p.loops.job_loops - INFO - Worker pull loop started
2026-01-13 09:10:10,793 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:10:10 -0600] "GET /health HTTP/1.1" 200 737 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:10:13,360 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 192-222-57-184 at 100.77.186.124:8770
2026-01-13 09:10:14,196 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 192-222-58-171 at 100.83.177.16:8770
2026-01-13 09:10:15,275 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:10:15 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:10:15,291 - aiohttp.access - INFO - fd7a:115c:a1e0::1d01:1390 [13/Jan/2026:09:10:10 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:10:15,299 - scripts.p2p.loops.queue_populator_loop - WARNING - [queue_populator] FOLLOWER TAKEOVER: Leader unreachable for 49s, populating queue
2026-01-13 09:10:16,530 - scripts.p2p.managers.work_discovery_manager - INFO - [WorkDiscovery] MacBook MacBook-Pro-5.local matched mac-studio config, selfplay_enabled=false - disabling direct selfplay
2026-01-13 09:10:16,531 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:10:10 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:10:16,938 - p2p_orchestrator - WARNING - [VoterHealth] Voter vultr-a100-20gb went OFFLINE (3/8 alive, quorum=3)
2026-01-13 09:10:16,938 - p2p_orchestrator - INFO - [VoterHealth] Voter hetzner-cpu1 came ONLINE (3/8 alive, quorum=3)
2026-01-13 09:10:16,938 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:10:16,939 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:10:10 -0600] "GET /status HTTP/1.1" 200 52942 "-" "curl/8.7.1"
2026-01-13 09:10:17,289 - app.coordination.unified_queue_populator - INFO - [QueuePopulator] Worker capacity limit: 100 -> 50 (capacity=50)
2026-01-13 09:10:17,309 - app.coordination.work_queue - INFO -  Added work selfplay_square8_2p_1768317017290: selfplay (priority: 50)
2026-01-13 09:10:17,319 - app.coordination.work_queue - INFO -  Added work selfplay_square8_3p_1768317017310: selfplay (priority: 50)
2026-01-13 09:10:17,327 - app.coordination.work_queue - INFO -  Added work selfplay_square8_4p_1768317017319: selfplay (priority: 50)
2026-01-13 09:10:17,343 - app.coordination.work_queue - INFO -  Added work selfplay_square19_2p_1768317017327: selfplay (priority: 50)
2026-01-13 09:10:17,353 - app.coordination.work_queue - INFO -  Added work selfplay_square19_3p_1768317017344: selfplay (priority: 50)
2026-01-13 09:10:17,361 - app.coordination.work_queue - INFO -  Added work selfplay_square19_4p_1768317017354: selfplay (priority: 50)
2026-01-13 09:10:17,378 - app.coordination.work_queue - INFO -  Added work selfplay_hex8_2p_1768317017362: selfplay (priority: 50)
2026-01-13 09:10:17,389 - app.coordination.work_queue - INFO -  Added work selfplay_hex8_3p_1768317017379: selfplay (priority: 50)
2026-01-13 09:10:17,397 - app.coordination.work_queue - INFO -  Added work selfplay_hex8_4p_1768317017389: selfplay (priority: 50)
2026-01-13 09:10:17,405 - app.coordination.work_queue - INFO -  Added work selfplay_hexagonal_2p_1768317017397: selfplay (priority: 50)
2026-01-13 09:10:17,425 - app.coordination.work_queue - INFO -  Added work selfplay_hexagonal_3p_1768317017413: selfplay (priority: 50)
2026-01-13 09:10:17,433 - app.coordination.work_queue - INFO -  Added work selfplay_hexagonal_4p_1768317017426: selfplay (priority: 50)
2026-01-13 09:10:17,441 - app.coordination.work_queue - INFO -  Added work selfplay_square8_2p_1768317017434: selfplay (priority: 50)
2026-01-13 09:10:17,457 - app.coordination.work_queue - INFO -  Added work selfplay_square8_3p_1768317017441: selfplay (priority: 50)
2026-01-13 09:10:17,467 - app.coordination.work_queue - INFO -  Added work selfplay_square8_4p_1768317017458: selfplay (priority: 50)
2026-01-13 09:10:17,475 - app.coordination.work_queue - INFO -  Added work selfplay_square19_2p_1768317017468: selfplay (priority: 50)
2026-01-13 09:10:17,483 - app.coordination.work_queue - INFO -  Added work selfplay_square19_3p_1768317017476: selfplay (priority: 50)
2026-01-13 09:10:17,501 - app.coordination.work_queue - INFO -  Added work selfplay_square19_4p_1768317017492: selfplay (priority: 50)
2026-01-13 09:10:17,509 - app.coordination.work_queue - INFO -  Added work selfplay_hex8_2p_1768317017502: selfplay (priority: 50)
2026-01-13 09:10:17,519 - app.coordination.work_queue - INFO -  Added work selfplay_hex8_3p_1768317017510: selfplay (priority: 50)
2026-01-13 09:10:17,527 - app.coordination.work_queue - INFO -  Added work selfplay_hex8_4p_1768317017519: selfplay (priority: 50)
2026-01-13 09:10:17,547 - app.coordination.work_queue - INFO -  Added work selfplay_hexagonal_2p_1768317017537: selfplay (priority: 50)
2026-01-13 09:10:17,554 - app.coordination.work_queue - INFO -  Added work selfplay_hexagonal_3p_1768317017547: selfplay (priority: 50)
2026-01-13 09:10:17,560 - app.coordination.work_queue - INFO -  Added work selfplay_hexagonal_4p_1768317017554: selfplay (priority: 50)
2026-01-13 09:10:17,567 - app.coordination.work_queue - INFO -  Added work selfplay_square8_2p_1768317017560: selfplay (priority: 50)
2026-01-13 09:10:17,576 - app.distributed.storage_provider - INFO - Storage provider initialized: local
2026-01-13 09:10:19,517 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:10:19,518 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:10:16 -0600] "GET /status HTTP/1.1" 200 52955 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:10:21,083 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:10:21,085 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:10:16 -0600] "GET /status HTTP/1.1" 200 52954 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:10:21,977 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:10:21 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:10:23,809 - scripts.p2p.loops.resilience_loops - INFO - Self-healing loop started
Metrics Report: {'timestamp': 1768317026.9645162, 'node_id': '0.0.0.0:7947', 'metrics': {'node_event': {'events': {'start': 1}}}}
2026-01-13 09:10:27,005 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:10:26 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:10:27,005 - p2p_orchestrator - INFO - [P2P] Fetched 3 game counts from fallback MacBook-Pro-5
2026-01-13 09:10:27,064 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:10:27 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:10:32,996 - scripts.p2p.loops.job_loops - INFO - [JobReassignment] Initial delay complete, starting checks
2026-01-13 09:10:35,477 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:10:34 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:10:35,478 - scripts.p2p.loops.job_loops - INFO - Work queue maintenance loop started
2026-01-13 09:10:36,436 - aiohttp.access - INFO - fd7a:115c:a1e0::4f01:ae13 [13/Jan/2026:09:10:35 -0600] "POST /gossip HTTP/1.1" 200 5878 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:10:36,962 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:10:36,965 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:10:36 -0600] "GET /status HTTP/1.1" 200 50247 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:10:37,562 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:10:37,566 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:10:36 -0600] "GET /status HTTP/1.1" 200 50249 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:10:37,567 - scripts.p2p.loops.network_loops - INFO - [TailscalePeerDiscovery] Mode transition: bootstrap -> maintenance (peers=6, threshold=5)
2026-01-13 09:10:38,103 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:10:38,109 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:10:36 -0600] "GET /status HTTP/1.1" 200 50250 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:10:39,279 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:10:38 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:10:39,282 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:10:39 -0600] "GET /health HTTP/1.1" 200 355 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:10:39,425 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:10:39 -0600] "GET /health HTTP/1.1" 200 753 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:10:40,496 - p2p_orchestrator - INFO - [RelayHealthCheck] Relay MacBook-Pro-5 unhealthy for lambda-gh200-2, switching to hetzner-cpu1
2026-01-13 09:10:40,496 - p2p_orchestrator - INFO - [RelayHealthCheck] Relay MacBook-Pro-5 unhealthy for lambda-gh200-1, switching to hetzner-cpu1
2026-01-13 09:10:41,429 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:10:41 -0600] "GET /health HTTP/1.1" 200 753 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:10:44,609 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: local-mac at 127.0.0.1:8770
2026-01-13 09:10:45,478 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: nebius-h100-1 at 127.0.0.1:8770
2026-01-13 09:10:46,394 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: d6928e099d99 at 127.0.0.1:8770
2026-01-13 09:10:47,350 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: MacBook-Pro-2.local at 127.0.0.1:8770
2026-01-13 09:10:48,330 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: computeinstance-e00gyg7x6xhkc7fs5x at 127.0.0.1:8770
2026-01-13 09:10:49,313 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: ringrift-cpu1 at 100.94.174.19:8770
2026-01-13 09:10:50,213 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: computeinstance-e00hcbnn7s7p0c7bbp at 127.0.0.1:8770
2026-01-13 09:10:51,124 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: b148b1697229 at 127.0.0.1:8770
2026-01-13 09:10:52,073 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: vast-29031159 at 127.0.0.1:8770
2026-01-13 09:10:52,991 - swim.transport.tcp - ERROR - Failed to establish connection to 100.109.195.71:7947: [Errno 60] Connect call failed ('100.109.195.71', 7947)
2026-01-13 09:10:52,991 - swim.transport.tcp - ERROR - Failed to send data to ('100.109.195.71', 7947): [Errno 60] Connect call failed ('100.109.195.71', 7947)
2026-01-13 09:10:52,992 - swim.protocol.disseminator - ERROR - [b7881138] Error sending heartbeat to 100.109.195.71:7947: [Errno 60] Connect call failed ('100.109.195.71', 7947)
2026-01-13 09:10:53,950 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:10:43 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:10:53,987 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:10:52 -0600] "GET /game_counts HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:10:53,988 - swim.transport.tcp - ERROR - Failed to establish connection to 100.67.131.72:7947: [Errno 61] Connect call failed ('100.67.131.72', 7947)
2026-01-13 09:10:53,989 - swim.transport.tcp - ERROR - Connection refused to 100.67.131.72:7947
2026-01-13 09:10:55,015 - p2p_orchestrator - INFO - LOCAL: Disk at 83% - skipping job starts
2026-01-13 09:10:55,015 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:10:55,733 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:10:57,705 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:10:53 -0600] "POST /heartbeat HTTP/1.1" 200 1951 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:10:57,706 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:10:53 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:10:57,708 - swim.protocol.sync - ERROR - [390c728a] Error sending incremental sync request to 100.67.131.72:7947: [Errno 61] Connect call failed ('100.67.131.72', 7947)
2026-01-13 09:10:57,853 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:10:53 -0600] "GET /game_counts HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:10:58,751 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:10:57 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:10:59,781 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:10:57 -0600] "POST /heartbeat HTTP/1.1" 200 1952 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:00,733 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:10:57 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:01,604 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:10:57 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:02,532 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:10:57 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:03,447 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:10:57 -0600] "POST /heartbeat HTTP/1.1" 200 1944 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:04,333 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:10:57 -0600] "POST /heartbeat HTTP/1.1" 200 1943 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:05,305 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:10:57 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:05,318 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:11:05 -0600] "GET /health HTTP/1.1" 200 355 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:06,149 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:11:05 -0600] "GET /api/cluster/status HTTP/1.1" 200 19068 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:06,150 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:11:05 -0600] "POST /election/start HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:06,232 - p2p_orchestrator - WARNING - Isolated: only 4 alive peers (need 5), attempting bootstrap...
2026-01-13 09:11:06,280 - swim.protocol.sync - INFO - [7e3bd633] Performing full sync with 2 members
2026-01-13 09:11:06,320 - scripts.p2p.loops.http_server_health_loop - WARNING - [http_server_health] Health probe failed (consecutive: 1/4)
2026-01-13 09:11:06,321 - swim.transport.tcp - ERROR - Failed to send data to ('100.126.21.102', 7947): Connection lost
2026-01-13 09:11:06,321 - swim.protocol.sync - ERROR - [7e3bd633] Error sending full sync request to 100.126.21.102:7947: Connection lost
2026-01-13 09:11:07,176 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:11:06 -0600] "POST /heartbeat HTTP/1.1" 200 1944 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:11:07,178 - swim.protocol.failure_detector - WARNING - [889e204c] TIMEOUT waiting for PONG from 100.126.21.102:7947 (attempt 1/3)
2026-01-13 09:11:07,179 - swim.transport.tcp - ERROR - Failed to send data to ('100.126.21.102', 7947): [Errno 32] Broken pipe
2026-01-13 09:11:07,179 - swim.protocol.failure_detector - ERROR - [889e204c] Error pinging 100.126.21.102:7947: [Errno 32] Broken pipe
2026-01-13 09:11:07,179 - swim.transport.tcp - ERROR - Failed to send data to ('100.126.21.102', 7947): [Errno 32] Broken pipe
2026-01-13 09:11:07,179 - swim.protocol.failure_detector - ERROR - [889e204c] Error pinging 100.126.21.102:7947: [Errno 32] Broken pipe
2026-01-13 09:11:07,180 - swim.protocol.failure_detector - WARNING - [889e204c] All ping attempts failed to 100.126.21.102:7947, marking as SUSPECT
2026-01-13 09:11:07,199 - swim.protocol.member - INFO - STATE CHANGE: Member 100.126.21.102:7947 transitioned from ALIVE to SUSPECT (inc=2)
2026-01-13 09:11:07,206 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:11:07,207 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:11:07,207 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:11:07,210 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:11:07 -0600] "GET /health HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:07,211 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:11:07 -0600] "GET /peers HTTP/1.1" 404 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:07,212 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:11:07 -0600] "GET /health HTTP/1.1" 200 736 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:09,462 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:11:09,464 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:11:05 -0600] "GET /status HTTP/1.1" 200 46584 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:09,756 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:11:09,757 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:11:05 -0600] "GET /status HTTP/1.1" 200 46584 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:10,052 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:11:10,054 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:11:05 -0600] "GET /status HTTP/1.1" 200 46584 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:10,102 - scripts.p2p.loops.resilience_loops - INFO - Predictive monitoring loop started
2026-01-13 09:11:10,207 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:11:07 -0600] "POST /gossip HTTP/1.1" 200 5826 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:11,083 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:11:10 -0600] "POST /heartbeat HTTP/1.1" 200 1945 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:12,028 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:11:10 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:12,890 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:11:10 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:13,756 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:11:10 -0600] "POST /heartbeat HTTP/1.1" 200 1955 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:14,665 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:11:10 -0600] "POST /heartbeat HTTP/1.1" 200 1945 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:15,564 - aiohttp.access - INFO - fd7a:115c:a1e0::2e01:d06c [13/Jan/2026:09:11:07 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:15,658 - p2p_orchestrator - INFO - Bootstrap from 100.67.131.72:8770: imported 10 peers
2026-01-13 09:11:15,671 - p2p_orchestrator - INFO - Leader established (hetzner-cpu2), stopping election retry task
2026-01-13 09:11:15,822 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:11:15 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:11:16,824 - scripts.p2p.loops.autonomous_queue_loop - WARNING - [AutonomousQueue] ACTIVATED: queue_starved_for_34s (depth=0) (no_leader_duration=0s)
2026-01-13 09:11:16,824 - app.coordination.event_emission_helpers - INFO - [AutonomousQueue] Autonomous queue activated: queue_starvation
2026-01-13 09:11:16,826 - p2p_orchestrator - INFO - Bootstrap successful! Now have 5 alive peers
2026-01-13 09:11:16,831 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:11:16,835 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:11:16,838 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:11:16,842 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:11:16,845 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:11:17,747 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:11:17,747 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:11:18,556 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:11:17 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:11:18,557 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:11:16 -0600] "GET /relay/peers HTTP/1.1" 200 40272 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:18,567 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:11:18,568 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:11:18,568 - swim.protocol.sync - ERROR - [416643a1] Error sending incremental sync request to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:11:18,569 - swim.protocol.disseminator - ERROR - [a77d0984] Error sending heartbeat to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:11:19,474 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-bebb33ec: selfplay (source: autonomous)
2026-01-13 09:11:19,474 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-bebb33ec: selfplay_enabled=false for this node
2026-01-13 09:11:19,476 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:11:19 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:19,477 - scripts.p2p.loops.http_server_health_loop - INFO - [http_server_health] HTTP server recovered after 1 failures
2026-01-13 09:11:21,784 - p2p_orchestrator - INFO - [VoterHealth] Voter mac-studio came ONLINE (6/8 alive, quorum=3)
2026-01-13 09:11:21,784 - p2p_orchestrator - INFO - [VoterHealth] Voter hetzner-cpu3 came ONLINE (6/8 alive, quorum=3)
2026-01-13 09:11:21,784 - p2p_orchestrator - INFO - [VoterHealth] Voter hetzner-cpu2 came ONLINE (6/8 alive, quorum=3)
2026-01-13 09:11:21,784 - p2p_orchestrator - WARNING - [VoterHealth] Status: 6/8 voters alive, quorum=OK, offline: ['vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:11:21,786 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:11:21 -0600] "GET /status HTTP/1.1" 200 50265 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:11:22,093 - p2p_orchestrator - WARNING - [VoterHealth] Status: 6/8 voters alive, quorum=OK, offline: ['vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:11:22,095 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:11:21 -0600] "GET /status HTTP/1.1" 200 50261 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:11:26,407 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:11:26 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:11:26,695 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:11:26 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.11 aiohttp/3.12.14"
Metrics Report: {'timestamp': 1768317086.9921012, 'node_id': '0.0.0.0:7947', 'metrics': {'node_event': {'events': {'start': 1}}, 'ping_timeout': {'gauge': 0.5}, 'probe_result': {'counter': 2}, 'ping': {'events': {'failure': 1}}, 'peer_rtt': {'histogram': {'count': 1, 'min': 14.208169937133789, 'max': 14.208169937133789, 'mean': 14.208169937133789}}, 'timeout_adjustment': {'events': {'1.000->0.500': 1}}, 'member_count': {'gauge': 8}, 'protocol_cycle_duration': {'histogram': {'count': 1, 'min': 100.23378777503967, 'max': 100.23378777503967, 'mean': 100.23378777503967}}, 'protocol_period': {'gauge': 1.0}}}
2026-01-13 09:11:27,949 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:11:27 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:11:28,597 - p2p_orchestrator - INFO - Voter mesh incomplete, missing: ['vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:11:29,475 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-95920484: selfplay (source: autonomous)
2026-01-13 09:11:29,475 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-95920484: selfplay_enabled=false for this node
2026-01-13 09:11:29,479 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:11:29 -0600] "GET /health HTTP/1.1" 200 353 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:31,831 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:11:30 -0600] "POST /gossip HTTP/1.1" 200 5614 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:11:33,852 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:11:32 -0600] "POST /heartbeat HTTP/1.1" 200 1945 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:34,641 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 100.94.174.19:7947 at 100.94.174.19:8770
2026-01-13 09:11:35,548 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:11:33 -0600] "POST /gossip HTTP/1.1" 200 5681 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:11:36,085 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: hetzner-cpu1
2026-01-13 09:11:36,560 - scripts.p2p.loops.validation_loop - INFO - Validation loop started
2026-01-13 09:11:38,592 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:11:38 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:11:39,463 - scripts.p2p.loops.resilience_loops - INFO - Split-brain detection loop started
2026-01-13 09:11:39,840 - p2p_orchestrator - WARNING - [VoterHealth] Status: 6/8 voters alive, quorum=OK, offline: ['vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:11:39,842 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:11:39 -0600] "GET /status HTTP/1.1" 200 51810 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:39,845 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:11:39 -0600] "GET /health HTTP/1.1" 200 355 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:40,145 - p2p_orchestrator - WARNING - [VoterHealth] Status: 6/8 voters alive, quorum=OK, offline: ['vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:11:40,146 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:11:39 -0600] "GET /status HTTP/1.1" 200 51809 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:40,146 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-8fa83392: selfplay (source: autonomous)
2026-01-13 09:11:40,147 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-8fa83392: selfplay_enabled=false for this node
2026-01-13 09:11:42,078 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:11:41 -0600] "POST /heartbeat HTTP/1.1" 200 1949 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:11:42,593 - p2p_orchestrator - WARNING - [VoterHealth] Status: 6/8 voters alive, quorum=OK, offline: ['vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:11:42,594 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:11:42 -0600] "GET /status HTTP/1.1" 200 51802 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:42,959 - p2p_orchestrator - WARNING - [VoterHealth] Status: 6/8 voters alive, quorum=OK, offline: ['vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:11:42,960 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:11:42 -0600] "GET /status HTTP/1.1" 200 51801 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:46,182 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:11:46 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:11:46,197 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:11:46 -0600] "GET /health HTTP/1.1" 200 753 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:11:47,045 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:11:46 -0600] "POST /heartbeat HTTP/1.1" 200 1946 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:11:48,586 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:11:48 -0600] "GET /health HTTP/1.1" 200 737 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:50,301 - p2p_orchestrator - WARNING - [VoterHealth] Status: 6/8 voters alive, quorum=OK, offline: ['vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:11:50,302 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:11:49 -0600] "GET /status HTTP/1.1" 200 51854 "-" "curl/8.7.1"
2026-01-13 09:11:50,304 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-60267ab6: selfplay (source: autonomous)
2026-01-13 09:11:50,305 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-60267ab6: selfplay_enabled=false for this node
2026-01-13 09:11:50,306 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:11:50 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:11:52,379 - p2p_orchestrator - INFO - LOCAL: Disk at 83% - skipping job starts
2026-01-13 09:11:52,380 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:11:53,018 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:11:53,018 - p2p_orchestrator - INFO - LOCAL: Memory at 92% - skipping GPU auto-scale
2026-01-13 09:11:55,432 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:11:54 -0600] "POST /heartbeat HTTP/1.1" 200 1945 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:11:55,437 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:11:55 -0600] "GET /health HTTP/1.1" 200 736 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:11:55,541 - p2p_orchestrator - WARNING - [VoterHealth] Status: 6/8 voters alive, quorum=OK, offline: ['vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:11:56,137 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:11:56 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:11:57,048 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:11:57 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:11:57,517 - app.coordination.work_queue - INFO -  Added work training_square8_2p_1768317117508: training (priority: 100)
2026-01-13 09:11:58,256 - aiohttp.access - INFO - fd7a:115c:a1e0::4f01:ae13 [13/Jan/2026:09:11:57 -0600] "POST /gossip HTTP/1.1" 200 5844 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:12:00,372 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-1e869e09: selfplay (source: autonomous)
2026-01-13 09:12:00,373 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-1e869e09: selfplay_enabled=false for this node
2026-01-13 09:12:00,375 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:12:00 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:00,738 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:12:00 -0600] "GET /health HTTP/1.1" 200 757 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:07,404 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:12:06 -0600] "GET /api/cluster/status HTTP/1.1" 200 19053 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:08,432 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:12:06 -0600] "GET /api/cluster/status HTTP/1.1" 200 19052 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:09,375 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:12:06 -0600] "GET /api/cluster/status HTTP/1.1" 200 19054 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:09,409 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:12:06 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:12:11,160 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:12:09 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:12:12,911 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:12:11 -0600] "GET /api/cluster/status HTTP/1.1" 200 19053 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:12:13,784 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:12:12 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:14,238 - p2p_orchestrator - WARNING - [VoterHealth] Voter lambda-gh200-training went OFFLINE (5/8 alive, quorum=3)
2026-01-13 09:12:14,239 - p2p_orchestrator - WARNING - [VoterHealth] Status: 5/8 voters alive, quorum=OK, offline: ['lambda-gh200-training', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:12:14,243 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:12:06 -0600] "GET /status HTTP/1.1" 200 51874 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:14,545 - p2p_orchestrator - WARNING - [VoterHealth] Status: 5/8 voters alive, quorum=OK, offline: ['lambda-gh200-training', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:12:14,547 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:12:06 -0600] "GET /status HTTP/1.1" 200 50161 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:15,582 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:12:14 -0600] "POST /heartbeat HTTP/1.1" 200 1943 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:16,710 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:12:15 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:17,615 - aiohttp.access - INFO - 100.71.89.91 [13/Jan/2026:09:12:15 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:18,552 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:12:15 -0600] "POST /heartbeat HTTP/1.1" 200 1945 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:18,555 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:12:18 -0600] "GET /health HTTP/1.1" 200 353 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:19,709 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 192-222-51-29 at 100.69.101.108:8770
2026-01-13 09:12:20,609 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 100.94.174.19:7947 at 100.94.174.19:8770
2026-01-13 09:12:22,396 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:12:19 -0600] "GET /api/cluster/status HTTP/1.1" 200 19053 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:12:23,402 - app.distributed.hybrid_transport - INFO - [Transport] nebius-backbone-1: Switching to SSH after 3 HTTP failures
2026-01-13 09:12:23,432 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:12:18 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:12:23,433 - p2p_orchestrator - INFO - Reconnected to dead peer lambda-gh200-2 (was dead for 152s)
2026-01-13 09:12:24,450 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:12:23 -0600] "GET /health HTTP/1.1" 200 757 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:12:24,451 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:12:23 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:12:24,453 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:12:23 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:12:24,454 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-2, invalidating cluster manifest
2026-01-13 09:12:24,454 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-2, node available for jobs
2026-01-13 09:12:26,313 - app.coordination.sync_router - INFO - [SyncRouter] Added new node: 100.110.143.119
2026-01-13 09:12:26,315 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 192-222-51-29 at 100.69.101.108:8770
Metrics Report: {'timestamp': 1768317146.996456, 'node_id': '0.0.0.0:7947', 'metrics': {'node_event': {'events': {'start': 1}}, 'ping_timeout': {'gauge': 0.5}, 'probe_result': {'counter': 2}, 'ping': {'events': {'failure': 1}}, 'peer_rtt': {'histogram': {'count': 1, 'min': 14.208169937133789, 'max': 14.208169937133789, 'mean': 14.208169937133789}}, 'timeout_adjustment': {'events': {'1.000->0.500': 1}}, 'member_count': {'gauge': 8}, 'protocol_cycle_duration': {'histogram': {'count': 1, 'min': 100.23378777503967, 'max': 100.23378777503967, 'mean': 100.23378777503967}}, 'protocol_period': {'gauge': 1.0}}}
2026-01-13 09:12:27,212 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 100.94.174.19:7947 at 100.94.174.19:8770
2026-01-13 09:12:28,153 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:12:23 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:12:28,155 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: 192-222-51-29
2026-01-13 09:12:28,403 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-331cce66: selfplay (source: autonomous)
2026-01-13 09:12:28,405 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-331cce66: selfplay_enabled=false for this node
2026-01-13 09:12:29,137 - p2p_orchestrator - WARNING - [VoterHealth] Voter mac-studio went OFFLINE (4/8 alive, quorum=3)
2026-01-13 09:12:29,138 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:12:29,141 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:12:28 -0600] "GET /status HTTP/1.1" 200 53947 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:12:29,494 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:12:29,496 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:12:28 -0600] "GET /status HTTP/1.1" 200 53948 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:12:29,641 - p2p_orchestrator - INFO - Reconnected to dead peer lambda-gh200-8 (was dead for 266s)
2026-01-13 09:12:30,693 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-8, invalidating cluster manifest
2026-01-13 09:12:30,694 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-8, node available for jobs
2026-01-13 09:12:30,694 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: 192-222-51-29
2026-01-13 09:12:30,701 - app.coordination.sync_router - INFO - [SyncRouter] Added new node: 100.121.230.110
2026-01-13 09:12:30,743 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:12:30 -0600] "GET /health HTTP/1.1" 200 747 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:31,649 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:12:31 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:12:33,102 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:12:33,104 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:12:32 -0600] "GET /status HTTP/1.1" 200 55791 "-" "curl/8.7.1"
2026-01-13 09:12:33,271 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:12:33 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:33,570 - swim.transport.tcp - ERROR - Failed to establish connection to 100.109.195.71:7947: [Errno 60] Connect call failed ('100.109.195.71', 7947)
2026-01-13 09:12:33,570 - swim.transport.tcp - ERROR - Failed to send data to ('100.109.195.71', 7947): [Errno 60] Connect call failed ('100.109.195.71', 7947)
2026-01-13 09:12:33,570 - swim.protocol.disseminator - ERROR - [a77d0984] Error sending heartbeat to 100.109.195.71:7947: [Errno 60] Connect call failed ('100.109.195.71', 7947)
2026-01-13 09:12:33,571 - swim.protocol.node - INFO - Checking 1 suspect members
2026-01-13 09:12:33,571 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.126.21.102:7947: 15.00s (base: 5.00s)
2026-01-13 09:12:33,572 - swim.protocol.node - WARNING - Suspect timeout expired for 100.126.21.102:7947, marking as DEAD
2026-01-13 09:12:33,572 - swim.protocol.member - INFO - STATE CHANGE: Member 100.126.21.102:7947 transitioned from SUSPECT to DEAD (inc=3)
2026-01-13 09:12:33,572 - swim.transport.tcp - ERROR - Failed to send data to ('100.126.21.102', 7947): [Errno 32] Broken pipe
2026-01-13 09:12:33,573 - swim.protocol.sync - ERROR - [3f7d09a7] Error sending incremental sync request to 100.126.21.102:7947: [Errno 32] Broken pipe
2026-01-13 09:12:35,382 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:12:35 -0600] "GET /health HTTP/1.1" 200 355 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:36,575 - swim.protocol.sync - INFO - [d5641a98] Performing full sync with 2 members
2026-01-13 09:12:38,410 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-909d4b31: selfplay (source: autonomous)
2026-01-13 09:12:38,410 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-909d4b31: selfplay_enabled=false for this node
2026-01-13 09:12:41,381 - aiohttp.access - INFO - 100.67.131.72 [13/Jan/2026:09:12:41 -0600] "GET /health HTTP/1.1" 200 757 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:43,228 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:12:43,239 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:12:41 -0600] "GET /status HTTP/1.1" 200 55857 "-" "curl/8.7.1"
2026-01-13 09:12:45,245 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:12:45,248 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:12:44 -0600] "GET /status HTTP/1.1" 200 54119 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:45,688 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:12:45,690 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:12:45 -0600] "GET /status HTTP/1.1" 200 54121 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:45,701 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:12:45 -0600] "GET /health HTTP/1.1" 200 355 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:12:48,413 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-0a2ae6a7: selfplay (source: autonomous)
2026-01-13 09:12:48,414 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-0a2ae6a7: selfplay_enabled=false for this node
2026-01-13 09:12:49,856 - p2p_orchestrator - INFO - LOCAL: Disk at 83% - skipping job starts
2026-01-13 09:12:49,856 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:12:50,983 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:12:53,563 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:12:52 -0600] "POST /heartbeat HTTP/1.1" 200 1955 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:12:54,585 - p2p_orchestrator - INFO - Reconnected to dead peer 192-222-57-210 (was dead for 415s)
2026-01-13 09:12:56,093 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 192-222-57-210, invalidating cluster manifest
2026-01-13 09:12:56,093 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 192-222-57-210, node available for jobs
2026-01-13 09:12:56,094 - app.coordination.sync_router - INFO - [SyncRouter] Added new node: 100.71.89.91
2026-01-13 09:12:57,362 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 192-222-57-184 at 100.77.186.124:8770
2026-01-13 09:12:58,532 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 192-222-58-171 at 100.83.177.16:8770
2026-01-13 09:12:59,639 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: local-mac at 127.0.0.1:8770
2026-01-13 09:13:01,288 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: nebius-h100-1 at 127.0.0.1:8770
2026-01-13 09:13:02,626 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: d6928e099d99 at 127.0.0.1:8770
2026-01-13 09:13:03,617 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: MacBook-Pro-2.local at 127.0.0.1:8770
2026-01-13 09:13:04,667 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: computeinstance-e00gyg7x6xhkc7fs5x at 127.0.0.1:8770
2026-01-13 09:13:05,990 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 100.94.174.19:7947 at 100.94.174.19:8770
2026-01-13 09:13:07,426 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:13:07 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:07,440 - scripts.p2p.loops.http_server_health_loop - WARNING - [http_server_health] Health probe failed (consecutive: 1/4)
2026-01-13 09:13:07,442 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:12:56 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:13:07,446 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:13:07 -0600] "GET /health HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:13:07,447 - p2p_orchestrator - INFO - First-contact peer registered: 192-222-57-184 (caps: ['selfplay', 'training', 'cmaes', 'large_boards'])
2026-01-13 09:13:08,589 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:13:07 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:08,592 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 192-222-57-184, invalidating cluster manifest
2026-01-13 09:13:08,592 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 192-222-57-184, node available for jobs
2026-01-13 09:13:08,608 - app.coordination.sync_router - INFO - [SyncRouter] Added new node: 100.77.186.124
2026-01-13 09:13:10,171 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:13:08 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:12,069 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:13:08 -0600] "POST /heartbeat HTTP/1.1" 200 1951 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:13,271 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:13:08 -0600] "POST /heartbeat HTTP/1.1" 200 1945 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:13,296 - p2p_orchestrator - INFO - Reconnected to dead peer 192-222-57-140 (was dead for 436s)
2026-01-13 09:13:14,460 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: 192-222-57-184
2026-01-13 09:13:14,466 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: 192-222-58-171
2026-01-13 09:13:15,599 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:13:13 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:17,240 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:13:13 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:17,244 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 192-222-57-140, invalidating cluster manifest
2026-01-13 09:13:17,244 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 192-222-57-140, node available for jobs
2026-01-13 09:13:19,712 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-20dad26d: selfplay (source: autonomous)
2026-01-13 09:13:19,713 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-20dad26d: selfplay_enabled=false for this node
2026-01-13 09:13:20,908 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:13:19 -0600] "POST /heartbeat HTTP/1.1" 200 1955 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:20,918 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:13:20,922 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:13:22,463 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:13:20 -0600] "POST /heartbeat HTTP/1.1" 200 1955 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:13:25,254 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:13:23 -0600] "POST /heartbeat HTTP/1.1" 200 1944 "-" "Python/3.10 aiohttp/3.13.2"
Metrics Report: {'timestamp': 1768317207.000631, 'node_id': '0.0.0.0:7947', 'metrics': {'node_event': {'events': {'start': 1}}, 'ping_timeout': {'gauge': 0.5}, 'probe_result': {'counter': 2}, 'ping': {'events': {'failure': 1}}, 'peer_rtt': {'histogram': {'count': 1, 'min': 14.208169937133789, 'max': 14.208169937133789, 'mean': 14.208169937133789}}, 'timeout_adjustment': {'events': {'1.000->0.500': 1}}, 'member_count': {'gauge': 8}, 'protocol_cycle_duration': {'histogram': {'count': 1, 'min': 100.23378777503967, 'max': 100.23378777503967, 'mean': 100.23378777503967}}, 'protocol_period': {'gauge': 1.0}, 'suspect_timeout': {'gauge': 15.0, 'events': {'100.126.21.102:7947': 1}}}}
2026-01-13 09:13:27,203 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:13:23 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:27,205 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:13:20 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:27,475 - p2p_orchestrator - INFO - [RelayHealthCheck] Relay hetzner-cpu1 unhealthy for lambda-gh200-2, switching to hetzner-cpu3
2026-01-13 09:13:27,475 - p2p_orchestrator - INFO - [RelayHealthCheck] Relay hetzner-cpu1 unhealthy for lambda-gh200-1, switching to hetzner-cpu3
2026-01-13 09:13:27,475 - p2p_orchestrator - INFO - [RelayHealthCheck] Relay 192-222-51-195 unhealthy for test, switching to hetzner-cpu3
2026-01-13 09:13:27,478 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:13:20 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:13:27,478 - p2p_orchestrator - INFO - Reconnected to dead peer lambda-gh200-10 (was dead for 346s)
2026-01-13 09:13:28,853 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:13:28,857 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-10, invalidating cluster manifest
2026-01-13 09:13:28,858 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-10, node available for jobs
2026-01-13 09:13:28,860 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:13:28 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:28,862 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:13:28 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:13:28,914 - aiohttp.access - INFO - 100.71.89.91 [13/Jan/2026:09:13:28 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:28,916 - app.coordination.sync_router - INFO - [SyncRouter] Added new node: 100.100.19.96
2026-01-13 09:13:29,964 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:13:29,970 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: MacBook-Pro-5
2026-01-13 09:13:29,972 - scripts.p2p.loops.http_server_health_loop - WARNING - [http_server_health] Health probe failed (consecutive: 2/4)
2026-01-13 09:13:30,038 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:13:29 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:31,648 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:13:30 -0600] "GET /api/cluster/status HTTP/1.1" 200 21156 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:13:31,650 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:13:31 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:31,672 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:13:31 -0600] "GET /health HTTP/1.1" 200 757 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:31,674 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:13:29 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:13:31,675 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:13:29 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:13:31,682 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-af6be39b: selfplay (source: autonomous)
2026-01-13 09:13:31,683 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-af6be39b: selfplay_enabled=false for this node
2026-01-13 09:13:32,560 - p2p_orchestrator - WARNING - [VoterHealth] Voter hetzner-cpu1 went OFFLINE (2/8 alive, quorum=3)
2026-01-13 09:13:32,563 - p2p_orchestrator - WARNING - [VoterHealth] Voter hetzner-cpu2 went OFFLINE (2/8 alive, quorum=3)
2026-01-13 09:13:32,563 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:13:32,568 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:13:28 -0600] "GET /status HTTP/1.1" 200 60477 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:13:34,343 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:13:32 -0600] "GET /api/cluster/status HTTP/1.1" 200 21157 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:13:34,370 - p2p_orchestrator - INFO - Reconnected to dead peer 192-222-51-195 (was dead for 342s)
2026-01-13 09:13:36,150 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 192-222-51-195, invalidating cluster manifest
2026-01-13 09:13:36,151 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 192-222-51-195, node available for jobs
2026-01-13 09:13:36,152 - app.coordination.sync_router - INFO - [SyncRouter] Added new node: 100.68.208.43
2026-01-13 09:13:38,314 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:13:36 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:39,696 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:13:38 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:40,597 - p2p_orchestrator - INFO - [VoterHealth] Voter lambda-gh200-training came ONLINE (3/8 alive, quorum=3)
2026-01-13 09:13:40,598 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:13:40,601 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:13:36 -0600] "GET /status HTTP/1.1" 200 62259 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:13:41,203 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:13:41,206 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:13:36 -0600] "GET /status HTTP/1.1" 200 62260 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:13:41,265 - p2p_orchestrator - INFO - Reconnected to dead peer MacBook-Pro-2 (was dead for 524s)
2026-01-13 09:13:43,241 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: MacBook-Pro-2, invalidating cluster manifest
2026-01-13 09:13:43,242 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: MacBook-Pro-2, node available for jobs
2026-01-13 09:13:43,243 - app.coordination.sync_router - INFO - [SyncRouter] Added new node: 100.69.164.58
2026-01-13 09:13:43,506 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:13:43 -0600] "GET /health HTTP/1.1" 200 745 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:13:43,506 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:13:43 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:13:44,958 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-902319b3: selfplay (source: autonomous)
2026-01-13 09:13:44,958 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-902319b3: selfplay_enabled=false for this node
2026-01-13 09:13:46,259 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:13:46 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:46,873 - p2p_orchestrator - WARNING - [VoterHealth] Voter hetzner-cpu3 went OFFLINE (2/8 alive, quorum=3)
2026-01-13 09:13:46,874 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:13:46,875 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:13:43 -0600] "GET /status HTTP/1.1" 200 64044 "-" "curl/8.7.1"
2026-01-13 09:13:46,878 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:13:44 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:46,880 - aiohttp.access - INFO - 100.83.177.16 [13/Jan/2026:09:13:44 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:46,883 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:13:44 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:46,887 - scripts.p2p.loops.http_server_health_loop - INFO - [http_server_health] HTTP server recovered after 2 failures
2026-01-13 09:13:49,476 - swim.transport.tcp - ERROR - Failed to establish connection to 100.109.195.71:7947: [Errno 60] Connect call failed ('100.109.195.71', 7947)
2026-01-13 09:13:49,477 - swim.transport.tcp - ERROR - Failed to send data to ('100.109.195.71', 7947): [Errno 60] Connect call failed ('100.109.195.71', 7947)
2026-01-13 09:13:49,477 - swim.protocol.failure_detector - ERROR - [896aac12] Error pinging 100.109.195.71:7947: [Errno 60] Connect call failed ('100.109.195.71', 7947)
2026-01-13 09:13:49,484 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:13:49 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:49,518 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:13:49,518 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:13:51,178 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:13:51 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:51,588 - aiohttp.access - INFO - 100.83.177.16 [13/Jan/2026:09:13:51 -0600] "GET /health HTTP/1.1" 200 731 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:51,589 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:13:51 -0600] "GET /health HTTP/1.1" 200 731 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:52,094 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:13:52 -0600] "GET /health HTTP/1.1" 200 730 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:55,259 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:13:55,322 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:13:53 -0600] "GET /status HTTP/1.1" 200 60584 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:55,324 - aiohttp.access - INFO - 100.106.87.89 [13/Jan/2026:09:13:53 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:56,924 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:13:56,928 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:13:53 -0600] "GET /status HTTP/1.1" 200 60583 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:58,848 - aiohttp.access - INFO - 100.83.177.16 [13/Jan/2026:09:13:56 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:59,045 - aiohttp.access - INFO - 100.83.177.16 [13/Jan/2026:09:13:59 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:13:59,052 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-6d0759bb: selfplay (source: autonomous)
2026-01-13 09:13:59,052 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-6d0759bb: selfplay_enabled=false for this node
2026-01-13 09:13:59,053 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:13:59 -0600] "GET /health HTTP/1.1" 200 355 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:14:02,294 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:14:00 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:14:03,654 - p2p_orchestrator - INFO - LOCAL: Disk at 83% - skipping job starts
2026-01-13 09:14:03,654 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:14:05,765 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:14:05,766 - p2p_orchestrator - INFO - LOCAL: Memory at 95% - skipping GPU auto-scale
2026-01-13 09:14:07,265 - app.distributed.hybrid_transport - INFO - [Transport] mac-studio: Switching to SSH after 3 HTTP failures
2026-01-13 09:14:07,273 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:14:07 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:14:07,841 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:14:07 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:14:10,774 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:14:08 -0600] "POST /heartbeat HTTP/1.1" 200 1952 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:14:10,800 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-b15f9831: selfplay (source: autonomous)
2026-01-13 09:14:10,805 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-b15f9831: selfplay_enabled=false for this node
2026-01-13 09:14:10,816 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:14:10 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:14:14,984 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:14:13 -0600] "POST /heartbeat HTTP/1.1" 200 1955 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:14:20,809 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-3c72cda8: selfplay (source: autonomous)
2026-01-13 09:14:20,809 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-3c72cda8: selfplay_enabled=false for this node
2026-01-13 09:14:20,825 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:14:20 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:14:20,831 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:14:20 -0600] "GET /health HTTP/1.1" 200 753 "-" "Python/3.11 aiohttp/3.12.14"
Metrics Report: {'timestamp': 1768317267.005007, 'node_id': '0.0.0.0:7947', 'metrics': {'node_event': {'events': {'start': 1}}, 'ping_timeout': {'gauge': 0.5}, 'probe_result': {'counter': 2}, 'ping': {'events': {'failure': 1}}, 'peer_rtt': {'histogram': {'count': 1, 'min': 14.208169937133789, 'max': 14.208169937133789, 'mean': 14.208169937133789}}, 'timeout_adjustment': {'events': {'1.000->0.500': 1}}, 'member_count': {'gauge': 8}, 'protocol_cycle_duration': {'histogram': {'count': 1, 'min': 100.23378777503967, 'max': 100.23378777503967, 'mean': 100.23378777503967}}, 'protocol_period': {'gauge': 1.0}, 'suspect_timeout': {'gauge': 15.0, 'events': {'100.126.21.102:7947': 1}}}}
2026-01-13 09:14:27,488 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:14:27 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:14:30,039 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:14:30,043 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:14:27 -0600] "GET /status HTTP/1.1" 200 55130 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:14:32,760 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:14:30 -0600] "GET /relay/peers HTTP/1.1" 200 45090 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:14:32,761 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:14:32 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:14:33,979 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:14:33 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:14:33,982 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:14:33 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:14:33,982 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:14:33 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:14:35,231 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:14:33 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:14:36,918 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:14:35 -0600] "POST /heartbeat HTTP/1.1" 200 1952 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:14:36,919 - scripts.p2p.loops.peer_cleanup_loop - INFO - [PeerCleanup] Purged 1 stale peers (tier2: 1, tier3: 0). Health ratio: 100.0% → 100.0%
2026-01-13 09:14:36,919 - scripts.p2p.loops.gossip_state_cleanup_loop - INFO - [GossipStateCleanup] Purged 21 entries: states=0, manifests=0, recovery=0, reputation=0, endpoints=21, promotion=0, jobs=0
2026-01-13 09:14:37,224 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:14:37 -0600] "GET /health HTTP/1.1" 200 753 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:14:38,108 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:14:38 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:14:38,436 - scripts.p2p.loops.cluster_healing_loop - WARNING - [ClusterHealing] Failed to load hosts YAML: 'str' object has no attribute 'get'
2026-01-13 09:14:42,111 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:14:40 -0600] "POST /gossip HTTP/1.1" 200 5793 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:14:43,400 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:14:43,402 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:14:41 -0600] "GET /status HTTP/1.1" 200 54518 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:14:44,198 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:14:44,200 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:14:41 -0600] "GET /status HTTP/1.1" 200 54502 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:14:45,322 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:14:45 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:14:45,499 - p2p_orchestrator - INFO - [RelayHealthCheck] Relay hetzner-cpu3 unhealthy for lambda-gh200-2, switching to aws-staging
2026-01-13 09:14:45,499 - p2p_orchestrator - INFO - [RelayHealthCheck] Relay hetzner-cpu3 unhealthy for lambda-gh200-1, switching to aws-staging
2026-01-13 09:14:45,544 - app.coordination.work_queue - INFO -  Added work training_square8_3p_1768317285533: training (priority: 100)
2026-01-13 09:14:47,768 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:14:46 -0600] "POST /heartbeat HTTP/1.1" 200 1945 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:14:47,772 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:14:47 -0600] "GET /health HTTP/1.1" 200 735 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:14:48,282 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:14:48 -0600] "GET /health HTTP/1.1" 200 738 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:14:48,297 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:14:48 -0600] "GET /health HTTP/1.1" 200 738 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:14:49,870 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:14:49 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:14:54,485 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-e878f331: selfplay (source: autonomous)
2026-01-13 09:14:54,486 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-e878f331: selfplay_enabled=false for this node
2026-01-13 09:14:55,353 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:14:55 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:14:59,697 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:14:58 -0600] "POST /heartbeat HTTP/1.1" 200 1955 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:15:02,344 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:15:02 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:15:02,350 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:15:02 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:15:02,356 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:15:02 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:15:03,685 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:15:03,687 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:15:02 -0600] "GET /status HTTP/1.1" 200 49136 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:15:05,296 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 192-222-51-60 at 100.127.168.116:8770
2026-01-13 09:15:06,624 - swim.transport.tcp - ERROR - Failed to establish connection to 100.109.195.71:7947: [Errno 60] Connect call failed ('100.109.195.71', 7947)
2026-01-13 09:15:06,650 - swim.transport.tcp - ERROR - Failed to send data to ('100.109.195.71', 7947): [Errno 60] Connect call failed ('100.109.195.71', 7947)
2026-01-13 09:15:06,653 - swim.protocol.failure_detector - ERROR - [896aac12] Error pinging 100.109.195.71:7947: [Errno 60] Connect call failed ('100.109.195.71', 7947)
2026-01-13 09:15:06,660 - swim.protocol.sync - ERROR - [d5641a98] Error sending full sync request to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:15:09,048 - aiohttp.access - INFO - fd7a:115c:a1e0::4f01:ae13 [13/Jan/2026:09:15:03 -0600] "POST /gossip HTTP/1.1" 200 5630 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:15:09,835 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:15:09,837 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:15:03 -0600] "GET /status HTTP/1.1" 200 49423 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:15:09,838 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-e954a93a: selfplay (source: autonomous)
2026-01-13 09:15:09,855 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-e954a93a: selfplay_enabled=false for this node
2026-01-13 09:15:09,929 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:15:06 -0600] "POST /gossip HTTP/1.1" 200 5636 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:15:10,044 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:15:10 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:15:10,044 - scripts.p2p.loops.data_loops - INFO - [data_management] Disk at 83.3% (warning: 70.0%), triggering cleanup
2026-01-13 09:15:10,045 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:15:11,143 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:15:14,913 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:15:14,918 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:15:09 -0600] "GET /status HTTP/1.1" 200 49314 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:15:16,082 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:15:14 -0600] "POST /heartbeat HTTP/1.1" 200 1944 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:15:17,242 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:15:16 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:15:17,265 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:15:14 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:15:18,131 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:15:18,133 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:15:17 -0600] "GET /status HTTP/1.1" 200 47562 "-" "curl/8.7.1"
2026-01-13 09:15:19,930 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-b5526a7d: selfplay (source: autonomous)
2026-01-13 09:15:19,983 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-b5526a7d: selfplay_enabled=false for this node
2026-01-13 09:15:24,924 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:15:24 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:15:25,107 - p2p_orchestrator - INFO - DB consolidation: 12 DBs with 75 games to merge
2026-01-13 09:15:25,135 - p2p_orchestrator - INFO - Started DB merge (PID: 27410)
2026-01-13 09:15:26,783 - p2p_orchestrator - INFO - LOCAL: Disk at 83% - triggering cleanup
2026-01-13 09:15:26,784 - p2p_orchestrator - INFO - Running local disk cleanup...
Metrics Report: {'timestamp': 1768317327.010251, 'node_id': '0.0.0.0:7947', 'metrics': {'node_event': {'events': {'start': 1}}, 'ping_timeout': {'gauge': 0.5}, 'probe_result': {'counter': 2}, 'ping': {'events': {'failure': 1}}, 'peer_rtt': {'histogram': {'count': 1, 'min': 14.208169937133789, 'max': 14.208169937133789, 'mean': 14.208169937133789}}, 'timeout_adjustment': {'events': {'1.000->0.500': 1}}, 'member_count': {'gauge': 8}, 'protocol_cycle_duration': {'histogram': {'count': 1, 'min': 100.23378777503967, 'max': 100.23378777503967, 'mean': 100.23378777503967}}, 'protocol_period': {'gauge': 1.0}, 'suspect_timeout': {'gauge': 15.0, 'events': {'100.126.21.102:7947': 1}}}}
2026-01-13 09:15:28,121 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:15:28,122 - p2p_orchestrator - WARNING - LOCAL: Memory CRITICAL at 89% - emergency cleanup
2026-01-13 09:15:29,011 - p2p_orchestrator - INFO - Restarting stuck local selfplay jobs...
2026-01-13 09:15:29,296 - p2p_orchestrator - INFO - Killed 0 processes, cleared 0 job records
2026-01-13 09:15:30,293 - p2p_orchestrator - INFO - Emergency memory cleanup: cleared 21 gossip states, 2 manifests, ran gc.collect()
2026-01-13 09:15:31,635 - p2p_orchestrator - INFO - LOCAL: Disk at 83% - skipping job starts
2026-01-13 09:15:31,635 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:15:32,745 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:15:36,477 - app.distributed.hybrid_transport - INFO - [Transport] lambda-gh200-9: Switching to SSH after 3 HTTP failures
2026-01-13 09:15:38,415 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 192-222-51-60 at 100.127.168.116:8770
2026-01-13 09:15:38,497 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:15:38 -0600] "GET /health HTTP/1.1" 200 353 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:15:38,502 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:15:36 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:15:40,051 - p2p_orchestrator - INFO - [VoterHealth] Voter hetzner-cpu1 came ONLINE (3/8 alive, quorum=3)
2026-01-13 09:15:40,056 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:15:40,058 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:15:36 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:15:40,790 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:15:40,792 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:15:36 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:15:42,150 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-7ee7657e: selfplay (source: autonomous)
2026-01-13 09:15:42,151 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-7ee7657e: selfplay_enabled=false for this node
2026-01-13 09:15:42,151 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 192-222-51-60 at 100.127.168.116:8770
2026-01-13 09:15:42,220 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:15:39 -0600] "POST /gossip HTTP/1.1" 200 5528 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:15:44,768 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:15:43 -0600] "POST /heartbeat HTTP/1.1" 200 1944 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:15:44,769 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:15:43 -0600] "GET /health HTTP/1.1" 200 736 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:15:44,772 - scripts.p2p.loops.network_loops - INFO - [TailscalePeerDiscovery] Mode transition: maintenance -> bootstrap (peers=4, threshold=5)
2026-01-13 09:15:44,773 - aiohttp.access - INFO - 100.121.230.110 [13/Jan/2026:09:15:43 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:15:44,791 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:15:44 -0600] "GET /health HTTP/1.1" 200 745 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:15:44,795 - aiohttp.access - INFO - fd7a:115c:a1e0::4f01:ae13 [13/Jan/2026:09:15:42 -0600] "POST /gossip HTTP/1.1" 200 5538 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:15:46,178 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:15:44 -0600] "GET /api/cluster/status HTTP/1.1" 200 21153 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:15:47,649 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:15:46 -0600] "GET /api/cluster/status HTTP/1.1" 200 21153 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:15:48,951 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:15:46 -0600] "POST /heartbeat HTTP/1.1" 200 1943 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:15:49,937 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:15:49,940 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:15:48 -0600] "GET /status HTTP/1.1" 200 47202 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:15:50,834 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:15:50,836 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:15:48 -0600] "GET /status HTTP/1.1" 200 47201 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:15:50,838 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:15:49 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:15:50,842 - p2p_orchestrator - INFO - [P2P] Fetched 3 game counts from fallback MacBook-Pro-5
2026-01-13 09:15:52,196 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-1059dcf8: selfplay (source: autonomous)
2026-01-13 09:15:52,197 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-1059dcf8: selfplay_enabled=false for this node
2026-01-13 09:15:52,223 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:15:52 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:15:53,451 - p2p_orchestrator - WARNING - Isolated: only 4 alive peers (need 5), attempting bootstrap...
2026-01-13 09:15:54,331 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:15:54,335 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:15:53 -0600] "GET /status HTTP/1.1" 200 47202 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:15:54,358 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:15:54 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:15:55,880 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:15:54 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:15:57,109 - p2p_orchestrator - INFO - Bootstrap from 100.94.174.19:8770: imported 29 peers
2026-01-13 09:15:57,112 - p2p_orchestrator - INFO - Bootstrap successful! Now have 3 alive peers
2026-01-13 09:15:57,500 - p2p_orchestrator - INFO - Detected symmetric NAT (multiple external IPs seen)
2026-01-13 09:15:59,071 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:15:59 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:05,016 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-6df090a6: selfplay (source: autonomous)
2026-01-13 09:16:05,016 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-6df090a6: selfplay_enabled=false for this node
2026-01-13 09:16:07,836 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:16:05 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:16:07,838 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:16:07 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:14,986 - p2p_orchestrator - WARNING - Isolated: only 3 alive peers (need 5), attempting bootstrap...
2026-01-13 09:16:16,396 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:16:14 -0600] "POST /heartbeat HTTP/1.1" 200 1952 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:18,125 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: ringrift-cpu1 at 100.94.174.19:8770
2026-01-13 09:16:19,109 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:16:16 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:19,177 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:16:19 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:16:19,203 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:16:19 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:16:19,204 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:16:16 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:16:19,881 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:16:19,907 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:16:16 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:20,442 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:16:20,444 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:16:16 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:20,744 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:16:20,746 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:16:16 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:20,797 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:16:20 -0600] "GET /health HTTP/1.1" 200 742 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:22,426 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: ringrift-cpu1 at 100.94.174.19:8770
2026-01-13 09:16:25,635 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:16:25 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
Metrics Report: {'timestamp': 1768317387.01508, 'node_id': '0.0.0.0:7947', 'metrics': {'node_event': {'events': {'start': 1}}, 'ping_timeout': {'gauge': 0.5}, 'probe_result': {'counter': 2}, 'ping': {'events': {'failure': 1}}, 'peer_rtt': {'histogram': {'count': 1, 'min': 14.208169937133789, 'max': 14.208169937133789, 'mean': 14.208169937133789}}, 'timeout_adjustment': {'events': {'1.000->0.500': 1}}, 'member_count': {'gauge': 8}, 'protocol_cycle_duration': {'histogram': {'count': 1, 'min': 100.23378777503967, 'max': 100.23378777503967, 'mean': 100.23378777503967}}, 'protocol_period': {'gauge': 1.0}, 'suspect_timeout': {'gauge': 15.0, 'events': {'100.126.21.102:7947': 1}}}}
2026-01-13 09:16:28,247 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:16:25 -0600] "GET /api/cluster/status HTTP/1.1" 200 21871 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:28,248 - swim.transport.tcp - ERROR - Failed to establish connection to 100.109.195.71:7947: [Errno 60] Connect call failed ('100.109.195.71', 7947)
2026-01-13 09:16:28,248 - swim.transport.tcp - ERROR - Failed to send data to ('100.109.195.71', 7947): [Errno 60] Connect call failed ('100.109.195.71', 7947)
2026-01-13 09:16:28,248 - swim.protocol.failure_detector - ERROR - [896aac12] Error pinging 100.109.195.71:7947: [Errno 60] Connect call failed ('100.109.195.71', 7947)
2026-01-13 09:16:28,248 - swim.protocol.failure_detector - WARNING - [896aac12] All ping attempts failed to 100.109.195.71:7947, marking as SUSPECT
2026-01-13 09:16:28,249 - swim.protocol.member - INFO - STATE CHANGE: Member 100.109.195.71:7947 transitioned from ALIVE to SUSPECT (inc=2)
2026-01-13 09:16:28,273 - scripts.p2p.loops.http_server_health_loop - WARNING - [http_server_health] Health probe failed (consecutive: 1/4)
2026-01-13 09:16:30,194 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-c2ba3545: selfplay (source: autonomous)
2026-01-13 09:16:30,195 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-c2ba3545: selfplay_enabled=false for this node
2026-01-13 09:16:30,196 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:16:20 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:16:31,592 - p2p_orchestrator - INFO - LOCAL: Disk at 83% - skipping job starts
2026-01-13 09:16:31,592 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:16:33,008 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:16:33,009 - p2p_orchestrator - INFO - LOCAL: Memory at 91% - skipping GPU auto-scale
2026-01-13 09:16:34,807 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:16:30 -0600] "GET /health HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:36,138 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:16:30 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:16:36,139 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:16:30 -0600] "GET /peers HTTP/1.1" 404 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:36,141 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:16:30 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:36,143 - swim.transport.tcp - ERROR - Failed to establish connection to 100.67.131.72:7947: [Errno 61] Connect call failed ('100.67.131.72', 7947)
2026-01-13 09:16:36,143 - swim.transport.tcp - ERROR - Connection refused to 100.67.131.72:7947
2026-01-13 09:16:36,143 - swim.protocol.sync - ERROR - [d5641a98] Error sending full sync request to 100.67.131.72:7947: [Errno 61] Connect call failed ('100.67.131.72', 7947)
2026-01-13 09:16:36,148 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:16:36 -0600] "GET /health HTTP/1.1" 200 753 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:37,598 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:16:36 -0600] "GET /api/cluster/status HTTP/1.1" 200 21868 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:37,601 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: hetzner-cpu1
2026-01-13 09:16:40,483 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:16:39 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:16:43,426 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:16:43,426 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:16:43,426 - swim.protocol.disseminator - ERROR - [92b48a54] Error sending heartbeat to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:16:43,429 - swim.protocol.sync - INFO - [a30cf46e] Performing full sync with 2 members
2026-01-13 09:16:43,430 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:16:39 -0600] "GET /relay/peers HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:43,433 - aiohttp.access - INFO - fd7a:115c:a1e0::2e01:d06c [13/Jan/2026:09:16:37 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:43,436 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:16:39 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:43,437 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: hetzner-cpu1
2026-01-13 09:16:46,761 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:16:43 -0600] "GET /health HTTP/1.1" 200 753 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:47,116 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:16:47,118 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:16:39 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:47,430 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:16:47,431 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:16:39 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:47,432 - aiohttp.access - INFO - fd7a:115c:a1e0::2e01:d06c [13/Jan/2026:09:16:43 -0600] "POST /gossip/anti-entropy HTTP/1.1" 200 5875 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:47,433 - swim.transport.tcp - ERROR - Failed to establish connection to 100.67.131.72:7947: [Errno 61] Connect call failed ('100.67.131.72', 7947)
2026-01-13 09:16:47,433 - swim.transport.tcp - ERROR - Connection refused to 100.67.131.72:7947
2026-01-13 09:16:47,434 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:16:47 -0600] "GET /health HTTP/1.1" 200 353 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:47,436 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:16:47 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:47,438 - aiohttp.access - INFO - 100.67.131.72 [13/Jan/2026:09:16:43 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:47,438 - aiohttp.access - INFO - fd7a:115c:a1e0::4f01:ae13 [13/Jan/2026:09:16:43 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:47,482 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-0aa67ca9: selfplay (source: autonomous)
2026-01-13 09:16:47,484 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-0aa67ca9: selfplay_enabled=false for this node
2026-01-13 09:16:47,518 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:16:47 -0600] "GET /health HTTP/1.1" 200 752 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:47,522 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:16:47 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:49,483 - aiohttp.access - INFO - 100.67.131.72 [13/Jan/2026:09:16:47 -0600] "POST /heartbeat HTTP/1.1" 200 1945 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:49,484 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:16:47 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:52,322 - scripts.p2p.loops.http_server_health_loop - INFO - [http_server_health] HTTP server recovered after 1 failures
2026-01-13 09:16:52,322 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: ringrift-cpu1 at 100.94.174.19:8770
2026-01-13 09:16:53,324 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:16:47 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:53,337 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:16:47 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:16:53,357 - p2p_orchestrator - WARNING - handle_status: gossip_metrics timed out
2026-01-13 09:16:53,371 - p2p_orchestrator - WARNING - handle_status: distributed_training timed out
2026-01-13 09:16:53,379 - p2p_orchestrator - WARNING - handle_status: cluster_elo timed out
2026-01-13 09:16:53,389 - p2p_orchestrator - WARNING - handle_status: node_recovery timed out
2026-01-13 09:16:53,398 - p2p_orchestrator - WARNING - handle_status: leader_consensus timed out
2026-01-13 09:16:53,399 - p2p_orchestrator - WARNING - handle_status: peer_reputation timed out
2026-01-13 09:16:53,399 - p2p_orchestrator - WARNING - handle_status: sync_intervals timed out
2026-01-13 09:16:53,399 - p2p_orchestrator - WARNING - handle_status: tournament_scheduling timed out
2026-01-13 09:16:53,399 - p2p_orchestrator - WARNING - handle_status: data_dedup timed out
2026-01-13 09:16:54,315 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:16:53 -0600] "GET /health HTTP/1.1" 200 732 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:16:54,317 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:16:53 -0600] "GET /health HTTP/1.1" 200 733 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:16:55,519 - p2p_orchestrator - INFO - [VoterHealth] Voter hetzner-cpu2 came ONLINE (4/8 alive, quorum=3)
2026-01-13 09:16:55,519 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:16:55,521 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:16:47 -0600] "GET /status HTTP/1.1" 200 44768 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:55,521 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:16:52 -0600] "POST /gossip/anti-entropy HTTP/1.1" 200 7343 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:55,542 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: ringrift-cpu1 at 100.94.174.19:8770
2026-01-13 09:16:56,605 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:16:53 -0600] "POST /gossip HTTP/1.1" 200 5634 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:16:56,607 - aiohttp.access - INFO - 100.67.131.72 [13/Jan/2026:09:16:56 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:56,609 - aiohttp.access - INFO - 100.67.131.72 [13/Jan/2026:09:16:56 -0600] "GET /health HTTP/1.1" 200 743 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:16:56,908 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:16:56,910 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:16:55 -0600] "GET /status HTTP/1.1" 200 47914 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:16:57,204 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:16:57,206 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:16:55 -0600] "GET /status HTTP/1.1" 200 47914 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:16:57,229 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:16:53 -0600] "GET /api/cluster/status HTTP/1.1" 200 6404 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:57,475 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: hetzner-cpu1
2026-01-13 09:16:57,628 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: hetzner-cpu1
2026-01-13 09:16:57,772 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:16:53 -0600] "GET /api/cluster/status HTTP/1.1" 200 6405 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:57,988 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:16:57 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:16:58,262 - p2p_orchestrator - INFO - Bootstrap from 100.94.174.19:8770: imported 28 peers
2026-01-13 09:16:58,263 - p2p_orchestrator - INFO - Bootstrap successful! Now have 4 alive peers
2026-01-13 09:16:58,275 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:16:53 -0600] "GET /api/cluster/status HTTP/1.1" 200 6402 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:58,876 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:16:57 -0600] "GET /api/cluster/status HTTP/1.1" 200 6400 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:59,397 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:16:57 -0600] "GET /api/cluster/status HTTP/1.1" 200 6399 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:16:59,486 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-dcb1672c: selfplay (source: autonomous)
2026-01-13 09:16:59,487 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-dcb1672c: selfplay_enabled=false for this node
2026-01-13 09:17:00,484 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: ringrift-cpu1 at 100.94.174.19:8770
2026-01-13 09:17:01,339 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 100.94.174.19:7947 at 100.94.174.19:8770
2026-01-13 09:17:02,184 - p2p_orchestrator - INFO - Attempting connection to gossip-learned peer: 46.62.147.150:7947 at 46.62.147.150:8770
2026-01-13 09:17:03,079 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:16:59 -0600] "POST /gossip HTTP/1.1" 200 5518 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:17:03,080 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:16:58 -0600] "GET /api/cluster/status HTTP/1.1" 200 6401 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:17:03,081 - p2p_orchestrator - INFO - Adopting higher cluster epoch: 3920 (was 3918)
2026-01-13 09:17:03,965 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:17:03 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:03,966 - aiohttp.access - INFO - fd7a:115c:a1e0::c901:834a [13/Jan/2026:09:17:03 -0600] "POST /gossip HTTP/1.1" 200 5626 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:03,967 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: hetzner-cpu1
2026-01-13 09:17:03,970 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: hetzner-cpu1
2026-01-13 09:17:04,325 - p2p_orchestrator - INFO - Successfully connected to gossip-learned peer: hetzner-cpu1
2026-01-13 09:17:04,600 - p2p_orchestrator - INFO - Voter mesh incomplete, missing: ['vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:17:05,583 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:17:05 -0600] "GET /health HTTP/1.1" 200 753 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:17:08,953 - aiohttp.access - INFO - fd7a:115c:a1e0::4f01:ae13 [13/Jan/2026:09:17:08 -0600] "POST /gossip HTTP/1.1" 200 5634 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:17:09,489 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-d1c61a0c: selfplay (source: autonomous)
2026-01-13 09:17:09,490 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-d1c61a0c: selfplay_enabled=false for this node
2026-01-13 09:17:13,264 - p2p_orchestrator - WARNING - Isolated: only 4 alive peers (need 5), attempting bootstrap...
2026-01-13 09:17:17,705 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:17:16 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:17:17,717 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:17:16 -0600] "GET /relay/peers HTTP/1.1" 200 46798 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:18,725 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:17:18 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:18,770 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:17:18 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:20,045 - p2p_orchestrator - INFO - LOCAL: Leader present but no work dispatched in 686s (timeout=120s) - self-assigning
2026-01-13 09:17:21,160 - p2p_orchestrator - INFO - LOCAL: Disk at 83% - skipping job starts
2026-01-13 09:17:21,161 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:17:21,916 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:17:23,428 - p2p_orchestrator - INFO - Bootstrap from 100.126.21.102:8770: imported 41 peers
2026-01-13 09:17:23,431 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-5cf91c9d: selfplay (source: autonomous)
2026-01-13 09:17:23,432 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-5cf91c9d: selfplay_enabled=false for this node
2026-01-13 09:17:23,438 - p2p_orchestrator - INFO - Adopting higher cluster epoch: 3921 (was 3920)
2026-01-13 09:17:24,881 - p2p_orchestrator - INFO - Bootstrap successful! Now have 5 alive peers
2026-01-13 09:17:25,028 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:17:23 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
Metrics Report: {'timestamp': 1768317447.0213141, 'node_id': '0.0.0.0:7947', 'metrics': {'node_event': {'events': {'start': 1}}, 'ping_timeout': {'gauge': 0.5}, 'probe_result': {'counter': 4}, 'ping': {'events': {'failure': 2}}, 'peer_rtt': {'histogram': {'count': 2, 'min': 14.208169937133789, 'max': 234.6769700050354, 'mean': 124.4425699710846, 'stdev': 155.8949835680744}}, 'timeout_adjustment': {'events': {'1.000->0.500': 1}}, 'member_count': {'gauge': 8}, 'protocol_cycle_duration': {'histogram': {'count': 2, 'min': 100.23378777503967, 'max': 318.1459758281708, 'mean': 209.18988180160522, 'stdev': 154.08718587556717}}, 'protocol_period': {'gauge': 1.0}, 'suspect_timeout': {'gauge': 15.0, 'events': {'100.126.21.102:7947': 1}}}}
2026-01-13 09:17:27,569 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:17:25 -0600] "POST /gossip HTTP/1.1" 200 5409 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:17:27,573 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:17:27 -0600] "GET /health HTTP/1.1" 200 752 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:17:27,884 - p2p_orchestrator - WARNING - [VoterHealth] Voter lambda-gh200-training went OFFLINE (2/8 alive, quorum=3)
2026-01-13 09:17:27,885 - p2p_orchestrator - WARNING - [VoterHealth] Voter hetzner-cpu2 went OFFLINE (2/8 alive, quorum=3)
2026-01-13 09:17:27,885 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:17:27,886 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:17:27 -0600] "GET /status HTTP/1.1" 200 53806 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:28,200 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:17:28,201 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:17:27 -0600] "GET /status HTTP/1.1" 200 53807 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:28,508 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:17:28,510 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:17:27 -0600] "GET /status HTTP/1.1" 200 53808 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:28,807 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:17:28,808 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:17:27 -0600] "GET /status HTTP/1.1" 200 53809 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:29,115 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:17:29,116 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:17:27 -0600] "GET /status HTTP/1.1" 200 53811 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:29,415 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:17:29,417 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:17:27 -0600] "GET /status HTTP/1.1" 200 53810 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:29,718 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:17:29,719 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:17:27 -0600] "GET /status HTTP/1.1" 200 53812 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:30,016 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:17:30,017 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:17:27 -0600] "GET /status HTTP/1.1" 200 53812 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:30,327 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:17:30,328 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:17:27 -0600] "GET /status HTTP/1.1" 200 53812 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:30,733 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:17:30,735 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:17:27 -0600] "GET /status HTTP/1.1" 200 53809 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:30,744 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:17:30 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:33,439 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-a7e02ad5: selfplay (source: autonomous)
2026-01-13 09:17:33,439 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-a7e02ad5: selfplay_enabled=false for this node
2026-01-13 09:17:35,338 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:17:34 -0600] "POST /heartbeat HTTP/1.1" 200 1955 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:17:40,747 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:17:40 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:42,191 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:17:42,194 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:17:41 -0600] "GET /status HTTP/1.1" 200 55531 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:17:43,441 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-a2a88109: selfplay (source: autonomous)
2026-01-13 09:17:43,442 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-a2a88109: selfplay_enabled=false for this node
2026-01-13 09:17:43,625 - app.coordination.work_queue - INFO -  Added work training_square8_4p_1768317463610: training (priority: 100)
2026-01-13 09:17:44,106 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:17:44,108 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:17:43 -0600] "GET /status HTTP/1.1" 200 55524 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:17:48,532 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:17:48,532 - p2p_orchestrator - ERROR - [VoterHealth] QUORUM LOST: 2/8 voters alive, need 3
2026-01-13 09:17:48,533 - p2p_orchestrator - INFO - Peer ringrift-gpu has 3 consecutive failures, marking as NAT-blocked
2026-01-13 09:17:48,533 - p2p_orchestrator - INFO - [RelayHealthCheck] Relay MacBook-Pro-5 unhealthy for lambda-gh200-training, switching to hetzner-cpu1
2026-01-13 09:17:48,533 - p2p_orchestrator - INFO - [RelayHealthCheck] Relay 192-222-51-195 unhealthy for test, switching to hetzner-cpu1
2026-01-13 09:17:49,737 - p2p_orchestrator - INFO - Reconnected to dead peer 192-222-50-177 (was dead for 267s)
2026-01-13 09:17:49,738 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 192-222-50-177, invalidating cluster manifest
2026-01-13 09:17:49,738 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 192-222-50-177, node available for jobs
2026-01-13 09:17:50,877 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:17:50,879 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:17:50 -0600] "GET /status HTTP/1.1" 200 55522 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:50,880 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:17:50 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:50,895 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:17:50 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:53,274 - scripts.p2p.loops.network_loops - INFO - [TailscalePeerDiscovery] Mode transition: bootstrap -> maintenance (peers=6, threshold=5)
2026-01-13 09:17:53,445 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-804f742e: selfplay (source: autonomous)
2026-01-13 09:17:53,446 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-804f742e: selfplay_enabled=false for this node
2026-01-13 09:17:55,946 - aiohttp.access - INFO - fd7a:115c:a1e0::8c01:1567 [13/Jan/2026:09:17:54 -0600] "POST /gossip HTTP/1.1" 200 5617 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:17:59,872 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:17:59,874 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:17:59 -0600] "GET /status HTTP/1.1" 200 55536 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:18:00,193 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:18:00,195 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:17:59 -0600] "GET /status HTTP/1.1" 200 55537 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:18:00,903 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:18:00 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:02,435 - swim.transport.tcp - ERROR - Failed to establish connection to 100.109.195.71:7947: [Errno 60] Connect call failed ('100.109.195.71', 7947)
2026-01-13 09:18:02,435 - swim.transport.tcp - ERROR - Failed to send data to ('100.109.195.71', 7947): [Errno 60] Connect call failed ('100.109.195.71', 7947)
2026-01-13 09:18:02,435 - swim.protocol.sync - ERROR - [a30cf46e] Error sending full sync request to 100.109.195.71:7947: [Errno 60] Connect call failed ('100.109.195.71', 7947)
2026-01-13 09:18:02,436 - swim.protocol.disseminator - ERROR - [92b48a54] Error sending heartbeat to 100.67.131.72:7947: [Errno 61] Connect call failed ('100.67.131.72', 7947)
2026-01-13 09:18:02,436 - swim.protocol.node - INFO - Checking 1 suspect members
2026-01-13 09:18:02,436 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.109.195.71:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:02,436 - swim.protocol.node - WARNING - Suspect timeout expired for 100.109.195.71:7947, marking as DEAD
2026-01-13 09:18:02,437 - swim.protocol.member - INFO - STATE CHANGE: Member 100.109.195.71:7947 transitioned from SUSPECT to DEAD (inc=3)
2026-01-13 09:18:02,437 - swim.transport.tcp - ERROR - Failed to send data to ('100.94.174.19', 7947): Connection lost
2026-01-13 09:18:02,437 - swim.protocol.sync - ERROR - [a30cf46e] Error sending full sync request to 100.94.174.19:7947: Connection lost
2026-01-13 09:18:02,438 - swim.transport.tcp - ERROR - Failed to send data to ('100.94.174.19', 7947): Connection lost
2026-01-13 09:18:02,438 - swim.protocol.failure_detector - ERROR - [ea6805e6] Error pinging 100.94.174.19:7947: Connection lost
2026-01-13 09:18:02,438 - swim.transport.tcp - ERROR - Failed to send data to ('100.94.174.19', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:02,438 - swim.protocol.failure_detector - ERROR - [ea6805e6] Error pinging 100.94.174.19:7947: [Errno 32] Broken pipe
2026-01-13 09:18:02,438 - swim.transport.tcp - ERROR - Failed to send data to ('100.94.174.19', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:02,438 - swim.protocol.failure_detector - ERROR - [ea6805e6] Error pinging 100.94.174.19:7947: [Errno 32] Broken pipe
2026-01-13 09:18:02,438 - swim.protocol.failure_detector - WARNING - [ea6805e6] All ping attempts failed to 100.94.174.19:7947, marking as SUSPECT
2026-01-13 09:18:02,438 - swim.protocol.member - INFO - STATE CHANGE: Member 100.94.174.19:7947 transitioned from ALIVE to SUSPECT (inc=2)
2026-01-13 09:18:03,439 - swim.transport.tcp - ERROR - Failed to send data to ('100.94.174.19', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:03,439 - swim.protocol.disseminator - ERROR - [8f22de99] Error sending heartbeat to 100.94.174.19:7947: [Errno 32] Broken pipe
2026-01-13 09:18:03,439 - swim.protocol.node - INFO - Checking 1 suspect members
2026-01-13 09:18:03,440 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.94.174.19:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:03,440 - swim.protocol.node - INFO - [95ce1511] Checking suspect member 100.94.174.19:7947 with indirect probe (suspect for 1.00s)
2026-01-13 09:18:03,440 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.94.174.19:7947 (awareness=0): 7
2026-01-13 09:18:03,440 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.94.174.19:7947: 7 -> 8
2026-01-13 09:18:03,552 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:03,553 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:18:03,553 - swim.protocol.failure_detector - ERROR - [2ae74de9] Error sending PING-REQ to helper 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:03,684 - swim.transport.tcp - ERROR - Failed to send data to ('100.68.208.43', 7947): Connection lost
2026-01-13 09:18:03,684 - swim.protocol.failure_detector - ERROR - [2ae74de9] Error sending PING-REQ to helper 100.68.208.43:7947: Connection lost
2026-01-13 09:18:04,685 - swim.protocol.failure_detector - INFO - [2ae74de9] Indirect probe failed for 100.94.174.19:7947
2026-01-13 09:18:04,685 - swim.protocol.node - INFO - [95ce1511] Indirect probe FAILED for 100.94.174.19:7947
2026-01-13 09:18:04,686 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:04,686 - swim.transport.tcp - ERROR - Failed to send data to ('100.94.174.19', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:04,686 - swim.protocol.failure_detector - ERROR - [6999cb89] Error pinging 100.94.174.19:7947: [Errno 32] Broken pipe
2026-01-13 09:18:04,686 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:04,686 - swim.transport.tcp - ERROR - Failed to send data to ('100.94.174.19', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:04,686 - swim.protocol.failure_detector - ERROR - [6999cb89] Error pinging 100.94.174.19:7947: [Errno 32] Broken pipe
2026-01-13 09:18:04,687 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:04,687 - swim.transport.tcp - ERROR - Failed to send data to ('100.94.174.19', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:04,687 - swim.protocol.failure_detector - ERROR - [6999cb89] Error pinging 100.94.174.19:7947: [Errno 32] Broken pipe
2026-01-13 09:18:04,687 - swim.protocol.failure_detector - WARNING - [6999cb89] All ping attempts failed to 100.94.174.19:7947, marking as SUSPECT
2026-01-13 09:18:05,503 - swim.protocol.sync - INFO - [68fae013] Performing full sync with 2 members
2026-01-13 09:18:05,503 - swim.transport.tcp - ERROR - Failed to send data to ('100.68.208.43', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:05,503 - swim.protocol.sync - ERROR - [68fae013] Error sending full sync request to 100.68.208.43:7947: [Errno 32] Broken pipe
2026-01-13 09:18:05,624 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:05,625 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:18:05,625 - swim.protocol.sync - ERROR - [68fae013] Error sending full sync request to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:05,670 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:18:05 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:18:05,689 - swim.transport.tcp - ERROR - Failed to send data to ('100.68.208.43', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:05,689 - swim.protocol.disseminator - ERROR - [82d7ee0e] Error sending heartbeat to 100.68.208.43:7947: [Errno 32] Broken pipe
2026-01-13 09:18:05,689 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:05,689 - swim.transport.tcp - ERROR - Failed to send data to ('100.94.174.19', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:05,689 - swim.protocol.disseminator - ERROR - [82d7ee0e] Error sending heartbeat to 100.94.174.19:7947: [Errno 32] Broken pipe
2026-01-13 09:18:05,690 - swim.protocol.node - INFO - Checking 1 suspect members
2026-01-13 09:18:05,690 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.94.174.19:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:05,690 - swim.protocol.node - INFO - [f7aa52a2] Checking suspect member 100.94.174.19:7947 with indirect probe (suspect for 3.25s)
2026-01-13 09:18:05,690 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.94.174.19:7947 (awareness=0): 7
2026-01-13 09:18:05,690 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.94.174.19:7947: 7 -> 8
2026-01-13 09:18:05,690 - swim.transport.tcp - ERROR - Failed to send data to ('100.68.208.43', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:05,691 - swim.protocol.failure_detector - ERROR - [d8fb8fd1] Error sending PING-REQ to helper 100.68.208.43:7947: [Errno 32] Broken pipe
2026-01-13 09:18:05,725 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:05,726 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:18:05,726 - swim.protocol.failure_detector - ERROR - [d8fb8fd1] Error sending PING-REQ to helper 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:06,727 - swim.protocol.failure_detector - INFO - [d8fb8fd1] Indirect probe failed for 100.94.174.19:7947
2026-01-13 09:18:06,727 - swim.protocol.node - INFO - [f7aa52a2] Indirect probe FAILED for 100.94.174.19:7947
2026-01-13 09:18:06,727 - swim.transport.tcp - ERROR - Failed to send data to ('100.68.208.43', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:06,728 - swim.protocol.failure_detector - ERROR - [38f879e3] Error pinging 100.68.208.43:7947: [Errno 32] Broken pipe
2026-01-13 09:18:06,728 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:06,728 - swim.transport.tcp - ERROR - Failed to send data to ('100.68.208.43', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:06,728 - swim.protocol.failure_detector - ERROR - [38f879e3] Error pinging 100.68.208.43:7947: [Errno 32] Broken pipe
2026-01-13 09:18:06,729 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:06,729 - swim.transport.tcp - ERROR - Failed to send data to ('100.68.208.43', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:06,729 - swim.protocol.failure_detector - ERROR - [38f879e3] Error pinging 100.68.208.43:7947: [Errno 32] Broken pipe
2026-01-13 09:18:06,729 - swim.protocol.failure_detector - WARNING - [38f879e3] All ping attempts failed to 100.68.208.43:7947, marking as SUSPECT
2026-01-13 09:18:06,729 - swim.protocol.member - INFO - STATE CHANGE: Member 100.68.208.43:7947 transitioned from ALIVE to SUSPECT (inc=2)
2026-01-13 09:18:06,730 - swim.lifeguard.timing - INFO - LIFEGUARD: Increasing protocol period due to congestion: 1.00s -> 1.10s
2026-01-13 09:18:07,242 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:18:07 -0600] "GET /health HTTP/1.1" 200 728 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:18:07,831 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:07,832 - swim.transport.tcp - ERROR - Failed to send data to ('100.94.174.19', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:07,832 - swim.protocol.disseminator - ERROR - [afd3948c] Error sending heartbeat to 100.94.174.19:7947: [Errno 32] Broken pipe
2026-01-13 09:18:07,865 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:07,865 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:18:07,865 - swim.protocol.disseminator - ERROR - [afd3948c] Error sending heartbeat to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:07,866 - swim.protocol.node - INFO - Checking 2 suspect members
2026-01-13 09:18:07,866 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.68.208.43:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:07,867 - swim.protocol.node - INFO - [615f5271] Checking suspect member 100.68.208.43:7947 with indirect probe (suspect for 1.14s)
2026-01-13 09:18:07,867 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.68.208.43:7947 (awareness=0): 7
2026-01-13 09:18:07,867 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.68.208.43:7947: 7 -> 8
2026-01-13 09:18:07,868 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:07,868 - swim.transport.tcp - ERROR - Failed to send data to ('100.94.174.19', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:07,868 - swim.protocol.failure_detector - ERROR - [2a14dd46] Error sending PING-REQ to helper 100.94.174.19:7947: [Errno 32] Broken pipe
2026-01-13 09:18:07,909 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:07,910 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:18:07,910 - swim.protocol.failure_detector - ERROR - [2a14dd46] Error sending PING-REQ to helper 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:08,245 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-training, invalidating cluster manifest
2026-01-13 09:18:08,245 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-training, node available for jobs
2026-01-13 09:18:08,246 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-5, invalidating cluster manifest
2026-01-13 09:18:08,246 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-5, node available for jobs
2026-01-13 09:18:09,126 - aiohttp.access - INFO - fd7a:115c:a1e0::1d01:1390 [13/Jan/2026:09:18:08 -0600] "POST /gossip/anti-entropy HTTP/1.1" 200 9868 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:09,127 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:09,127 - swim.transport.tcp - ERROR - Failed to send data to ('100.68.208.43', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:09,127 - swim.protocol.sync - ERROR - [57b35226] Error sending incremental sync request to 100.68.208.43:7947: [Errno 32] Broken pipe
2026-01-13 09:18:09,128 - swim.protocol.failure_detector - INFO - [2a14dd46] Indirect probe failed for 100.68.208.43:7947
2026-01-13 09:18:09,128 - swim.protocol.node - INFO - [615f5271] Indirect probe FAILED for 100.68.208.43:7947
2026-01-13 09:18:09,128 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.94.174.19:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:09,128 - swim.protocol.node - INFO - [ccfb2906] Checking suspect member 100.94.174.19:7947 with indirect probe (suspect for 6.69s)
2026-01-13 09:18:09,129 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.94.174.19:7947 (awareness=0): 7
2026-01-13 09:18:09,129 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.94.174.19:7947: 7 -> 8
2026-01-13 09:18:09,163 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:09,163 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:18:09,163 - swim.protocol.failure_detector - ERROR - [e4976bbb] Error sending PING-REQ to helper 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:09,163 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:09,164 - swim.transport.tcp - ERROR - Failed to send data to ('100.68.208.43', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:09,164 - swim.protocol.failure_detector - ERROR - [e4976bbb] Error sending PING-REQ to helper 100.68.208.43:7947: [Errno 32] Broken pipe
2026-01-13 09:18:10,125 - p2p_orchestrator - INFO - LOCAL: Disk at 83% - skipping job starts
2026-01-13 09:18:10,126 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:18:10,806 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:18:11,619 - swim.protocol.failure_detector - INFO - [e4976bbb] Indirect probe failed for 100.94.174.19:7947
2026-01-13 09:18:11,619 - swim.protocol.node - INFO - [ccfb2906] Indirect probe FAILED for 100.94.174.19:7947
2026-01-13 09:18:11,622 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:18:11 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:11,654 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:11,654 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:18:11,654 - swim.protocol.failure_detector - ERROR - [01be9f79] Error pinging 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:11,688 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:11,688 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:18:11,688 - swim.protocol.failure_detector - ERROR - [01be9f79] Error pinging 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:11,721 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:11,721 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:18:11,721 - swim.protocol.failure_detector - ERROR - [01be9f79] Error pinging 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:11,721 - swim.protocol.failure_detector - WARNING - [01be9f79] All ping attempts failed to 100.94.201.92:7947, marking as SUSPECT
2026-01-13 09:18:11,722 - swim.protocol.member - INFO - STATE CHANGE: Member 100.94.201.92:7947 transitioned from ALIVE to SUSPECT (inc=2)
2026-01-13 09:18:11,722 - swim.lifeguard.timing - INFO - LIFEGUARD: Increasing protocol period due to congestion: 1.10s -> 1.21s
2026-01-13 09:18:12,128 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:12,128 - swim.transport.tcp - ERROR - Failed to send data to ('100.94.174.19', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:12,128 - swim.protocol.sync - ERROR - [e6b05a07] Error sending incremental sync request to 100.94.174.19:7947: [Errno 32] Broken pipe
2026-01-13 09:18:12,932 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:12,933 - swim.transport.tcp - ERROR - Failed to send data to ('100.68.208.43', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:12,933 - swim.protocol.disseminator - ERROR - [78877bc8] Error sending heartbeat to 100.68.208.43:7947: [Errno 32] Broken pipe
2026-01-13 09:18:12,992 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:12,993 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:18:12,993 - swim.protocol.disseminator - ERROR - [78877bc8] Error sending heartbeat to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:12,993 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:12,993 - swim.transport.tcp - ERROR - Failed to send data to ('100.94.174.19', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:12,993 - swim.protocol.disseminator - ERROR - [78877bc8] Error sending heartbeat to 100.94.174.19:7947: [Errno 32] Broken pipe
2026-01-13 09:18:12,993 - swim.protocol.node - INFO - Checking 3 suspect members
2026-01-13 09:18:12,994 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.68.208.43:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:12,994 - swim.protocol.node - INFO - [3254b720] Checking suspect member 100.68.208.43:7947 with indirect probe (suspect for 6.26s)
2026-01-13 09:18:12,994 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.68.208.43:7947 (awareness=0): 7
2026-01-13 09:18:12,994 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.68.208.43:7947: 7 -> 8
2026-01-13 09:18:12,994 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:12,994 - swim.transport.tcp - ERROR - Failed to send data to ('100.94.174.19', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:12,994 - swim.protocol.failure_detector - ERROR - [9b184b50] Error sending PING-REQ to helper 100.94.174.19:7947: [Errno 32] Broken pipe
2026-01-13 09:18:13,034 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:13,034 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:18:13,034 - swim.protocol.failure_detector - ERROR - [9b184b50] Error sending PING-REQ to helper 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:13,449 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-d56dccdf: selfplay (source: autonomous)
2026-01-13 09:18:13,449 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-d56dccdf: selfplay_enabled=false for this node
2026-01-13 09:18:14,035 - swim.protocol.failure_detector - INFO - [9b184b50] Indirect probe failed for 100.68.208.43:7947
2026-01-13 09:18:14,036 - swim.protocol.node - INFO - [3254b720] Indirect probe FAILED for 100.68.208.43:7947
2026-01-13 09:18:14,036 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.94.174.19:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:14,036 - swim.protocol.node - INFO - [d6f09bc7] Checking suspect member 100.94.174.19:7947 with indirect probe (suspect for 11.60s)
2026-01-13 09:18:14,036 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.94.174.19:7947 (awareness=0): 7
2026-01-13 09:18:14,037 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.94.174.19:7947: 7 -> 8
2026-01-13 09:18:14,037 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:14,037 - swim.transport.tcp - ERROR - Failed to send data to ('100.68.208.43', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:14,037 - swim.protocol.failure_detector - ERROR - [115366ec] Error sending PING-REQ to helper 100.68.208.43:7947: [Errno 32] Broken pipe
2026-01-13 09:18:14,080 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:14,080 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:18:14,080 - swim.protocol.failure_detector - ERROR - [115366ec] Error sending PING-REQ to helper 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:15,136 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:18:15,139 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:18:14 -0600] "GET /status HTTP/1.1" 200 55533 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:15,140 - swim.protocol.failure_detector - INFO - [115366ec] Indirect probe failed for 100.94.174.19:7947
2026-01-13 09:18:15,140 - swim.protocol.node - INFO - [d6f09bc7] Indirect probe FAILED for 100.94.174.19:7947
2026-01-13 09:18:15,140 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.94.201.92:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:15,140 - swim.protocol.node - INFO - [fa76054c] Checking suspect member 100.94.201.92:7947 with indirect probe (suspect for 3.42s)
2026-01-13 09:18:15,141 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.94.201.92:7947 (awareness=0): 7
2026-01-13 09:18:15,151 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.94.201.92:7947: 7 -> 8
2026-01-13 09:18:15,152 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:15,152 - swim.transport.tcp - ERROR - Failed to send data to ('100.68.208.43', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:15,152 - swim.protocol.failure_detector - ERROR - [f7570501] Error sending PING-REQ to helper 100.68.208.43:7947: [Errno 32] Broken pipe
2026-01-13 09:18:15,152 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:15,153 - swim.transport.tcp - ERROR - Failed to send data to ('100.94.174.19', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:15,153 - swim.protocol.failure_detector - ERROR - [f7570501] Error sending PING-REQ to helper 100.94.174.19:7947: [Errno 32] Broken pipe
2026-01-13 09:18:16,155 - swim.protocol.failure_detector - INFO - [f7570501] Indirect probe failed for 100.94.201.92:7947
2026-01-13 09:18:16,155 - swim.protocol.node - INFO - [fa76054c] Indirect probe FAILED for 100.94.201.92:7947
2026-01-13 09:18:16,155 - swim.lifeguard.timing - INFO - LIFEGUARD: Increasing protocol period due to congestion: 1.21s -> 1.33s
2026-01-13 09:18:17,521 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:17,522 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:18:17,522 - swim.protocol.disseminator - ERROR - [65493f42] Error sending heartbeat to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:17,522 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:17,522 - swim.transport.tcp - ERROR - Failed to send data to ('100.68.208.43', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:17,522 - swim.protocol.disseminator - ERROR - [65493f42] Error sending heartbeat to 100.68.208.43:7947: [Errno 32] Broken pipe
2026-01-13 09:18:17,522 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:17,523 - swim.transport.tcp - ERROR - Failed to send data to ('100.94.174.19', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:17,523 - swim.protocol.disseminator - ERROR - [65493f42] Error sending heartbeat to 100.94.174.19:7947: [Errno 32] Broken pipe
2026-01-13 09:18:17,523 - swim.protocol.node - INFO - Checking 3 suspect members
2026-01-13 09:18:17,523 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.68.208.43:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:17,523 - swim.protocol.node - INFO - [01afc3e5] Checking suspect member 100.68.208.43:7947 with indirect probe (suspect for 10.79s)
2026-01-13 09:18:17,523 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.68.208.43:7947 (awareness=0): 7
2026-01-13 09:18:17,523 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.68.208.43:7947: 7 -> 8
2026-01-13 09:18:17,557 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:17,557 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:18:17,558 - swim.protocol.failure_detector - ERROR - [50167d07] Error sending PING-REQ to helper 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:17,558 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:17,558 - swim.transport.tcp - ERROR - Failed to send data to ('100.94.174.19', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:17,558 - swim.protocol.failure_detector - ERROR - [50167d07] Error sending PING-REQ to helper 100.94.174.19:7947: [Errno 32] Broken pipe
2026-01-13 09:18:17,870 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:18:17 -0600] "GET /health HTTP/1.1" 200 735 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:18:19,217 - swim.protocol.failure_detector - INFO - [50167d07] Indirect probe failed for 100.68.208.43:7947
2026-01-13 09:18:19,218 - swim.protocol.node - INFO - [01afc3e5] Indirect probe FAILED for 100.68.208.43:7947
2026-01-13 09:18:19,218 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.94.174.19:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:19,219 - swim.protocol.node - WARNING - Suspect timeout expired for 100.94.174.19:7947, marking as DEAD
2026-01-13 09:18:19,219 - swim.protocol.member - INFO - STATE CHANGE: Member 100.94.174.19:7947 transitioned from SUSPECT to DEAD (inc=3)
2026-01-13 09:18:19,219 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.94.201.92:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:19,219 - swim.protocol.node - INFO - [274769ad] Checking suspect member 100.94.201.92:7947 with indirect probe (suspect for 7.50s)
2026-01-13 09:18:19,219 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.94.201.92:7947 (awareness=0): 7
2026-01-13 09:18:19,220 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.94.201.92:7947: 7 -> 8
2026-01-13 09:18:19,220 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:19,220 - swim.transport.tcp - ERROR - Failed to send data to ('100.68.208.43', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:19,220 - swim.protocol.failure_detector - ERROR - [fc30ff12] Error sending PING-REQ to helper 100.68.208.43:7947: [Errno 32] Broken pipe
2026-01-13 09:18:19,221 - aiohttp.access - INFO - fd7a:115c:a1e0::8c01:1567 [13/Jan/2026:09:18:18 -0600] "POST /gossip HTTP/1.1" 200 5576 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:21,572 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:18:20 -0600] "GET /api/cluster/status HTTP/1.1" 200 31857 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:18:21,572 - swim.protocol.failure_detector - INFO - [fc30ff12] Indirect probe failed for 100.94.201.92:7947
2026-01-13 09:18:21,573 - swim.protocol.node - INFO - [274769ad] Indirect probe FAILED for 100.94.201.92:7947
2026-01-13 09:18:21,573 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:21,573 - swim.transport.tcp - ERROR - Failed to send data to ('100.68.208.43', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:21,573 - swim.protocol.failure_detector - ERROR - [6cdf939a] Error pinging 100.68.208.43:7947: [Errno 32] Broken pipe
2026-01-13 09:18:21,574 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:21,574 - swim.transport.tcp - ERROR - Failed to send data to ('100.68.208.43', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:21,574 - swim.protocol.failure_detector - ERROR - [6cdf939a] Error pinging 100.68.208.43:7947: [Errno 32] Broken pipe
2026-01-13 09:18:21,574 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:21,574 - swim.transport.tcp - ERROR - Failed to send data to ('100.68.208.43', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:21,574 - swim.protocol.failure_detector - ERROR - [6cdf939a] Error pinging 100.68.208.43:7947: [Errno 32] Broken pipe
2026-01-13 09:18:21,574 - swim.protocol.failure_detector - WARNING - [6cdf939a] All ping attempts failed to 100.68.208.43:7947, marking as SUSPECT
2026-01-13 09:18:21,575 - swim.lifeguard.timing - INFO - LIFEGUARD: Increasing protocol period due to congestion: 1.33s -> 1.46s
2026-01-13 09:18:21,589 - aiohttp.access - INFO - 100.121.230.110 [13/Jan/2026:09:18:21 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:21,625 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:18:21 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:22,531 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:18:21 -0600] "GET /api/cluster/status HTTP/1.1" 200 31859 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:18:23,040 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:18:23,040 - swim.transport.tcp - ERROR - Failed to send data to ('100.68.208.43', 7947): [Errno 32] Broken pipe
2026-01-13 09:18:23,040 - swim.protocol.disseminator - ERROR - [860e67b8] Error sending heartbeat to 100.68.208.43:7947: [Errno 32] Broken pipe
2026-01-13 09:18:23,076 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:23,076 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:18:23,076 - swim.protocol.disseminator - ERROR - [860e67b8] Error sending heartbeat to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:23,076 - swim.protocol.node - INFO - Checking 2 suspect members
2026-01-13 09:18:23,076 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.68.208.43:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:23,077 - swim.protocol.node - WARNING - Suspect timeout expired for 100.68.208.43:7947, marking as DEAD
2026-01-13 09:18:23,077 - swim.protocol.member - INFO - STATE CHANGE: Member 100.68.208.43:7947 transitioned from SUSPECT to DEAD (inc=3)
2026-01-13 09:18:23,077 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.94.201.92:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:23,077 - swim.protocol.node - INFO - [d89f6df8] Checking suspect member 100.94.201.92:7947 with indirect probe (suspect for 11.36s)
2026-01-13 09:18:23,077 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.94.201.92:7947 (awareness=0): 7
2026-01-13 09:18:23,077 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.94.201.92:7947: 7 -> 8
2026-01-13 09:18:23,451 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-6a710174: selfplay (source: autonomous)
2026-01-13 09:18:23,451 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-6a710174: selfplay_enabled=false for this node
2026-01-13 09:18:23,793 - aiohttp.access - INFO - 100.121.230.110 [13/Jan/2026:09:18:23 -0600] "GET /health HTTP/1.1" 200 729 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:24,084 - swim.protocol.failure_detector - INFO - [38f91169] Indirect probe failed for 100.94.201.92:7947
2026-01-13 09:18:24,085 - swim.protocol.node - INFO - [d89f6df8] Indirect probe FAILED for 100.94.201.92:7947
2026-01-13 09:18:24,086 - swim.lifeguard.timing - INFO - LIFEGUARD: Increasing protocol period due to congestion: 1.46s -> 1.61s
2026-01-13 09:18:24,616 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:24,616 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:18:24,616 - swim.protocol.sync - ERROR - [5068e58f] Error sending incremental sync request to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:25,924 - aiohttp.access - INFO - fd7a:115c:a1e0::4f01:ae13 [13/Jan/2026:09:18:25 -0600] "POST /gossip HTTP/1.1" 200 5578 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:18:25,924 - aiohttp.access - INFO - 100.121.230.110 [13/Jan/2026:09:18:25 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:26,760 - swim.transport.tcp - ERROR - Failed to establish connection to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:26,761 - swim.transport.tcp - ERROR - Connection refused to 100.94.201.92:7947
2026-01-13 09:18:26,761 - swim.protocol.disseminator - ERROR - [fc6e9081] Error sending heartbeat to 100.94.201.92:7947: [Errno 61] Connect call failed ('100.94.201.92', 7947)
2026-01-13 09:18:26,761 - swim.protocol.node - INFO - Checking 1 suspect members
2026-01-13 09:18:26,761 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.94.201.92:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:26,761 - swim.protocol.node - WARNING - Suspect timeout expired for 100.94.201.92:7947, marking as DEAD
2026-01-13 09:18:26,762 - swim.protocol.member - INFO - STATE CHANGE: Member 100.94.201.92:7947 transitioned from SUSPECT to DEAD (inc=3)
Metrics Report: {'timestamp': 1768317507.024514, 'node_id': '0.0.0.0:7947', 'metrics': {'node_event': {'events': {'start': 1}}, 'ping_timeout': {'gauge': 0.5}, 'probe_result': {'counter': 34}, 'ping': {'events': {'failure': 7}}, 'peer_rtt': {'histogram': {'count': 7, 'min': 0.0014598369598388672, 'max': 234.6769700050354, 'mean': 35.570731265204294, 'stdev': 87.95664121302465, 'p95': 234.6769700050354, 'p99': 234.6769700050354}}, 'timeout_adjustment': {'events': {'1.000->0.500': 1}}, 'member_count': {'gauge': 8}, 'protocol_cycle_duration': {'histogram': {'count': 9, 'min': 1.0413780212402344, 'max': 318.1459758281708, 'mean': 57.69035585721334, 'stdev': 105.35823057199079, 'p95': 318.1459758281708, 'p99': 318.1459758281708}}, 'protocol_period': {'gauge': 1.6105100000000008}, 'suspect_timeout': {'gauge': 15.0, 'events': {'100.126.21.102:7947': 1, '100.109.195.71:7947': 1, '100.94.174.19:7947': 1, '100.68.208.43:7947': 1, '100.94.201.92:7947': 1}}, 'probe_count': {'gauge': 8}, 'indirect_probe': {'events': {'failure': 10}}}}
2026-01-13 09:18:28,411 - aiohttp.access - INFO - fd7a:115c:a1e0::2501:e689 [13/Jan/2026:09:18:25 -0600] "POST /gossip HTTP/1.1" 200 5635 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:28,413 - aiohttp.access - INFO - 100.121.230.110 [13/Jan/2026:09:18:28 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:28,415 - swim.protocol.failure_detector - WARNING - [a5851837] TIMEOUT waiting for PONG from 100.107.168.125:7947 (attempt 1/3)
2026-01-13 09:18:28,816 - swim.protocol.failure_detector - WARNING - [a5851837] TIMEOUT waiting for PONG from 100.107.168.125:7947 (attempt 2/3)
2026-01-13 09:18:29,217 - swim.protocol.failure_detector - WARNING - [a5851837] TIMEOUT waiting for PONG from 100.107.168.125:7947 (attempt 3/3)
2026-01-13 09:18:29,217 - swim.protocol.failure_detector - WARNING - [a5851837] All ping attempts failed to 100.107.168.125:7947, marking as SUSPECT
2026-01-13 09:18:29,217 - swim.protocol.member - INFO - STATE CHANGE: Member 100.107.168.125:7947 transitioned from ALIVE to SUSPECT (inc=2)
2026-01-13 09:18:29,218 - swim.lifeguard.timing - INFO - LIFEGUARD: Increasing protocol period due to congestion: 1.61s -> 1.77s
2026-01-13 09:18:31,175 - swim.protocol.node - INFO - Checking 1 suspect members
2026-01-13 09:18:31,177 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.107.168.125:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:31,177 - swim.protocol.node - INFO - [76ad7c78] Checking suspect member 100.107.168.125:7947 with indirect probe (suspect for 1.96s)
2026-01-13 09:18:31,177 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.107.168.125:7947 (awareness=0): 7
2026-01-13 09:18:31,178 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.107.168.125:7947: 7 -> 8
2026-01-13 09:18:32,282 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:18:32,336 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:18:30 -0600] "GET /status HTTP/1.1" 200 55566 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:32,797 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:18:32,800 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:18:30 -0600] "GET /status HTTP/1.1" 200 55483 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:33,054 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:18:33,055 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:18:30 -0600] "GET /status HTTP/1.1" 200 55472 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:33,301 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:18:33,302 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:18:30 -0600] "GET /status HTTP/1.1" 200 55469 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:33,547 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:18:33,548 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:18:30 -0600] "GET /status HTTP/1.1" 200 55471 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:33,794 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:18:33,795 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:18:30 -0600] "GET /status HTTP/1.1" 200 55472 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:34,048 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:18:34,049 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:18:30 -0600] "GET /status HTTP/1.1" 200 55471 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:34,395 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:18:34,397 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:18:30 -0600] "GET /status HTTP/1.1" 200 55471 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:34,645 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:18:34,646 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:18:30 -0600] "GET /status HTTP/1.1" 200 55472 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:34,894 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:18:34,896 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:18:30 -0600] "GET /status HTTP/1.1" 200 55471 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:35,743 - swim.protocol.failure_detector - INFO - [ca61f34d] Indirect probe failed for 100.107.168.125:7947
2026-01-13 09:18:35,743 - swim.protocol.node - INFO - [76ad7c78] Indirect probe FAILED for 100.107.168.125:7947
2026-01-13 09:18:35,744 - swim.lifeguard.timing - INFO - LIFEGUARD: Increasing protocol period due to congestion: 1.77s -> 1.95s
2026-01-13 09:18:35,747 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-f1a7ce2a: selfplay (source: autonomous)
2026-01-13 09:18:35,747 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-f1a7ce2a: selfplay_enabled=false for this node
2026-01-13 09:18:35,749 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:18:35 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:37,695 - swim.protocol.node - INFO - Checking 1 suspect members
2026-01-13 09:18:37,695 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.107.168.125:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:37,695 - swim.protocol.node - INFO - [cde7004e] Checking suspect member 100.107.168.125:7947 with indirect probe (suspect for 8.48s)
2026-01-13 09:18:37,695 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.107.168.125:7947 (awareness=0): 7
2026-01-13 09:18:37,695 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.107.168.125:7947: 7 -> 8
2026-01-13 09:18:37,925 - swim.protocol.sync - INFO - [2dc69e15] Performing full sync with 2 members
2026-01-13 09:18:38,647 - aiohttp.access - INFO - fd7a:115c:a1e0::1d01:1390 [13/Jan/2026:09:18:38 -0600] "POST /gossip HTTP/1.1" 200 5470 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:38,696 - swim.protocol.failure_detector - INFO - [f57e8131] Indirect probe failed for 100.107.168.125:7947
2026-01-13 09:18:38,696 - swim.protocol.node - INFO - [cde7004e] Indirect probe FAILED for 100.107.168.125:7947
2026-01-13 09:18:38,697 - swim.lifeguard.timing - INFO - LIFEGUARD: Increasing protocol period due to congestion: 1.95s -> 2.14s
2026-01-13 09:18:40,698 - swim.protocol.node - INFO - Checking 1 suspect members
2026-01-13 09:18:40,698 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.107.168.125:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:40,699 - swim.protocol.node - INFO - [dd563374] Checking suspect member 100.107.168.125:7947 with indirect probe (suspect for 11.48s)
2026-01-13 09:18:40,699 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.107.168.125:7947 (awareness=0): 7
2026-01-13 09:18:40,699 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.107.168.125:7947: 7 -> 8
2026-01-13 09:18:41,700 - swim.protocol.failure_detector - INFO - [dd186945] Indirect probe failed for 100.107.168.125:7947
2026-01-13 09:18:41,700 - swim.protocol.node - INFO - [dd563374] Indirect probe FAILED for 100.107.168.125:7947
2026-01-13 09:18:41,700 - swim.lifeguard.timing - INFO - LIFEGUARD: Increasing protocol period due to congestion: 2.00s -> 2.20s
2026-01-13 09:18:41,763 - p2p_orchestrator - WARNING - Isolated: only 4 alive peers (need 5), attempting bootstrap...
2026-01-13 09:18:42,390 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:18:42 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:18:42,390 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:18:42 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:18:42,707 - p2p_orchestrator - INFO - Bootstrap from 100.94.174.19:8770: imported 28 peers
2026-01-13 09:18:42,708 - p2p_orchestrator - INFO - Bootstrap successful! Now have 4 alive peers
2026-01-13 09:18:43,702 - swim.protocol.node - INFO - Checking 1 suspect members
2026-01-13 09:18:43,702 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.107.168.125:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:43,702 - swim.protocol.node - INFO - [90e452fe] Checking suspect member 100.107.168.125:7947 with indirect probe (suspect for 14.49s)
2026-01-13 09:18:43,703 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.107.168.125:7947 (awareness=0): 7
2026-01-13 09:18:43,703 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.107.168.125:7947: 7 -> 8
2026-01-13 09:18:44,704 - swim.protocol.failure_detector - INFO - [673953c6] Indirect probe failed for 100.107.168.125:7947
2026-01-13 09:18:44,704 - swim.protocol.node - INFO - [90e452fe] Indirect probe FAILED for 100.107.168.125:7947
2026-01-13 09:18:44,704 - swim.lifeguard.timing - INFO - LIFEGUARD: Increasing protocol period due to congestion: 2.00s -> 2.20s
2026-01-13 09:18:45,356 - p2p_orchestrator - INFO - LOCAL: Leader present but no work dispatched in 771s (timeout=120s) - self-assigning
2026-01-13 09:18:46,201 - p2p_orchestrator - INFO - LOCAL: Disk at 83% - skipping job starts
2026-01-13 09:18:46,202 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:18:46,863 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:18:47,662 - swim.protocol.node - INFO - Checking 1 suspect members
2026-01-13 09:18:47,662 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.107.168.125:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:47,663 - swim.protocol.node - WARNING - Suspect timeout expired for 100.107.168.125:7947, marking as DEAD
2026-01-13 09:18:47,663 - swim.protocol.member - INFO - STATE CHANGE: Member 100.107.168.125:7947 transitioned from SUSPECT to DEAD (inc=3)
2026-01-13 09:18:47,663 - swim.lifeguard.timing - INFO - LIFEGUARD: Increasing protocol period due to congestion: 2.00s -> 2.20s
2026-01-13 09:18:47,732 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:18:47 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:18:47,752 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:18:47 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:47,764 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-e2efb454: selfplay (source: autonomous)
2026-01-13 09:18:47,765 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-e2efb454: selfplay_enabled=false for this node
2026-01-13 09:18:48,108 - p2p_orchestrator - INFO - [VoterHealth] Voter hetzner-cpu3 came ONLINE (3/8 alive, quorum=3)
2026-01-13 09:18:48,109 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:18:48,111 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:18:47 -0600] "GET /status HTTP/1.1" 200 51812 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:18:48,397 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:18:48,398 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:18:47 -0600] "GET /status HTTP/1.1" 200 51813 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:18:48,449 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:18:48 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:49,665 - swim.lifeguard.timing - INFO - LIFEGUARD: Increasing protocol period due to congestion: 2.00s -> 2.20s
2026-01-13 09:18:50,502 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:18:49 -0600] "POST /heartbeat HTTP/1.1" 200 1956 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:18:51,728 - swim.lifeguard.timing - INFO - LIFEGUARD: Increasing protocol period due to congestion: 2.00s -> 2.20s
2026-01-13 09:18:52,905 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:18:52 -0600] "POST /gossip HTTP/1.1" 200 5559 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:18:52,907 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:18:52 -0600] "GET /health HTTP/1.1" 200 736 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:18:53,771 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:18:53 -0600] "GET /api/cluster/status HTTP/1.1" 200 31847 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:18:53,803 - swim.lifeguard.timing - INFO - LIFEGUARD: Increasing protocol period due to congestion: 2.00s -> 2.20s
2026-01-13 09:18:53,803 - scripts.p2p.loops.network_loops - INFO - [TailscalePeerDiscovery] Mode transition: maintenance -> bootstrap (peers=4, threshold=5)
2026-01-13 09:18:54,856 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:18:54 -0600] "GET /api/cluster/status HTTP/1.1" 200 31847 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:18:56,303 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:18:56,305 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:18:55 -0600] "GET /status HTTP/1.1" 200 51823 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:56,306 - swim.protocol.failure_detector - WARNING - [25f6be1a] TIMEOUT waiting for PONG from 100.67.131.72:7947 (attempt 1/3)
2026-01-13 09:18:56,712 - swim.protocol.failure_detector - WARNING - [25f6be1a] TIMEOUT waiting for PONG from 100.67.131.72:7947 (attempt 2/3)
2026-01-13 09:18:57,115 - swim.protocol.failure_detector - WARNING - [25f6be1a] TIMEOUT waiting for PONG from 100.67.131.72:7947 (attempt 3/3)
2026-01-13 09:18:57,115 - swim.protocol.failure_detector - WARNING - [25f6be1a] All ping attempts failed to 100.67.131.72:7947, marking as SUSPECT
2026-01-13 09:18:57,116 - swim.protocol.member - INFO - STATE CHANGE: Member 100.67.131.72:7947 transitioned from ALIVE to SUSPECT (inc=2)
2026-01-13 09:18:57,116 - swim.lifeguard.timing - INFO - LIFEGUARD: Increasing protocol period due to congestion: 2.00s -> 2.20s
2026-01-13 09:18:57,709 - p2p_orchestrator - WARNING - Isolated: only 4 alive peers (need 5), attempting bootstrap...
2026-01-13 09:18:57,770 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-5530face: selfplay (source: autonomous)
2026-01-13 09:18:57,771 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-5530face: selfplay_enabled=false for this node
2026-01-13 09:18:58,401 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:18:58 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:18:58,620 - p2p_orchestrator - INFO - Bootstrap from 100.126.21.102:8770: imported 42 peers
2026-01-13 09:18:58,621 - p2p_orchestrator - INFO - Bootstrap successful! Now have 4 alive peers
2026-01-13 09:18:59,118 - swim.protocol.node - INFO - Checking 1 suspect members
2026-01-13 09:18:59,119 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.67.131.72:7947: 15.00s (base: 5.00s)
2026-01-13 09:18:59,119 - swim.protocol.node - INFO - [913f4782] Checking suspect member 100.67.131.72:7947 with indirect probe (suspect for 2.00s)
2026-01-13 09:18:59,119 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.67.131.72:7947 (awareness=0): 7
2026-01-13 09:18:59,119 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.67.131.72:7947: 7 -> 8
2026-01-13 09:18:59,119 - swim.protocol.failure_detector - WARNING - No helpers available for indirect probe of 100.67.131.72:7947
2026-01-13 09:18:59,120 - swim.protocol.node - INFO - [913f4782] Indirect probe FAILED for 100.67.131.72:7947
2026-01-13 09:18:59,120 - swim.lifeguard.timing - INFO - LIFEGUARD: Increasing protocol period due to congestion: 2.00s -> 2.20s
2026-01-13 09:19:01,120 - swim.transport.tcp - ERROR - Failed to send data to ('100.67.131.72', 7947): [Errno 54] Connection reset by peer
2026-01-13 09:19:01,120 - swim.protocol.disseminator - ERROR - [ad95bead] Error sending heartbeat to 100.67.131.72:7947: [Errno 54] Connection reset by peer
2026-01-13 09:19:01,121 - swim.protocol.node - INFO - Checking 1 suspect members
2026-01-13 09:19:01,121 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.67.131.72:7947: 15.00s (base: 5.00s)
2026-01-13 09:19:01,121 - swim.protocol.node - INFO - [3f805cce] Checking suspect member 100.67.131.72:7947 with indirect probe (suspect for 4.01s)
2026-01-13 09:19:01,121 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.67.131.72:7947 (awareness=0): 7
2026-01-13 09:19:01,121 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.67.131.72:7947: 7 -> 8
2026-01-13 09:19:01,121 - swim.protocol.failure_detector - WARNING - No helpers available for indirect probe of 100.67.131.72:7947
2026-01-13 09:19:01,122 - swim.protocol.node - INFO - [3f805cce] Indirect probe FAILED for 100.67.131.72:7947
2026-01-13 09:19:02,814 - swim.transport.tcp - ERROR - Failed to send data to ('100.67.131.72', 7947): [Errno 54] Connection reset by peer
2026-01-13 09:19:02,814 - swim.protocol.sync - ERROR - [42223a61] Error sending incremental sync request to 100.67.131.72:7947: [Errno 54] Connection reset by peer
2026-01-13 09:19:03,123 - swim.transport.tcp - ERROR - Failed to send data to ('100.67.131.72', 7947): [Errno 54] Connection reset by peer
2026-01-13 09:19:03,123 - swim.protocol.disseminator - ERROR - [622d3f01] Error sending heartbeat to 100.67.131.72:7947: [Errno 54] Connection reset by peer
2026-01-13 09:19:03,124 - swim.protocol.node - INFO - Checking 1 suspect members
2026-01-13 09:19:03,124 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.67.131.72:7947: 15.00s (base: 5.00s)
2026-01-13 09:19:03,124 - swim.protocol.node - INFO - [16df2e13] Checking suspect member 100.67.131.72:7947 with indirect probe (suspect for 6.01s)
2026-01-13 09:19:03,124 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.67.131.72:7947 (awareness=0): 7
2026-01-13 09:19:03,124 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.67.131.72:7947: 7 -> 8
2026-01-13 09:19:03,124 - swim.protocol.failure_detector - WARNING - No helpers available for indirect probe of 100.67.131.72:7947
2026-01-13 09:19:03,124 - swim.protocol.node - INFO - [16df2e13] Indirect probe FAILED for 100.67.131.72:7947
2026-01-13 09:19:03,499 - app.distributed.hybrid_transport - INFO - [Transport] lambda-gh200-training: Switching to SSH after 3 HTTP failures
2026-01-13 09:19:05,346 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:19:05,348 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:19:04 -0600] "GET /status HTTP/1.1" 200 51826 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:19:05,349 - swim.transport.tcp - ERROR - Failed to send data to ('100.67.131.72', 7947): [Errno 54] Connection reset by peer
2026-01-13 09:19:05,349 - swim.protocol.disseminator - ERROR - [a48c0c9c] Error sending heartbeat to 100.67.131.72:7947: [Errno 54] Connection reset by peer
2026-01-13 09:19:05,350 - swim.protocol.node - INFO - Checking 1 suspect members
2026-01-13 09:19:05,350 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.67.131.72:7947: 15.00s (base: 5.00s)
2026-01-13 09:19:05,351 - swim.protocol.node - INFO - [3d33a712] Checking suspect member 100.67.131.72:7947 with indirect probe (suspect for 8.23s)
2026-01-13 09:19:05,363 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.67.131.72:7947 (awareness=0): 7
2026-01-13 09:19:05,364 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.67.131.72:7947: 7 -> 8
2026-01-13 09:19:05,365 - swim.protocol.failure_detector - WARNING - No helpers available for indirect probe of 100.67.131.72:7947
2026-01-13 09:19:05,365 - swim.protocol.node - INFO - [3d33a712] Indirect probe FAILED for 100.67.131.72:7947
2026-01-13 09:19:05,366 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:19:05,366 - swim.transport.tcp - ERROR - Failed to send data to ('100.67.131.72', 7947): [Errno 54] Connection reset by peer
2026-01-13 09:19:05,367 - swim.protocol.failure_detector - ERROR - [8788aa0a] Error pinging 100.67.131.72:7947: [Errno 54] Connection reset by peer
2026-01-13 09:19:05,367 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:19:05,367 - swim.transport.tcp - ERROR - Failed to send data to ('100.67.131.72', 7947): [Errno 54] Connection reset by peer
2026-01-13 09:19:05,367 - swim.protocol.failure_detector - ERROR - [8788aa0a] Error pinging 100.67.131.72:7947: [Errno 54] Connection reset by peer
2026-01-13 09:19:05,367 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:19:05,367 - swim.transport.tcp - ERROR - Failed to send data to ('100.67.131.72', 7947): [Errno 54] Connection reset by peer
2026-01-13 09:19:05,368 - swim.protocol.failure_detector - ERROR - [8788aa0a] Error pinging 100.67.131.72:7947: [Errno 54] Connection reset by peer
2026-01-13 09:19:05,368 - swim.protocol.failure_detector - WARNING - [8788aa0a] All ping attempts failed to 100.67.131.72:7947, marking as SUSPECT
2026-01-13 09:19:05,891 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:19:05,904 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:19:04 -0600] "GET /status HTTP/1.1" 200 51827 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:19:05,916 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:19:05,917 - swim.transport.tcp - ERROR - Failed to send data to ('100.67.131.72', 7947): [Errno 54] Connection reset by peer
2026-01-13 09:19:05,917 - swim.protocol.sync - ERROR - [8b7d5ba5] Error sending incremental sync request to 100.67.131.72:7947: [Errno 54] Connection reset by peer
2026-01-13 09:19:07,370 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:19:07,370 - swim.transport.tcp - ERROR - Failed to send data to ('100.67.131.72', 7947): [Errno 54] Connection reset by peer
2026-01-13 09:19:07,371 - swim.protocol.disseminator - ERROR - [0483ab54] Error sending heartbeat to 100.67.131.72:7947: [Errno 54] Connection reset by peer
2026-01-13 09:19:07,371 - swim.protocol.node - INFO - Checking 1 suspect members
2026-01-13 09:19:07,371 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.67.131.72:7947: 15.00s (base: 5.00s)
2026-01-13 09:19:07,371 - swim.protocol.node - INFO - [7a9c7145] Checking suspect member 100.67.131.72:7947 with indirect probe (suspect for 10.26s)
2026-01-13 09:19:07,371 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.67.131.72:7947 (awareness=0): 7
2026-01-13 09:19:07,372 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.67.131.72:7947: 7 -> 8
2026-01-13 09:19:07,372 - swim.protocol.failure_detector - WARNING - No helpers available for indirect probe of 100.67.131.72:7947
2026-01-13 09:19:07,372 - swim.protocol.node - INFO - [7a9c7145] Indirect probe FAILED for 100.67.131.72:7947
2026-01-13 09:19:07,773 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-e6af0523: selfplay (source: autonomous)
2026-01-13 09:19:07,773 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-e6af0523: selfplay_enabled=false for this node
2026-01-13 09:19:08,405 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:19:08 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:08,891 - p2p_orchestrator - INFO - DB consolidation: 12 DBs with 75 games to merge
2026-01-13 09:19:08,911 - p2p_orchestrator - INFO - Started DB merge (PID: 39993)
2026-01-13 09:19:08,919 - swim.protocol.sync - INFO - [5eefb619] Performing full sync with 1 members
2026-01-13 09:19:08,919 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:19:08,919 - swim.transport.tcp - ERROR - Failed to send data to ('100.67.131.72', 7947): [Errno 54] Connection reset by peer
2026-01-13 09:19:08,919 - swim.protocol.sync - ERROR - [5eefb619] Error sending full sync request to 100.67.131.72:7947: [Errno 54] Connection reset by peer
2026-01-13 09:19:09,373 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:19:09,373 - swim.transport.tcp - ERROR - Failed to send data to ('100.67.131.72', 7947): [Errno 54] Connection reset by peer
2026-01-13 09:19:09,373 - swim.protocol.disseminator - ERROR - [a35e7db1] Error sending heartbeat to 100.67.131.72:7947: [Errno 54] Connection reset by peer
2026-01-13 09:19:09,374 - swim.protocol.node - INFO - Checking 1 suspect members
2026-01-13 09:19:09,374 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.67.131.72:7947: 15.00s (base: 5.00s)
2026-01-13 09:19:09,374 - swim.protocol.node - INFO - [5659ad96] Checking suspect member 100.67.131.72:7947 with indirect probe (suspect for 12.26s)
2026-01-13 09:19:09,374 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.67.131.72:7947 (awareness=0): 7
2026-01-13 09:19:09,374 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.67.131.72:7947: 7 -> 8
2026-01-13 09:19:09,375 - swim.protocol.failure_detector - WARNING - No helpers available for indirect probe of 100.67.131.72:7947
2026-01-13 09:19:09,375 - swim.protocol.node - INFO - [5659ad96] Indirect probe FAILED for 100.67.131.72:7947
2026-01-13 09:19:11,375 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:19:11,376 - swim.transport.tcp - ERROR - Failed to send data to ('100.67.131.72', 7947): [Errno 54] Connection reset by peer
2026-01-13 09:19:11,376 - swim.protocol.disseminator - ERROR - [43c25628] Error sending heartbeat to 100.67.131.72:7947: [Errno 54] Connection reset by peer
2026-01-13 09:19:11,376 - swim.protocol.node - INFO - Checking 1 suspect members
2026-01-13 09:19:11,376 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.67.131.72:7947: 15.00s (base: 5.00s)
2026-01-13 09:19:11,377 - swim.protocol.node - INFO - [da02562f] Checking suspect member 100.67.131.72:7947 with indirect probe (suspect for 14.26s)
2026-01-13 09:19:11,377 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Probe count for 100.67.131.72:7947 (awareness=0): 7
2026-01-13 09:19:11,377 - swim.lifeguard.probe_rate - INFO - LIFEGUARD: Increased probe count due to high failure rate (100.0%) for 100.67.131.72:7947: 7 -> 8
2026-01-13 09:19:11,377 - swim.protocol.failure_detector - WARNING - No helpers available for indirect probe of 100.67.131.72:7947
2026-01-13 09:19:11,377 - swim.protocol.node - INFO - [da02562f] Indirect probe FAILED for 100.67.131.72:7947
2026-01-13 09:19:11,378 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:19:11,378 - swim.transport.tcp - ERROR - Failed to send data to ('100.67.131.72', 7947): [Errno 54] Connection reset by peer
2026-01-13 09:19:11,378 - swim.protocol.failure_detector - ERROR - [95170467] Error pinging 100.67.131.72:7947: [Errno 54] Connection reset by peer
2026-01-13 09:19:11,378 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:19:11,378 - swim.transport.tcp - ERROR - Failed to send data to ('100.67.131.72', 7947): [Errno 54] Connection reset by peer
2026-01-13 09:19:11,379 - swim.protocol.failure_detector - ERROR - [95170467] Error pinging 100.67.131.72:7947: [Errno 54] Connection reset by peer
2026-01-13 09:19:11,379 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:19:11,379 - swim.transport.tcp - ERROR - Failed to send data to ('100.67.131.72', 7947): [Errno 54] Connection reset by peer
2026-01-13 09:19:11,379 - swim.protocol.failure_detector - ERROR - [95170467] Error pinging 100.67.131.72:7947: [Errno 54] Connection reset by peer
2026-01-13 09:19:11,379 - swim.protocol.failure_detector - WARNING - [95170467] All ping attempts failed to 100.67.131.72:7947, marking as SUSPECT
2026-01-13 09:19:11,920 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:19:11,920 - swim.transport.tcp - ERROR - Failed to send data to ('100.67.131.72', 7947): [Errno 54] Connection reset by peer
2026-01-13 09:19:11,921 - swim.protocol.sync - ERROR - [18288bd1] Error sending incremental sync request to 100.67.131.72:7947: [Errno 54] Connection reset by peer
2026-01-13 09:19:12,209 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:19:12 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:19:13,070 - app.coordination.work_queue - INFO -  Added work training_square19_2p_1768317553053: training (priority: 100)
2026-01-13 09:19:13,380 - asyncio - WARNING - socket.send() raised exception.
2026-01-13 09:19:13,380 - swim.transport.tcp - ERROR - Failed to send data to ('100.67.131.72', 7947): [Errno 54] Connection reset by peer
2026-01-13 09:19:13,380 - swim.protocol.disseminator - ERROR - [68f1c800] Error sending heartbeat to 100.67.131.72:7947: [Errno 54] Connection reset by peer
2026-01-13 09:19:13,381 - swim.protocol.node - INFO - Checking 1 suspect members
2026-01-13 09:19:13,381 - swim.protocol.node - INFO - LIFEGUARD: Using adaptive suspect timeout for 100.67.131.72:7947: 15.00s (base: 5.00s)
2026-01-13 09:19:13,381 - swim.protocol.node - WARNING - Suspect timeout expired for 100.67.131.72:7947, marking as DEAD
2026-01-13 09:19:13,381 - swim.protocol.member - INFO - STATE CHANGE: Member 100.67.131.72:7947 transitioned from SUSPECT to DEAD (inc=3)
2026-01-13 09:19:13,623 - p2p_orchestrator - WARNING - Isolated: only 4 alive peers (need 5), attempting bootstrap...
2026-01-13 09:19:14,598 - p2p_orchestrator - INFO - Bootstrap from 100.126.21.102:8770: imported 42 peers
2026-01-13 09:19:14,599 - p2p_orchestrator - INFO - Bootstrap successful! Now have 4 alive peers
2026-01-13 09:19:17,776 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-57b48af8: selfplay (source: autonomous)
2026-01-13 09:19:17,776 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-57b48af8: selfplay_enabled=false for this node
2026-01-13 09:19:17,830 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:19:17 -0600] "GET /health HTTP/1.1" 200 753 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:19:18,410 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:19:18 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:20,922 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:19:20 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:19:21,233 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:19:21,235 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:19:20 -0600] "GET /status HTTP/1.1" 200 51835 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:24,168 - p2p_orchestrator - INFO - LOCAL: Leader present but no work dispatched in 810s (timeout=120s) - self-assigning
2026-01-13 09:19:24,858 - p2p_orchestrator - INFO - LOCAL: Disk at 83% - skipping job starts
2026-01-13 09:19:24,858 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:19:25,385 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
Metrics Report: {'timestamp': 1768317567.027096, 'node_id': '0.0.0.0:7947', 'metrics': {'node_event': {'events': {'start': 1}}, 'ping_timeout': {'gauge': 0.5}, 'probe_result': {'counter': 57}, 'ping': {'events': {'failure': 11}}, 'peer_rtt': {'histogram': {'count': 11, 'min': 0.0014598369598388672, 'max': 234.6769700050354, 'mean': 22.978784322738647, 'stdev': 70.33821384640088, 'p95': 234.6769700050354, 'p99': 234.6769700050354}}, 'timeout_adjustment': {'events': {'1.000->0.500': 1}}, 'member_count': {'gauge': 8}, 'protocol_cycle_duration': {'histogram': {'count': 33, 'min': 9.298324584960938e-05, 'max': 318.1459758281708, 'mean': 16.104425199104078, 'stdev': 58.69262300661575, 'p95': 100.23378777503967, 'p99': 318.1459758281708}}, 'protocol_period': {'gauge': 2.0}, 'suspect_timeout': {'gauge': 15.0, 'events': {'100.126.21.102:7947': 1, '100.109.195.71:7947': 1, '100.94.174.19:7947': 1, '100.68.208.43:7947': 1, '100.94.201.92:7947': 1, '100.107.168.125:7947': 1, '100.67.131.72:7947': 1}}, 'probe_count': {'gauge': 8}, 'indirect_probe': {'events': {'failure': 21}}}}
2026-01-13 09:19:27,779 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-514cd59a: selfplay (source: autonomous)
2026-01-13 09:19:27,779 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-514cd59a: selfplay_enabled=false for this node
2026-01-13 09:19:28,414 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:19:28 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:29,436 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:19:28 -0600] "POST /gossip HTTP/1.1" 200 5501 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:19:37,047 - scripts.p2p.loops.peer_cleanup_loop - INFO - [PeerCleanup] Purged 1 stale peers (tier2: 1, tier3: 0). Health ratio: 100.0% → 100.0%
2026-01-13 09:19:37,052 - scripts.p2p.loops.gossip_state_cleanup_loop - INFO - [GossipStateCleanup] Purged 28 entries: states=0, manifests=0, recovery=0, reputation=0, endpoints=28, promotion=0, jobs=0
2026-01-13 09:19:38,459 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:19:38,494 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:19:36 -0600] "GET /status HTTP/1.1" 200 51368 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:38,844 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:19:38,846 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:19:36 -0600] "GET /status HTTP/1.1" 200 51370 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:39,153 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:19:39,155 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:19:36 -0600] "GET /status HTTP/1.1" 200 51368 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:39,467 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:19:39,468 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:19:36 -0600] "GET /status HTTP/1.1" 200 51369 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:39,921 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:19:39,923 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:19:36 -0600] "GET /status HTTP/1.1" 200 51370 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:40,252 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:19:40,254 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:19:36 -0600] "GET /status HTTP/1.1" 200 51368 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:40,572 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:19:40,574 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:19:36 -0600] "GET /status HTTP/1.1" 200 51370 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:40,883 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:19:40,885 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:19:36 -0600] "GET /status HTTP/1.1" 200 51370 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:41,191 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:19:41,193 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:19:36 -0600] "GET /status HTTP/1.1" 200 51369 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:41,620 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:19:41,623 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:19:36 -0600] "GET /status HTTP/1.1" 200 51368 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:41,908 - scripts.p2p.loops.cluster_healing_loop - WARNING - [ClusterHealing] Failed to load hosts YAML: 'str' object has no attribute 'get'
2026-01-13 09:19:41,913 - scripts.p2p.loops.coordination_loops - INFO - [AutoScaling] Scaling up by 3 nodes
2026-01-13 09:19:41,984 - scripts.p2p.loops.coordination_loops - INFO - [AutoScaling] Added 0 nodes: []
2026-01-13 09:19:42,009 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-cd00ffda: selfplay (source: autonomous)
2026-01-13 09:19:42,010 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-cd00ffda: selfplay_enabled=false for this node
2026-01-13 09:19:42,014 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:19:42 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:42,032 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:19:42 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:42,090 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:19:42 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:19:50,517 - aiohttp.access - INFO - 100.67.131.72 [13/Jan/2026:09:19:50 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:52,017 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-16a03703: selfplay (source: autonomous)
2026-01-13 09:19:52,017 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-16a03703: selfplay_enabled=false for this node
2026-01-13 09:19:52,094 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:19:52 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:58,018 - p2p_orchestrator - WARNING - [VoterHealth] Voter hetzner-cpu3 went OFFLINE (2/8 alive, quorum=3)
2026-01-13 09:19:58,018 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:19:58,021 - aiohttp.access - INFO - 100.106.87.89 [13/Jan/2026:09:19:57 -0600] "GET /status HTTP/1.1" 200 49367 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:58,034 - aiohttp.access - INFO - 100.106.87.89 [13/Jan/2026:09:19:57 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:19:58,500 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:19:58 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:19:59,603 - p2p_orchestrator - WARNING - Isolated: only 3 alive peers (need 5), attempting bootstrap...
2026-01-13 09:20:01,518 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:20:01,520 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:20:01 -0600] "GET /status HTTP/1.1" 200 49365 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:02,019 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-f7ffe7ce: selfplay (source: autonomous)
2026-01-13 09:20:02,019 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-f7ffe7ce: selfplay_enabled=false for this node
2026-01-13 09:20:02,100 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:20:02 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:03,752 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:20:03,753 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:20:03 -0600] "GET /status HTTP/1.1" 200 49363 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:03,756 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:20:03 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:08,628 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:20:08 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:20:09,024 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:20:09,035 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:20:08 -0600] "GET /status HTTP/1.1" 200 49368 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:20:10,470 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:20:09 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:20:12,163 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:20:11 -0600] "GET /api/cluster/status HTTP/1.1" 200 31868 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:20:12,258 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-d7497036: selfplay (source: autonomous)
2026-01-13 09:20:12,259 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-d7497036: selfplay_enabled=false for this node
2026-01-13 09:20:12,288 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:20:12 -0600] "GET /health HTTP/1.1" 200 353 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:12,582 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:20:12,584 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:20:12 -0600] "GET /status HTTP/1.1" 200 49357 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:20:12,869 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:20:12,870 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:20:12 -0600] "GET /status HTTP/1.1" 200 49358 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:20:13,169 - p2p_orchestrator - INFO - Bootstrap from 100.126.21.102:8770: imported 42 peers
2026-01-13 09:20:13,963 - p2p_orchestrator - INFO - LOCAL: Disk at 84% - skipping job starts
2026-01-13 09:20:13,964 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:20:14,603 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:20:16,205 - p2p_orchestrator - INFO - Bootstrap successful! Now have 3 alive peers
2026-01-13 09:20:16,206 - scripts.p2p.loops.data_loops - INFO - [data_management] Disk at 83.7% (warning: 70.0%), triggering cleanup
2026-01-13 09:20:16,206 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:20:16,851 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:20:19,683 - p2p_orchestrator - INFO - NAT-blocked peer lambda-gh200-4 is now reachable at 100.77.186.124:8770
2026-01-13 09:20:23,134 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-f5947188: selfplay (source: autonomous)
2026-01-13 09:20:23,134 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-f5947188: selfplay_enabled=false for this node
2026-01-13 09:20:23,389 - p2p_orchestrator - INFO - Reconnected to dead peer lambda-gh200-4 (was dead for 638s)
2026-01-13 09:20:24,238 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-4, invalidating cluster manifest
2026-01-13 09:20:24,238 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-4, node available for jobs
2026-01-13 09:20:26,127 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:20:25 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:20:26,207 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:20:26 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:26,745 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:20:26,748 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:20:26 -0600] "GET /status HTTP/1.1" 200 51218 "-" "Python/3.10 aiohttp/3.13.2"
Metrics Report: {'timestamp': 1768317627.031685, 'node_id': '0.0.0.0:7947', 'metrics': {'node_event': {'events': {'start': 1}}, 'ping_timeout': {'gauge': 0.5}, 'probe_result': {'counter': 57}, 'ping': {'events': {'failure': 11}}, 'peer_rtt': {'histogram': {'count': 11, 'min': 0.0014598369598388672, 'max': 234.6769700050354, 'mean': 22.978784322738647, 'stdev': 70.33821384640088, 'p95': 234.6769700050354, 'p99': 234.6769700050354}}, 'timeout_adjustment': {'events': {'1.000->0.500': 1}}, 'member_count': {'gauge': 8}, 'protocol_cycle_duration': {'histogram': {'count': 58, 'min': 8.320808410644531e-05, 'max': 318.1459758281708, 'mean': 9.162956513207535, 'stdev': 44.706319255365734, 'p95': 86.29481482505798, 'p99': 318.1459758281708}}, 'protocol_period': {'gauge': 2.0}, 'suspect_timeout': {'gauge': 15.0, 'events': {'100.126.21.102:7947': 1, '100.109.195.71:7947': 1, '100.94.174.19:7947': 1, '100.68.208.43:7947': 1, '100.94.201.92:7947': 1, '100.107.168.125:7947': 1, '100.67.131.72:7947': 1}}, 'probe_count': {'gauge': 8}, 'indirect_probe': {'events': {'failure': 21}}}}
2026-01-13 09:20:28,255 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:20:27 -0600] "POST /gossip HTTP/1.1" 200 5327 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:20:29,684 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:20:29 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:31,206 - p2p_orchestrator - WARNING - Isolated: only 4 alive peers (need 5), attempting bootstrap...
2026-01-13 09:20:33,136 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-5de5b142: selfplay (source: autonomous)
2026-01-13 09:20:33,136 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-5de5b142: selfplay_enabled=false for this node
2026-01-13 09:20:36,210 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:20:36 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:40,174 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:20:39 -0600] "POST /heartbeat HTTP/1.1" 200 1956 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:40,176 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:20:39 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:20:42,391 - p2p_orchestrator - INFO - Bootstrap from 100.126.21.102:8770: imported 42 peers
2026-01-13 09:20:42,393 - p2p_orchestrator - INFO - Bootstrap successful! Now have 5 alive peers
2026-01-13 09:20:43,150 - p2p_orchestrator - WARNING - [VoterHealth] Voter hetzner-cpu1 went OFFLINE (1/8 alive, quorum=3)
2026-01-13 09:20:43,150 - p2p_orchestrator - WARNING - [VoterHealth] Status: 1/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:20:43,151 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:20:42 -0600] "GET /status HTTP/1.1" 200 52948 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:43,401 - p2p_orchestrator - WARNING - [VoterHealth] Status: 1/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:20:43,402 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:20:42 -0600] "GET /status HTTP/1.1" 200 52950 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:43,650 - p2p_orchestrator - WARNING - [VoterHealth] Status: 1/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:20:43,651 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:20:42 -0600] "GET /status HTTP/1.1" 200 52951 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:43,901 - p2p_orchestrator - WARNING - [VoterHealth] Status: 1/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:20:43,902 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:20:42 -0600] "GET /status HTTP/1.1" 200 52951 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:44,154 - p2p_orchestrator - WARNING - [VoterHealth] Status: 1/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:20:44,155 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:20:42 -0600] "GET /status HTTP/1.1" 200 52950 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:44,394 - p2p_orchestrator - WARNING - [VoterHealth] Status: 1/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:20:44,395 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:20:42 -0600] "GET /status HTTP/1.1" 200 52948 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:44,632 - p2p_orchestrator - WARNING - [VoterHealth] Status: 1/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:20:44,633 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:20:42 -0600] "GET /status HTTP/1.1" 200 52949 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:44,868 - p2p_orchestrator - WARNING - [VoterHealth] Status: 1/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:20:44,869 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:20:42 -0600] "GET /status HTTP/1.1" 200 52948 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:45,210 - p2p_orchestrator - WARNING - [VoterHealth] Status: 1/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:20:45,211 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:20:42 -0600] "GET /status HTTP/1.1" 200 52951 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:45,457 - p2p_orchestrator - WARNING - [VoterHealth] Status: 1/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:20:45,458 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:20:42 -0600] "GET /status HTTP/1.1" 200 52949 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:45,491 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-dd6929b5: selfplay (source: autonomous)
2026-01-13 09:20:45,492 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-dd6929b5: selfplay_enabled=false for this node
2026-01-13 09:20:46,028 - app.coordination.work_queue - INFO -  Added work training_square19_3p_1768317646017: training (priority: 100)
2026-01-13 09:20:46,464 - p2p_orchestrator - INFO - LOCAL: Disk at 84% - triggering cleanup
2026-01-13 09:20:46,464 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:20:47,045 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:20:47,045 - p2p_orchestrator - INFO - LOCAL: Memory warning at 76% - reducing jobs to 1
2026-01-13 09:20:47,573 - p2p_orchestrator - INFO - LOCAL: Leader present but no work dispatched in 893s (timeout=120s) - self-assigning
2026-01-13 09:20:48,399 - p2p_orchestrator - INFO - LOCAL: Disk at 84% - skipping job starts
2026-01-13 09:20:48,400 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:20:49,068 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:20:49,069 - p2p_orchestrator - INFO - LOCAL: 0% GPU util, starting 1 diverse/hybrid selfplay job(s)
2026-01-13 09:20:49,070 - scripts.p2p.managers.selfplay_scheduler - INFO - Mode-specific engine mix: square8_2p 'mcts-only' -> 'gumbel-mcts' (gpu=True, extra_args={'budget': 800})
2026-01-13 09:20:49,071 - app.training.architecture_tracker - INFO - ArchitectureTracker: Loaded 5 architecture stats
2026-01-13 09:20:49,072 - scripts.p2p.managers.selfplay_scheduler - INFO - Mode-specific engine mix: square8_2p 'mcts-only' -> 'gumbel-mcts' (gpu=True, extra_args={'budget': 800})
2026-01-13 09:20:49,176 - p2p_orchestrator - INFO - SAFEGUARD blocked hybrid_selfplay on MacBook-Pro-5: CPU critical: 94.3%
2026-01-13 09:20:50,132 - p2p_orchestrator - INFO - Reconnected to dead peer lambda-gh200-2 (was dead for 640s)
2026-01-13 09:20:50,952 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-2, invalidating cluster manifest
2026-01-13 09:20:50,952 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-2, node available for jobs
2026-01-13 09:20:50,953 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:20:50 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:50,955 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:20:50 -0600] "GET /health HTTP/1.1" 200 353 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:52,713 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:20:51 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:20:53,553 - p2p_orchestrator - INFO - Reconnected to dead peer lambda-gh200-1 (was dead for 518s)
2026-01-13 09:20:54,404 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-1, invalidating cluster manifest
2026-01-13 09:20:54,405 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-1, node available for jobs
2026-01-13 09:20:54,406 - scripts.p2p.loops.network_loops - INFO - [TailscalePeerDiscovery] Mode transition: bootstrap -> maintenance (peers=7, threshold=5)
2026-01-13 09:20:54,737 - p2p_orchestrator - INFO - Reconnected to dead peer lambda-gh200-3 (was dead for 518s)
2026-01-13 09:20:55,623 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-3, invalidating cluster manifest
2026-01-13 09:20:55,623 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-3, node available for jobs
2026-01-13 09:20:55,625 - app.coordination.sync_router - INFO - [SyncRouter] Added new node: 100.69.101.108
2026-01-13 09:20:59,306 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:20:59 -0600] "GET /health HTTP/1.1" 200 737 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:59,312 - aiohttp.access - INFO - 100.71.89.91 [13/Jan/2026:09:20:59 -0600] "GET /health HTTP/1.1" 200 737 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:20:59,313 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-478cd3f5: selfplay (source: autonomous)
2026-01-13 09:20:59,313 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-478cd3f5: selfplay_enabled=false for this node
2026-01-13 09:21:00,202 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:20:59 -0600] "POST /heartbeat HTTP/1.1" 200 1945 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:21:00,204 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:20:59 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:00,863 - p2p_orchestrator - WARNING - [VoterHealth] Status: 1/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:21:00,880 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:20:59 -0600] "GET /status HTTP/1.1" 200 58522 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:01,886 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:21:01 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:01,947 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:21:01 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:21:01,960 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:21:01 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:01,962 - p2p_orchestrator - INFO - [P2P] Fetched 3 game counts from fallback MacBook-Pro-5
2026-01-13 09:21:04,394 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:21:03 -0600] "POST /gossip HTTP/1.1" 200 5572 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:21:04,889 - p2p_orchestrator - INFO - [VoterHealth] Voter hetzner-cpu3 came ONLINE (2/8 alive, quorum=3)
2026-01-13 09:21:04,889 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:21:04,890 - aiohttp.access - INFO - 100.106.87.89 [13/Jan/2026:09:21:04 -0600] "GET /status HTTP/1.1" 200 58718 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:07,500 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:21:07,502 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:21:07 -0600] "GET /status HTTP/1.1" 200 58727 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:09,317 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-f6423b28: selfplay (source: autonomous)
2026-01-13 09:21:09,318 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-f6423b28: selfplay_enabled=false for this node
2026-01-13 09:21:09,490 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:21:09 -0600] "GET /health HTTP/1.1" 200 737 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:11,890 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:21:11 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:13,318 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:21:13 -0600] "GET /health HTTP/1.1" 200 736 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:14,195 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:21:14 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:21:15,646 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:21:15,648 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:21:15 -0600] "GET /status HTTP/1.1" 200 58718 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:17,717 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:21:17,718 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:21:17 -0600] "GET /status HTTP/1.1" 200 58721 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:21:18,114 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:21:18,116 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:21:17 -0600] "GET /status HTTP/1.1" 200 58719 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:21:18,414 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:21:18,416 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:21:18 -0600] "GET /status HTTP/1.1" 200 58719 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:18,417 - app.distributed.hybrid_transport - INFO - [Transport] lambda-gh200-9: Switching back to HTTP
2026-01-13 09:21:19,451 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:21:19,453 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:21:19 -0600] "GET /status HTTP/1.1" 200 58833 "-" "Python-urllib/3.10"
2026-01-13 09:21:19,453 - p2p_orchestrator - INFO - LOCAL: Leader present but no work dispatched in 925s (timeout=120s) - self-assigning
2026-01-13 09:21:20,205 - p2p_orchestrator - INFO - LOCAL: Disk at 84% - skipping job starts
2026-01-13 09:21:20,205 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:21:20,895 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:21:22,720 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-6634faf7: selfplay (source: autonomous)
2026-01-13 09:21:22,720 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-6634faf7: selfplay_enabled=false for this node
2026-01-13 09:21:22,776 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:21:22 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:22,780 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:21:22 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:24,332 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:21:24 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.10 aiohttp/3.13.2"
Metrics Report: {'timestamp': 1768317687.039485, 'node_id': '0.0.0.0:7947', 'metrics': {'node_event': {'events': {'start': 1}}, 'ping_timeout': {'gauge': 0.5}, 'probe_result': {'counter': 57}, 'ping': {'events': {'failure': 11}}, 'peer_rtt': {'histogram': {'count': 11, 'min': 0.0014598369598388672, 'max': 234.6769700050354, 'mean': 22.978784322738647, 'stdev': 70.33821384640088, 'p95': 234.6769700050354, 'p99': 234.6769700050354}}, 'timeout_adjustment': {'events': {'1.000->0.500': 1}}, 'member_count': {'gauge': 8}, 'protocol_cycle_duration': {'histogram': {'count': 83, 'min': 6.29425048828125e-05, 'max': 318.1459758281708, 'mean': 6.403086785810539, 'stdev': 37.51260609681976, 'p95': 4.0877649784088135, 'p99': 318.1459758281708}}, 'protocol_period': {'gauge': 2.0}, 'suspect_timeout': {'gauge': 15.0, 'events': {'100.126.21.102:7947': 1, '100.109.195.71:7947': 1, '100.94.174.19:7947': 1, '100.68.208.43:7947': 1, '100.94.201.92:7947': 1, '100.107.168.125:7947': 1, '100.67.131.72:7947': 1}}, 'probe_count': {'gauge': 8}, 'indirect_probe': {'events': {'failure': 21}}}}
2026-01-13 09:21:27,700 - app.distributed.hybrid_transport - INFO - [Transport] lambda-gh200-5: Switching to SSH after 3 HTTP failures
2026-01-13 09:21:28,931 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:21:27 -0600] "POST /heartbeat HTTP/1.1" 200 1952 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:28,967 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:21:28 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:33,307 - p2p_orchestrator - INFO - [VoterHealth] Voter hetzner-cpu1 came ONLINE (5/8 alive, quorum=3)
2026-01-13 09:21:33,314 - p2p_orchestrator - INFO - [VoterHealth] Voter lambda-gh200-training came ONLINE (5/8 alive, quorum=3)
2026-01-13 09:21:33,314 - p2p_orchestrator - INFO - [VoterHealth] Voter mac-studio came ONLINE (5/8 alive, quorum=3)
2026-01-13 09:21:33,314 - p2p_orchestrator - WARNING - [VoterHealth] Status: 5/8 voters alive, quorum=OK, offline: ['hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:21:33,316 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:21:32 -0600] "GET /status HTTP/1.1" 200 59878 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:33,921 - p2p_orchestrator - WARNING - [VoterHealth] Status: 5/8 voters alive, quorum=OK, offline: ['hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:21:33,923 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:21:32 -0600] "GET /status HTTP/1.1" 200 59878 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:33,929 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:21:33 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:33,963 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:21:33 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:33,964 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-7237e346: selfplay (source: autonomous)
2026-01-13 09:21:33,964 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-7237e346: selfplay_enabled=false for this node
2026-01-13 09:21:33,992 - p2p_orchestrator - INFO - Detected symmetric NAT (multiple external IPs seen)
2026-01-13 09:21:34,096 - p2p_orchestrator - INFO - NAT-blocked peer lambda-gh200-4 is now reachable at 100.77.186.124:8770
2026-01-13 09:21:34,319 - p2p_orchestrator - INFO - NAT-blocked peer lambda-gh200-2 is now reachable at 100.110.143.119:8770
2026-01-13 09:21:34,428 - p2p_orchestrator - INFO - NAT-blocked peer lambda-gh200-1 is now reachable at 100.71.89.91:8770
2026-01-13 09:21:36,475 - aiohttp.access - INFO - 100.83.177.16 [13/Jan/2026:09:21:36 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:37,503 - app.distributed.hybrid_transport - INFO - [Transport] lambda-gh200-5: Switching back to HTTP
2026-01-13 09:21:37,513 - p2p_orchestrator - INFO - Reconnected to dead peer lambda-gh200-5 (was dead for 518s)
2026-01-13 09:21:38,609 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-5, invalidating cluster manifest
2026-01-13 09:21:38,610 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-5, node available for jobs
2026-01-13 09:21:38,611 - app.coordination.sync_router - INFO - [SyncRouter] Added new node: 100.83.177.16
2026-01-13 09:21:38,615 - aiohttp.access - INFO - 100.71.89.91 [13/Jan/2026:09:21:38 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:38,653 - aiohttp.access - INFO - 100.71.89.91 [13/Jan/2026:09:21:38 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:39,473 - p2p_orchestrator - WARNING - [VoterHealth] Voter hetzner-cpu1 went OFFLINE (4/8 alive, quorum=3)
2026-01-13 09:21:39,473 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:21:39,475 - aiohttp.access - INFO - 100.71.89.91 [13/Jan/2026:09:21:38 -0600] "GET /status HTTP/1.1" 200 60016 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:40,204 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:21:40 -0600] "GET /health HTTP/1.1" 200 753 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:40,798 - p2p_orchestrator - INFO - Reconnected to dead peer hetzner-cpu3 (was dead for 441s)
2026-01-13 09:21:42,088 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: hetzner-cpu3, invalidating cluster manifest
2026-01-13 09:21:42,088 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: hetzner-cpu3, node available for jobs
2026-01-13 09:21:42,088 - app.coordination.sync_router - INFO - [SyncRouter] Added new node: 100.126.21.102
2026-01-13 09:21:42,452 - p2p_orchestrator - INFO - Reconnected to dead peer 192-222-57-140 (was dead for 351s)
2026-01-13 09:21:43,756 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 192-222-57-140, invalidating cluster manifest
2026-01-13 09:21:43,756 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 192-222-57-140, node available for jobs
2026-01-13 09:21:43,763 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:21:43 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:45,096 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:21:43 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:45,100 - aiohttp.access - INFO - fd7a:115c:a1e0::a001:a888 [13/Jan/2026:09:21:43 -0600] "POST /gossip HTTP/1.1" 200 5664 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:45,101 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-81336024: selfplay (source: autonomous)
2026-01-13 09:21:45,101 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-81336024: selfplay_enabled=false for this node
2026-01-13 09:21:45,103 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:21:45 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:45,104 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:21:45 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:45,200 - p2p_orchestrator - INFO - Voter mesh incomplete, missing: ['vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:21:45,348 - p2p_orchestrator - INFO - Reconnected to dead peer lambda-gh200-10 (was dead for 833s)
2026-01-13 09:21:46,659 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-10, invalidating cluster manifest
2026-01-13 09:21:46,659 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-10, node available for jobs
2026-01-13 09:21:46,725 - p2p_orchestrator - INFO - DB consolidation: 12 DBs with 75 games to merge
2026-01-13 09:21:46,747 - p2p_orchestrator - INFO - Started DB merge (PID: 46443)
2026-01-13 09:21:47,109 - p2p_orchestrator - INFO - Reconnected to dead peer 192-222-51-195 (was dead for 339s)
2026-01-13 09:21:48,415 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 192-222-51-195, invalidating cluster manifest
2026-01-13 09:21:48,416 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 192-222-51-195, node available for jobs
2026-01-13 09:21:51,177 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:21:49 -0600] "POST /heartbeat HTTP/1.1" 200 1955 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:51,189 - p2p_orchestrator - INFO - Reconnected to dead peer MacBook-Pro-2 (was dead for 1012s)
2026-01-13 09:21:53,264 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: MacBook-Pro-2, invalidating cluster manifest
2026-01-13 09:21:53,264 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: MacBook-Pro-2, node available for jobs
2026-01-13 09:21:53,385 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:21:53 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:55,625 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:21:55,629 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:21:51 -0600] "GET /status HTTP/1.1" 200 65775 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:56,382 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-e7d9cbb4: selfplay (source: autonomous)
2026-01-13 09:21:56,382 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-e7d9cbb4: selfplay_enabled=false for this node
2026-01-13 09:21:58,323 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:21:58,338 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:21:53 -0600] "GET /status HTTP/1.1" 200 65776 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:21:59,464 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:21:59,467 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:21:53 -0600] "GET /status HTTP/1.1" 200 65776 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:00,634 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:00,637 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:21:53 -0600] "GET /status HTTP/1.1" 200 65776 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:01,511 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:01,512 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:21:53 -0600] "GET /status HTTP/1.1" 200 65773 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:02,917 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:02,920 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:21:53 -0600] "GET /status HTTP/1.1" 200 65775 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:03,837 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:03,839 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:21:53 -0600] "GET /status HTTP/1.1" 200 65774 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:04,990 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:04,991 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:21:53 -0600] "GET /status HTTP/1.1" 200 65775 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:06,283 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:06,286 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:21:53 -0600] "GET /status HTTP/1.1" 200 65775 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:07,219 - p2p_orchestrator - WARNING - [VoterHealth] Status: 4/8 voters alive, quorum=OK, offline: ['hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:07,222 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:21:53 -0600] "GET /status HTTP/1.1" 200 65773 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:07,686 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:22:07 -0600] "GET /health HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:07,742 - p2p_orchestrator - INFO - LOCAL: Leader present but no work dispatched in 973s (timeout=120s) - self-assigning
2026-01-13 09:22:09,509 - p2p_orchestrator - INFO - LOCAL: Disk at 84% - skipping job starts
2026-01-13 09:22:09,509 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:22:11,049 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:22:13,782 - scripts.p2p.loops.http_server_health_loop - WARNING - [http_server_health] Health probe failed (consecutive: 1/4)
2026-01-13 09:22:13,827 - p2p_orchestrator - INFO - Retiring peer 192-222-50-48 (offline for 926s)
2026-01-13 09:22:13,828 - p2p_orchestrator - INFO - Retiring peer lambda-gh200-training (offline for 1010s)
2026-01-13 09:22:13,828 - p2p_orchestrator - INFO - Retiring peer lambda-gh200-4 (offline for 887s)
2026-01-13 09:22:13,828 - p2p_orchestrator - INFO - Retiring peer lambda-gh200-1 (offline for 766s)
2026-01-13 09:22:13,828 - p2p_orchestrator - INFO - Retiring peer lambda-gh200-3 (offline for 1005s)
2026-01-13 09:22:13,828 - p2p_orchestrator - INFO - Retiring peer ringrift-gpu (offline for 825s)
2026-01-13 09:22:13,828 - p2p_orchestrator - INFO - Retiring peer mbp-16gb (offline for 1176s)
2026-01-13 09:22:13,828 - p2p_orchestrator - INFO - Retiring peer lambda-gh200-9 (offline for 1004s)
2026-01-13 09:22:13,828 - p2p_orchestrator - INFO - Retiring peer local-mac (offline for 969s)
2026-01-13 09:22:13,828 - p2p_orchestrator - INFO - Retiring peer nebius-h100-1 (offline for 969s)
2026-01-13 09:22:13,828 - p2p_orchestrator - INFO - Retiring peer d6928e099d99 (offline for 968s)
2026-01-13 09:22:13,828 - p2p_orchestrator - INFO - Retiring peer MacBook-Pro-2.local (offline for 968s)
2026-01-13 09:22:13,828 - p2p_orchestrator - INFO - Retiring peer computeinstance-e00gyg7x6xhkc7fs5x (offline for 968s)
2026-01-13 09:22:13,828 - p2p_orchestrator - INFO - Retiring peer ringrift-cpu1 (offline for 967s)
2026-01-13 09:22:13,829 - p2p_orchestrator - INFO - Retiring peer computeinstance-e00hcbnn7s7p0c7bbp (offline for 967s)
2026-01-13 09:22:13,829 - p2p_orchestrator - INFO - Retiring peer b148b1697229 (offline for 967s)
2026-01-13 09:22:13,829 - p2p_orchestrator - INFO - Retiring peer vast-29031159 (offline for 967s)
2026-01-13 09:22:13,829 - p2p_orchestrator - INFO - Retiring peer lambda-gh200-11 (offline for 1007s)
2026-01-13 09:22:13,829 - p2p_orchestrator - INFO - Retiring peer Mac-Studio (offline for 2009s)
2026-01-13 09:22:13,829 - p2p_orchestrator - INFO - Retiring peer 46.62.217.168:7947 (offline for 988s)
2026-01-13 09:22:13,829 - p2p_orchestrator - INFO - Retiring peer 100.127.168.116:7947 (offline for 986s)
2026-01-13 09:22:13,829 - p2p_orchestrator - INFO - Retiring peer 100.94.174.19:7947 (offline for 985s)
2026-01-13 09:22:13,829 - p2p_orchestrator - INFO - Retiring peer 46.62.147.150:7947 (offline for 949s)
2026-01-13 09:22:13,829 - p2p_orchestrator - INFO - Peer hetzner-cpu1 is dead (no heartbeat for 90s)
2026-01-13 09:22:13,829 - p2p_orchestrator - INFO - Peer lambda-gh200-2 is dead (no heartbeat for 90s)
2026-01-13 09:22:13,829 - p2p_orchestrator - INFO - Peer 192-222-50-174 is dead (no heartbeat for 90s)
2026-01-13 09:22:13,829 - p2p_orchestrator - INFO - Peer lambda-gh200-8 is dead (no heartbeat for 90s)
2026-01-13 09:22:13,830 - p2p_orchestrator - INFO - Peer hetzner-cpu2 is dead (no heartbeat for 90s)
2026-01-13 09:22:13,830 - p2p_orchestrator - INFO - Peer 192-222-51-29 is dead (no heartbeat for 90s)
2026-01-13 09:22:13,830 - p2p_orchestrator - INFO - Peer 192-222-58-171 is dead (no heartbeat for 90s)
2026-01-13 09:22:13,831 - p2p_orchestrator - INFO - Clearing stale/expired leader lease: leader_id=hetzner-cpu2, is_self=False
2026-01-13 09:22:13,831 - p2p_orchestrator - INFO - [LeaderSet] follower->follower, leader_id=hetzner-cpu2->None, reason=stale_remote_lease
2026-01-13 09:22:13,832 - scripts.p2p.event_emission_mixin - INFO - [P2P Event] Emitted LEADER_LOST for hetzner-cpu2
2026-01-13 09:22:13,832 - p2p_orchestrator - INFO - Triggering election retry 1 after 15s leaderless
2026-01-13 09:22:17,623 - p2p_orchestrator - WARNING - [VoterHealth] Voter mac-studio went OFFLINE (3/8 alive, quorum=3)
2026-01-13 09:22:17,623 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:17,625 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:21:56 -0600] "GET /status HTTP/1.1" 200 65666 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:17,686 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked 192-222-50-48 as unhealthy: retired
2026-01-13 09:22:17,687 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: 192-222-50-48, cancelling jobs
2026-01-13 09:22:17,688 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: 192-222-50-48, reason=retired
2026-01-13 09:22:17,689 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked lambda-gh200-training as unhealthy: retired
2026-01-13 09:22:17,689 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: lambda-gh200-training, cancelling jobs
2026-01-13 09:22:17,689 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: lambda-gh200-training, reason=retired
2026-01-13 09:22:17,690 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked lambda-gh200-4 as unhealthy: retired
2026-01-13 09:22:17,690 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: lambda-gh200-4, cancelling jobs
2026-01-13 09:22:17,690 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: lambda-gh200-4, reason=retired
2026-01-13 09:22:17,691 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked lambda-gh200-1 as unhealthy: retired
2026-01-13 09:22:17,691 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: lambda-gh200-1, cancelling jobs
2026-01-13 09:22:17,691 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: lambda-gh200-1, reason=retired
2026-01-13 09:22:17,692 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked lambda-gh200-3 as unhealthy: retired
2026-01-13 09:22:17,692 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: lambda-gh200-3, cancelling jobs
2026-01-13 09:22:17,692 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: lambda-gh200-3, reason=retired
2026-01-13 09:22:17,693 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked ringrift-gpu as unhealthy: retired
2026-01-13 09:22:17,693 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: ringrift-gpu, cancelling jobs
2026-01-13 09:22:17,693 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: ringrift-gpu, reason=retired
2026-01-13 09:22:17,695 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked mbp-16gb as unhealthy: retired
2026-01-13 09:22:17,706 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: mbp-16gb, cancelling jobs
2026-01-13 09:22:17,709 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: mbp-16gb, reason=retired
2026-01-13 09:22:17,711 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked lambda-gh200-9 as unhealthy: retired
2026-01-13 09:22:17,711 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: lambda-gh200-9, cancelling jobs
2026-01-13 09:22:17,713 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: lambda-gh200-9, reason=retired
2026-01-13 09:22:17,716 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked local-mac as unhealthy: retired
2026-01-13 09:22:17,716 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: local-mac, cancelling jobs
2026-01-13 09:22:17,716 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: local-mac, reason=retired
2026-01-13 09:22:17,717 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked nebius-h100-1 as unhealthy: retired
2026-01-13 09:22:17,717 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: nebius-h100-1, cancelling jobs
2026-01-13 09:22:17,718 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: nebius-h100-1, reason=retired
2026-01-13 09:22:17,719 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked d6928e099d99 as unhealthy: retired
2026-01-13 09:22:17,719 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: d6928e099d99, cancelling jobs
2026-01-13 09:22:17,719 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: d6928e099d99, reason=retired
2026-01-13 09:22:17,720 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked MacBook-Pro-2.local as unhealthy: retired
2026-01-13 09:22:17,720 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: MacBook-Pro-2.local, cancelling jobs
2026-01-13 09:22:17,721 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: MacBook-Pro-2.local, reason=retired
2026-01-13 09:22:17,721 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked computeinstance-e00gyg7x6xhkc7fs5x as unhealthy: retired
2026-01-13 09:22:17,721 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: computeinstance-e00gyg7x6xhkc7fs5x, cancelling jobs
2026-01-13 09:22:17,722 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: computeinstance-e00gyg7x6xhkc7fs5x, reason=retired
2026-01-13 09:22:17,722 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked ringrift-cpu1 as unhealthy: retired
2026-01-13 09:22:17,723 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: ringrift-cpu1, cancelling jobs
2026-01-13 09:22:17,723 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: ringrift-cpu1, reason=retired
2026-01-13 09:22:17,723 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked computeinstance-e00hcbnn7s7p0c7bbp as unhealthy: retired
2026-01-13 09:22:17,724 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: computeinstance-e00hcbnn7s7p0c7bbp, cancelling jobs
2026-01-13 09:22:17,724 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: computeinstance-e00hcbnn7s7p0c7bbp, reason=retired
2026-01-13 09:22:17,725 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked b148b1697229 as unhealthy: retired
2026-01-13 09:22:17,725 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: b148b1697229, cancelling jobs
2026-01-13 09:22:17,725 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: b148b1697229, reason=retired
2026-01-13 09:22:17,727 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked vast-29031159 as unhealthy: retired
2026-01-13 09:22:17,727 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: vast-29031159, cancelling jobs
2026-01-13 09:22:17,727 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: vast-29031159, reason=retired
2026-01-13 09:22:17,728 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked lambda-gh200-11 as unhealthy: retired
2026-01-13 09:22:17,728 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: lambda-gh200-11, cancelling jobs
2026-01-13 09:22:17,729 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: lambda-gh200-11, reason=retired
2026-01-13 09:22:17,729 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked Mac-Studio as unhealthy: retired
2026-01-13 09:22:17,729 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: Mac-Studio, cancelling jobs
2026-01-13 09:22:17,730 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: Mac-Studio, reason=retired
2026-01-13 09:22:17,731 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked 46.62.217.168:7947 as unhealthy: retired
2026-01-13 09:22:17,731 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: 46.62.217.168:7947, cancelling jobs
2026-01-13 09:22:17,731 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: 46.62.217.168:7947, reason=retired
2026-01-13 09:22:17,731 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked 100.127.168.116:7947 as unhealthy: retired
2026-01-13 09:22:17,732 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: 100.127.168.116:7947, cancelling jobs
2026-01-13 09:22:17,732 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: 100.127.168.116:7947, reason=retired
2026-01-13 09:22:17,733 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked 100.94.174.19:7947 as unhealthy: retired
2026-01-13 09:22:17,733 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: 100.94.174.19:7947, cancelling jobs
2026-01-13 09:22:17,733 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: 100.94.174.19:7947, reason=retired
2026-01-13 09:22:17,734 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Marked 46.62.147.150:7947 as unhealthy: retired
2026-01-13 09:22:17,734 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_OFFLINE: 46.62.147.150:7947, cancelling jobs
2026-01-13 09:22:17,735 - scripts.p2p.managers.training_coordinator - WARNING - [TrainingCoordinator] P2P_NODE_DEAD: 46.62.147.150:7947, reason=retired
2026-01-13 09:22:18,763 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,764 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,764 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,764 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,764 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,764 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,764 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,764 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,765 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,765 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,765 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,765 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,765 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,765 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,765 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,765 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,765 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,765 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,765 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,765 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,765 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,765 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,765 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,765 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,766 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,766 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,767 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,767 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,768 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,770 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,770 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,770 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,771 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,771 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,771 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,772 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,772 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,772 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,772 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,772 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,772 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,773 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,773 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,773 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,773 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:18,773 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:18,979 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:22:18 -0600] "GET /health HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:20,510 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:22:20 -0600] "GET /health HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:20,511 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:22:20 -0600] "GET /peers HTTP/1.1" 404 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:20,848 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,864 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,900 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,900 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,901 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,901 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,901 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,902 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,902 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,902 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,902 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,902 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,902 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,903 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,903 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,903 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,904 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,905 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,905 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,905 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,905 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,905 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,905 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,905 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,906 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,906 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,906 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,906 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,906 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,908 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,908 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,908 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,909 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,909 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,909 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,909 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,909 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,909 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,909 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,909 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,909 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,909 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,909 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,910 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:20,910 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_removed node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:20,910 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:22,249 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:22:20 -0600] "GET /health HTTP/1.1" 200 732 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:23,499 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:22:20 -0600] "POST /heartbeat HTTP/1.1" 200 1941 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:22:23,500 - aiohttp.access - INFO - 100.71.89.91 [13/Jan/2026:09:22:20 -0600] "GET /health HTTP/1.1" 200 732 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:23,504 - aiohttp.access - INFO - fd7a:115c:a1e0::4f01:ae13 [13/Jan/2026:09:22:18 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:22:24,332 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:24,334 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:22:13 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:22:24,339 - p2p_orchestrator - WARNING - No valid leader (current: None), attempting bootstrap...
2026-01-13 09:22:24,360 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:22:24 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:25,649 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:25,651 - aiohttp.access - INFO - 100.121.230.110 [13/Jan/2026:09:22:18 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:26,584 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:26,586 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:22:18 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:26,587 - aiohttp.access - INFO - fd7a:115c:a1e0::2e01:d06c [13/Jan/2026:09:22:20 -0600] "POST /gossip HTTP/1.1" 200 5731 "-" "Python/3.10 aiohttp/3.13.2"
Metrics Report: {'timestamp': 1768317747.1213682, 'node_id': '0.0.0.0:7947', 'metrics': {'node_event': {'events': {'start': 1}}, 'ping_timeout': {'gauge': 0.5}, 'probe_result': {'counter': 57}, 'ping': {'events': {'failure': 11}}, 'peer_rtt': {'histogram': {'count': 11, 'min': 0.0014598369598388672, 'max': 234.6769700050354, 'mean': 22.978784322738647, 'stdev': 70.33821384640088, 'p95': 234.6769700050354, 'p99': 234.6769700050354}}, 'timeout_adjustment': {'events': {'1.000->0.500': 1}}, 'member_count': {'gauge': 8}, 'protocol_cycle_duration': {'histogram': {'count': 99, 'min': 6.29425048828125e-05, 'max': 318.1459758281708, 'mean': 5.36836612826646, 'stdev': 34.3956399459302, 'p95': 4.0877649784088135, 'p99': 318.1459758281708}}, 'protocol_period': {'gauge': 2.0}, 'suspect_timeout': {'gauge': 15.0, 'events': {'100.126.21.102:7947': 1, '100.109.195.71:7947': 1, '100.94.174.19:7947': 1, '100.68.208.43:7947': 1, '100.94.201.92:7947': 1, '100.107.168.125:7947': 1, '100.67.131.72:7947': 1}}, 'probe_count': {'gauge': 8}, 'indirect_probe': {'events': {'failure': 21}}}}
2026-01-13 09:22:27,707 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:27,709 - aiohttp.access - INFO - 100.106.87.89 [13/Jan/2026:09:22:20 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:28,850 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:28,853 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:22:20 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:30,417 - aiohttp.access - INFO - 100.121.230.110 [13/Jan/2026:09:22:28 -0600] "POST /heartbeat HTTP/1.1" 200 1941 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:30,419 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:22:28 -0600] "GET /health HTTP/1.1" 200 732 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:30,419 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:22:28 -0600] "GET /peers HTTP/1.1" 404 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:30,423 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-dac04483: selfplay (source: autonomous)
2026-01-13 09:22:30,424 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-dac04483: selfplay_enabled=false for this node
2026-01-13 09:22:31,641 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:31,643 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:22:20 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:32,037 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:22:31 -0600] "GET /health HTTP/1.1" 200 730 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:32,073 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:22:32 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:33,628 - p2p_orchestrator - INFO - [LeaderSet] follower->follower, leader_id=None->hetzner-cpu2, reason=continuous_bootstrap_discover_leader
2026-01-13 09:22:33,647 - p2p_orchestrator - INFO - Bootstrap from 100.94.174.19:8770: imported 28 peers
2026-01-13 09:22:35,693 - p2p_orchestrator - WARNING - [VoterHealth] Voter lambda-gh200-training went OFFLINE (3/8 alive, quorum=3)
2026-01-13 09:22:35,694 - p2p_orchestrator - INFO - [VoterHealth] Voter hetzner-cpu1 came ONLINE (3/8 alive, quorum=3)
2026-01-13 09:22:35,694 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:35,696 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:22:28 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:38,084 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:38,087 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:22:30 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:39,049 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:39,051 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:22:30 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:22:39,051 - aiohttp.access - INFO - fd7a:115c:a1e0::1d01:1390 [13/Jan/2026:09:22:32 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:39,052 - scripts.p2p.loops.http_server_health_loop - INFO - [http_server_health] HTTP server recovered after 1 failures
2026-01-13 09:22:39,052 - p2p_orchestrator - INFO - Bootstrap successful! Now have 16 alive peers
2026-01-13 09:22:40,490 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Recovered node lambda-gh200-4 from unhealthy state (alive=True, healthy=True)
2026-01-13 09:22:40,490 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Recovered node lambda-gh200-3 from unhealthy state (alive=True, healthy=True)
2026-01-13 09:22:40,490 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Recovered node lambda-gh200-1 from unhealthy state (alive=True, healthy=True)
2026-01-13 09:22:40,492 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Recovered node 192-222-50-48 from unhealthy state (alive=True, healthy=True)
2026-01-13 09:22:40,492 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Recovered 4 nodes from unhealthy state: ['lambda-gh200-4', 'lambda-gh200-3', 'lambda-gh200-1', '192-222-50-48']
2026-01-13 09:22:40,492 - scripts.p2p.loops.coordination_loops - INFO - [HealthAggregation] Auto-recovered 4 nodes: ['lambda-gh200-4', 'lambda-gh200-3', 'lambda-gh200-1', '192-222-50-48']
2026-01-13 09:22:41,779 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:22:40 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:41,781 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:22:40 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:41,838 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:22:39 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:43,048 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:22:39 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:43,092 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-ca6d2968: selfplay (source: autonomous)
2026-01-13 09:22:43,092 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-ca6d2968: selfplay_enabled=false for this node
2026-01-13 09:22:43,093 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:22:41 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:22:45,094 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:45,096 - aiohttp.access - INFO - 100.83.177.16 [13/Jan/2026:09:22:40 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:45,097 - p2p_orchestrator - INFO - Reconnected to dead peer 192-222-51-29 (was dead for 685s)
2026-01-13 09:22:46,353 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:22:44 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:46,354 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 192-222-51-29, invalidating cluster manifest
2026-01-13 09:22:46,354 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 192-222-51-29, node available for jobs
2026-01-13 09:22:46,355 - p2p_orchestrator - INFO - Recovered retired peer via probe: lambda-gh200-1
2026-01-13 09:22:46,381 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-1, invalidating cluster manifest
2026-01-13 09:22:46,382 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-1, node available for jobs
2026-01-13 09:22:46,387 - aiohttp.access - INFO - fd7a:115c:a1e0::4f01:ae13 [13/Jan/2026:09:22:43 -0600] "POST /gossip HTTP/1.1" 200 5977 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:22:46,388 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_added node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:46,388 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:47,815 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:22:46 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:22:47,857 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:22:46 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:22:49,064 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_added node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:49,066 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:49,135 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:22:46 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:50,156 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:22:49 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:51,136 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:51,139 - aiohttp.access - INFO - 100.71.89.91 [13/Jan/2026:09:22:46 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:51,155 - p2p_orchestrator - INFO - Recovered retired peer via probe: lambda-gh200-3
2026-01-13 09:22:51,202 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-3, invalidating cluster manifest
2026-01-13 09:22:51,203 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-3, node available for jobs
2026-01-13 09:22:51,219 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_added node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:51,231 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:22:51 -0600] "GET /health HTTP/1.1" 200 353 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:51,232 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:51,240 - p2p_orchestrator - INFO - Reconnected to dead peer 192-222-57-184 (was dead for 539s)
2026-01-13 09:22:52,724 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 192-222-57-184, invalidating cluster manifest
2026-01-13 09:22:52,725 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 192-222-57-184, node available for jobs
2026-01-13 09:22:52,726 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_added node=unknown, total=43, gpu=0, reason=
2026-01-13 09:22:52,726 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:22:54,032 - aiohttp.access - INFO - 100.106.87.89 [13/Jan/2026:09:22:52 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:54,033 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:22:52 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:54,038 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-52ad96fe: selfplay (source: autonomous)
2026-01-13 09:22:54,039 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-52ad96fe: selfplay_enabled=false for this node
2026-01-13 09:22:54,292 - p2p_orchestrator - INFO - Reconnected to dead peer 192-222-58-171 (was dead for 537s)
2026-01-13 09:22:55,463 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 192-222-58-171, invalidating cluster manifest
2026-01-13 09:22:55,463 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 192-222-58-171, node available for jobs
2026-01-13 09:22:57,062 - aiohttp.access - INFO - 100.106.87.89 [13/Jan/2026:09:22:56 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:58,271 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:22:57 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:59,394 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:22:59,395 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:22:56 -0600] "GET /status HTTP/1.1" 200 72806 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:22:59,396 - p2p_orchestrator - INFO - Reconnected to dead peer local-mac (was dead for 720s)
2026-01-13 09:23:00,669 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Cleared unhealthy status for local-mac
2026-01-13 09:23:00,669 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: local-mac, invalidating cluster manifest
2026-01-13 09:23:00,669 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: local-mac, node available for jobs
2026-01-13 09:23:00,670 - p2p_orchestrator - INFO - Recovered retired peer via probe: mbp-16gb
2026-01-13 09:23:00,671 - app.coordination.sync_router - INFO - [SyncRouter] Added new node: 127.0.0.1
2026-01-13 09:23:00,671 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Cleared unhealthy status for mbp-16gb
2026-01-13 09:23:00,671 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: mbp-16gb, invalidating cluster manifest
2026-01-13 09:23:00,671 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: mbp-16gb, node available for jobs
2026-01-13 09:23:00,672 - app.coordination.sync_router - INFO - [SyncRouter] Added new node: 100.66.142.46
2026-01-13 09:23:00,675 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_added node=unknown, total=43, gpu=0, reason=
2026-01-13 09:23:00,675 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:23:00,677 - aiohttp.access - INFO - 100.83.177.16 [13/Jan/2026:09:23:00 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:00,678 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_added node=unknown, total=43, gpu=0, reason=
2026-01-13 09:23:00,678 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:23:02,027 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:00 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:02,042 - p2p_orchestrator - INFO - Reconnected to dead peer nebius-h100-1 (was dead for 720s)
2026-01-13 09:23:03,409 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Cleared unhealthy status for nebius-h100-1
2026-01-13 09:23:03,409 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: nebius-h100-1, invalidating cluster manifest
2026-01-13 09:23:03,409 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: nebius-h100-1, node available for jobs
2026-01-13 09:23:03,411 - p2p_orchestrator - INFO - Recovered retired peer via probe: lambda-gh200-9
2026-01-13 09:23:03,414 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Cleared unhealthy status for lambda-gh200-9
2026-01-13 09:23:03,414 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-9, invalidating cluster manifest
2026-01-13 09:23:03,414 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-9, node available for jobs
2026-01-13 09:23:03,416 - app.coordination.sync_router - INFO - [SyncRouter] Added new node: 100.127.168.116
2026-01-13 09:23:03,417 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_added node=unknown, total=43, gpu=0, reason=
2026-01-13 09:23:03,417 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:23:04,853 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:23:03 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:23:04,906 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_added node=unknown, total=43, gpu=0, reason=
2026-01-13 09:23:04,928 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:23:06,444 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:04 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:06,449 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:06 -0600] "GET /health HTTP/1.1" 200 355 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:06,656 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:06 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:08,117 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:23:08,245 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:23:03 -0600] "GET /status HTTP/1.1" 200 79779 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:23:08,245 - p2p_orchestrator - INFO - Reconnected to dead peer d6928e099d99 (was dead for 720s)
2026-01-13 09:23:09,774 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Cleared unhealthy status for d6928e099d99
2026-01-13 09:23:09,775 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: d6928e099d99, invalidating cluster manifest
2026-01-13 09:23:09,775 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: d6928e099d99, node available for jobs
2026-01-13 09:23:09,841 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:23:09,843 - p2p_orchestrator - WARNING - [VoterHealth] QUORUM THREATENED: 3/8 voters alive (at threshold of 3)
2026-01-13 09:23:09,844 - p2p_orchestrator - INFO - Recovered retired peer via probe: local-mac
2026-01-13 09:23:09,850 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: local-mac, invalidating cluster manifest
2026-01-13 09:23:09,928 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: local-mac, node available for jobs
2026-01-13 09:23:09,935 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_added node=unknown, total=43, gpu=0, reason=
2026-01-13 09:23:09,936 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:23:11,589 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:23:11,592 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:23:06 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:23:12,449 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-4055df9f: selfplay (source: autonomous)
2026-01-13 09:23:12,449 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-4055df9f: selfplay_enabled=false for this node
2026-01-13 09:23:12,450 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_added node=unknown, total=43, gpu=0, reason=
2026-01-13 09:23:12,450 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:23:13,879 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:12 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:13,963 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:13 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:15,518 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:23:15,521 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:23:11 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:15,521 - p2p_orchestrator - INFO - Reconnected to dead peer MacBook-Pro-2.local (was dead for 720s)
2026-01-13 09:23:16,935 - p2p_orchestrator - INFO - Recovered retired peer via probe: nebius-h100-1
2026-01-13 09:23:16,936 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Cleared unhealthy status for MacBook-Pro-2.local
2026-01-13 09:23:16,937 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: MacBook-Pro-2.local, invalidating cluster manifest
2026-01-13 09:23:16,937 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: MacBook-Pro-2.local, node available for jobs
2026-01-13 09:23:16,937 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: nebius-h100-1, invalidating cluster manifest
2026-01-13 09:23:16,937 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: nebius-h100-1, node available for jobs
2026-01-13 09:23:16,954 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_added node=unknown, total=43, gpu=0, reason=
2026-01-13 09:23:16,954 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:23:16,964 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:16 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:16,965 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:16 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:16,965 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:16 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:16,966 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_added node=unknown, total=43, gpu=0, reason=
2026-01-13 09:23:16,966 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:23:17,211 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:23:16 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:23:18,819 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:17 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:18,832 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:18 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:18,834 - p2p_orchestrator - INFO - Recovered retired peer via probe: d6928e099d99
2026-01-13 09:23:20,229 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:23:20,232 - aiohttp.access - INFO - 100.106.87.89 [13/Jan/2026:09:23:16 -0600] "GET /status HTTP/1.1" 200 83141 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:20,233 - p2p_orchestrator - INFO - Reconnected to dead peer computeinstance-e00gyg7x6xhkc7fs5x (was dead for 719s)
2026-01-13 09:23:21,698 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: d6928e099d99, invalidating cluster manifest
2026-01-13 09:23:21,698 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: d6928e099d99, node available for jobs
2026-01-13 09:23:21,699 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Cleared unhealthy status for computeinstance-e00gyg7x6xhkc7fs5x
2026-01-13 09:23:21,699 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: computeinstance-e00gyg7x6xhkc7fs5x, invalidating cluster manifest
2026-01-13 09:23:21,699 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: computeinstance-e00gyg7x6xhkc7fs5x, node available for jobs
2026-01-13 09:23:21,701 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_added node=unknown, total=43, gpu=0, reason=
2026-01-13 09:23:21,701 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:23:23,424 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_added node=unknown, total=43, gpu=0, reason=
2026-01-13 09:23:23,424 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:23:24,446 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:23:24 -0600] "GET /health HTTP/1.1" 200 737 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:23:24,448 - aiohttp.access - INFO - 100.83.177.16 [13/Jan/2026:09:23:24 -0600] "GET /health HTTP/1.1" 200 738 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:24,448 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:23:24 -0600] "GET /health HTTP/1.1" 200 738 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:26,172 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-74587b46: selfplay (source: autonomous)
2026-01-13 09:23:26,172 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-74587b46: selfplay_enabled=false for this node
Metrics Report: {'timestamp': 1768317807.127875, 'node_id': '0.0.0.0:7947', 'metrics': {'node_event': {'events': {'start': 1}}, 'ping_timeout': {'gauge': 0.5}, 'probe_result': {'counter': 57}, 'ping': {'events': {'failure': 11}}, 'peer_rtt': {'histogram': {'count': 11, 'min': 0.0014598369598388672, 'max': 234.6769700050354, 'mean': 22.978784322738647, 'stdev': 70.33821384640088, 'p95': 234.6769700050354, 'p99': 234.6769700050354}}, 'timeout_adjustment': {'events': {'1.000->0.500': 1}}, 'member_count': {'gauge': 8}, 'protocol_cycle_duration': {'histogram': {'count': 116, 'min': 6.29425048828125e-05, 'max': 318.1459758281708, 'mean': 4.581666775818529, 'stdev': 31.8089359879219, 'p95': 3.891355037689209, 'p99': 100.23378777503967}}, 'protocol_period': {'gauge': 2.0}, 'suspect_timeout': {'gauge': 15.0, 'events': {'100.126.21.102:7947': 1, '100.109.195.71:7947': 1, '100.94.174.19:7947': 1, '100.68.208.43:7947': 1, '100.94.201.92:7947': 1, '100.107.168.125:7947': 1, '100.67.131.72:7947': 1}}, 'probe_count': {'gauge': 8}, 'indirect_probe': {'events': {'failure': 21}}}}
2026-01-13 09:23:27,730 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:23:26 -0600] "POST /heartbeat HTTP/1.1" 200 1952 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:23:27,769 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:27 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:27,815 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:27 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:27,964 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:23:27 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:23:29,079 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:23:29,093 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:23:24 -0600] "GET /status HTTP/1.1" 200 84835 "-" "curl/8.7.1"
2026-01-13 09:23:29,093 - p2p_orchestrator - INFO - Recovered retired peer via probe: MacBook-Pro-2.local
2026-01-13 09:23:29,098 - p2p_orchestrator - INFO - Reconnected to dead peer ringrift-cpu1 (was dead for 719s)
2026-01-13 09:23:30,600 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: MacBook-Pro-2.local, invalidating cluster manifest
2026-01-13 09:23:30,600 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: MacBook-Pro-2.local, node available for jobs
2026-01-13 09:23:30,616 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Cleared unhealthy status for ringrift-cpu1
2026-01-13 09:23:30,617 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: ringrift-cpu1, invalidating cluster manifest
2026-01-13 09:23:30,617 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: ringrift-cpu1, node available for jobs
2026-01-13 09:23:30,630 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:23:30 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:31,910 - p2p_orchestrator - WARNING - [VoterHealth] Voter hetzner-cpu3 went OFFLINE (2/8 alive, quorum=3)
2026-01-13 09:23:31,913 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:23:31,916 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:24 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:33,145 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:23:33,147 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:24 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:34,633 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:23:34,635 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:24 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:36,305 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:23:36,307 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:24 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:37,600 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:23:37,603 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:24 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:38,984 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:23:38,988 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:24 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:40,364 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:23:40,367 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:24 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:41,601 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:23:41,604 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:24 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:42,974 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:23:42,977 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:24 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:42,977 - app.coordination.sync_router - INFO - [SyncRouter] Added new node: 100.94.174.19
2026-01-13 09:23:42,978 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_added node=unknown, total=43, gpu=0, reason=
2026-01-13 09:23:43,004 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:23:44,558 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:23:44,561 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:23:26 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:46,041 - p2p_orchestrator - INFO - LOCAL: Disk at 84% - skipping job starts
2026-01-13 09:23:46,041 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:23:48,363 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:23:48,363 - p2p_orchestrator - INFO - LOCAL: Memory at 92% - skipping GPU auto-scale
2026-01-13 09:23:49,811 - app.coordination.sync_router - INFO - [SyncRouter] Cluster capacity changed: node_added node=unknown, total=43, gpu=0, reason=
2026-01-13 09:23:49,814 - app.coordination.sync_router - WARNING - [SyncRouter] Error handling cluster capacity changed: 'ClusterManifest' object has no attribute 'refresh_capacity_data'
2026-01-13 09:23:49,842 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:23:49 -0600] "GET /peers HTTP/1.1" 404 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:52,108 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:23:52,112 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:23:30 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:53,462 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:50 -0600] "POST /heartbeat HTTP/1.1" 200 1955 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:53,463 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:23:50 -0600] "GET /health HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:54,579 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:23:50 -0600] "POST /heartbeat HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:23:54,581 - aiohttp.access - INFO - 100.106.87.89 [13/Jan/2026:09:23:50 -0600] "GET /health HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:55,785 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:23:50 -0600] "POST /heartbeat HTTP/1.1" 200 1955 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:56,104 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:23:55 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:23:57,449 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:23:55 -0600] "POST /heartbeat HTTP/1.1" 200 1955 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:23:57,450 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:23:55 -0600] "GET /peers HTTP/1.1" 404 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:23:59,756 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:23:59,763 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:23:49 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:01,069 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:24:01,071 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:23:49 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:24:02,400 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:24:02,404 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:23:49 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:24:06,260 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:24:04 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:06,290 - p2p_orchestrator - INFO - [RelayHealthCheck] Relay hetzner-cpu3 unhealthy for lambda-gh200-training, switching to hetzner-cpu1
2026-01-13 09:24:06,291 - p2p_orchestrator - INFO - [RelayHealthCheck] Relay hetzner-cpu3 unhealthy for hetzner-cpu2, switching to hetzner-cpu1
2026-01-13 09:24:07,567 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:24:07,569 - aiohttp.access - INFO - 100.83.177.16 [13/Jan/2026:09:23:50 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:08,990 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:24:08,994 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:23:55 -0600] "GET /status HTTP/1.1" 200 80962 "-" "curl/8.7.1"
2026-01-13 09:24:08,996 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-cf088b5f: selfplay (source: autonomous)
2026-01-13 09:24:08,996 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-cf088b5f: selfplay_enabled=false for this node
2026-01-13 09:24:09,096 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:24:04 -0600] "GET /game_counts HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:24:09,098 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:24:04 -0600] "GET /game_counts HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:24:09,102 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:24:09 -0600] "GET /health HTTP/1.1" 200 355 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:11,062 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:24:09 -0600] "POST /heartbeat HTTP/1.1" 200 1951 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:24:11,064 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:24:09 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:24:11,065 - aiohttp.access - INFO - 100.83.177.16 [13/Jan/2026:09:24:09 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:11,070 - aiohttp.access - INFO - 100.83.177.16 [13/Jan/2026:09:24:09 -0600] "GET /peers HTTP/1.1" 404 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:11,119 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:24:09 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:11,169 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:24:09 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:24:12,932 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:24:12,935 - aiohttp.access - INFO - 100.71.89.91 [13/Jan/2026:09:23:58 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:14,507 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:24:12 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:14,510 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:24:12 -0600] "GET /health HTTP/1.1" 200 753 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:24:14,511 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:24:12 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:17,381 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:24:14 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:18,766 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:24:18,767 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:24:09 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python-urllib/3.10"
2026-01-13 09:24:19,958 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:24:20,126 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:24:09 -0600] "GET /status HTTP/1.1" 200 77221 "-" "curl/8.7.1"
2026-01-13 09:24:20,689 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:24:20,691 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:24:09 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:21,002 - aiohttp.access - INFO - fd7a:115c:a1e0::1:611a [13/Jan/2026:09:24:14 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:24:21,003 - p2p_orchestrator - INFO - Reconnected to dead peer b148b1697229 (was dead for 718s)
2026-01-13 09:24:24,877 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:24:24,879 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:24:12 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:24:26,449 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:24:26,452 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:24:12 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:24:26,453 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:24:20 -0600] "GET /health HTTP/1.1" 200 753 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:26,454 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:24:20 -0600] "GET /health HTTP/1.1" 200 754 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:26,455 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:24:20 -0600] "GET /health HTTP/1.1" 200 753 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:26,488 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:24:20 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:26,524 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:24:20 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:26,579 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Cleared unhealthy status for b148b1697229
2026-01-13 09:24:26,579 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: b148b1697229, invalidating cluster manifest
2026-01-13 09:24:26,580 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: b148b1697229, node available for jobs
Metrics Report: {'timestamp': 1768317867.137321, 'node_id': '0.0.0.0:7947', 'metrics': {'node_event': {'events': {'start': 1}}, 'ping_timeout': {'gauge': 0.5}, 'probe_result': {'counter': 57}, 'ping': {'events': {'failure': 11}}, 'peer_rtt': {'histogram': {'count': 11, 'min': 0.0014598369598388672, 'max': 234.6769700050354, 'mean': 22.978784322738647, 'stdev': 70.33821384640088, 'p95': 234.6769700050354, 'p99': 234.6769700050354}}, 'timeout_adjustment': {'events': {'1.000->0.500': 1}}, 'member_count': {'gauge': 8}, 'protocol_cycle_duration': {'histogram': {'count': 124, 'min': 6.29425048828125e-05, 'max': 318.1459758281708, 'mean': 4.286101154742703, 'stdev': 30.777861136707745, 'p95': 3.2960898876190186, 'p99': 100.23378777503967}}, 'protocol_period': {'gauge': 2.0}, 'suspect_timeout': {'gauge': 15.0, 'events': {'100.126.21.102:7947': 1, '100.109.195.71:7947': 1, '100.94.174.19:7947': 1, '100.68.208.43:7947': 1, '100.94.201.92:7947': 1, '100.107.168.125:7947': 1, '100.67.131.72:7947': 1}}, 'probe_count': {'gauge': 8}, 'indirect_probe': {'events': {'failure': 21}}}}
2026-01-13 09:24:27,159 - aiohttp.access - INFO - 100.106.87.89 [13/Jan/2026:09:24:27 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:28,631 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:24:27 -0600] "POST /heartbeat HTTP/1.1" 200 1952 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:30,233 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:24:27 -0600] "POST /heartbeat HTTP/1.1" 200 1944 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:30,237 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:24:20 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:24:30,239 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-5649de9d: selfplay (source: autonomous)
2026-01-13 09:24:30,272 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-5649de9d: selfplay_enabled=false for this node
2026-01-13 09:24:32,005 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:24:30 -0600] "GET /health HTTP/1.1" 200 757 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:32,010 - p2p_orchestrator - WARNING - handle_status: gossip_metrics timed out
2026-01-13 09:24:32,011 - p2p_orchestrator - WARNING - handle_status: distributed_training timed out
2026-01-13 09:24:32,011 - p2p_orchestrator - WARNING - handle_status: cluster_elo timed out
2026-01-13 09:24:32,011 - p2p_orchestrator - WARNING - handle_status: node_recovery timed out
2026-01-13 09:24:32,011 - p2p_orchestrator - WARNING - handle_status: leader_consensus timed out
2026-01-13 09:24:32,012 - p2p_orchestrator - WARNING - handle_status: peer_reputation timed out
2026-01-13 09:24:32,012 - p2p_orchestrator - WARNING - handle_status: sync_intervals timed out
2026-01-13 09:24:32,012 - p2p_orchestrator - WARNING - handle_status: tournament_scheduling timed out
2026-01-13 09:24:32,012 - p2p_orchestrator - WARNING - handle_status: data_dedup timed out
2026-01-13 09:24:33,474 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:24:33 -0600] "GET /peers HTTP/1.1" 404 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:24:33,821 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:24:33 -0600] "GET /health HTTP/1.1" 200 757 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:35,335 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:24:33 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:24:37,084 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:24:37,086 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:24:20 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:38,747 - p2p_orchestrator - WARNING - handle_status: gossip_metrics timed out
2026-01-13 09:24:38,747 - p2p_orchestrator - WARNING - handle_status: distributed_training timed out
2026-01-13 09:24:38,747 - p2p_orchestrator - WARNING - handle_status: cluster_elo timed out
2026-01-13 09:24:38,747 - p2p_orchestrator - WARNING - handle_status: node_recovery timed out
2026-01-13 09:24:38,748 - p2p_orchestrator - WARNING - handle_status: leader_consensus timed out
2026-01-13 09:24:38,748 - p2p_orchestrator - WARNING - handle_status: peer_reputation timed out
2026-01-13 09:24:38,748 - p2p_orchestrator - WARNING - handle_status: sync_intervals timed out
2026-01-13 09:24:38,748 - p2p_orchestrator - WARNING - handle_status: tournament_scheduling timed out
2026-01-13 09:24:38,748 - p2p_orchestrator - WARNING - handle_status: data_dedup timed out
2026-01-13 09:24:38,748 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:24:27 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:40,007 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:24:38 -0600] "POST /heartbeat HTTP/1.1" 200 1945 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:41,400 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:24:38 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:24:41,569 - aiohttp.access - INFO - fd7a:115c:a1e0::4f01:ae13 [13/Jan/2026:09:24:30 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:24:41,587 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:24:41 -0600] "GET /work/pending HTTP/1.1" 404 174 "-" "curl/8.7.1"
2026-01-13 09:24:42,916 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:24:42,919 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:24:26 -0600] "GET /status HTTP/1.1" 200 64919 "-" "curl/8.7.1"
2026-01-13 09:24:43,046 - aiohttp.access - INFO - 100.121.230.110 [13/Jan/2026:09:24:38 -0600] "GET /game_counts HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:43,068 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:24:41 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:45,022 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:24:41 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:46,432 - aiohttp.access - INFO - 100.71.89.91 [13/Jan/2026:09:24:41 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:46,435 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:24:33 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:24:47,494 - scripts.p2p.loops.gossip_state_cleanup_loop - INFO - [GossipStateCleanup] Purged 38 entries: states=0, manifests=0, recovery=0, reputation=0, endpoints=38, promotion=0, jobs=0
2026-01-13 09:24:48,955 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:24:48,958 - aiohttp.access - INFO - 100.106.87.89 [13/Jan/2026:09:24:33 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:49,132 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:24:47 -0600] "GET /peers HTTP/1.1" 404 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:50,824 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:24:47 -0600] "POST /heartbeat HTTP/1.1" 200 1952 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:24:52,317 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:24:47 -0600] "POST /heartbeat HTTP/1.1" 200 1942 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:52,731 - scripts.p2p.loops.http_server_health_loop - WARNING - [http_server_health] Health probe failed (consecutive: 1/4)
2026-01-13 09:24:54,131 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:24:54 -0600] "GET /health HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:24:55,549 - app.coordination.work_queue - INFO -  Added work training_square19_4p_1768317895453: training (priority: 100)
2026-01-13 09:24:55,569 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:24:54 -0600] "POST /heartbeat HTTP/1.1" 200 1954 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:24:57,010 - scripts.p2p.loops.cluster_healing_loop - WARNING - [ClusterHealing] Failed to load hosts YAML: 'str' object has no attribute 'get'
2026-01-13 09:25:00,209 - aiohttp.access - INFO - 100.83.177.16 [13/Jan/2026:09:24:57 -0600] "POST /heartbeat HTTP/1.1" 200 1944 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:00,211 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:24:57 -0600] "GET /health HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:00,213 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:25:00 -0600] "GET /work/pending HTTP/1.1" 404 174 "-" "curl/8.7.1"
2026-01-13 09:25:02,575 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:25:02,578 - aiohttp.access - INFO - 100.77.186.124 [13/Jan/2026:09:24:47 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:03,708 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:25:03,826 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:24:47 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:04,908 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:25:04,910 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:24:47 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:25:06,670 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:25:06,673 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:24:47 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:25:06,676 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:25:00 -0600] "GET /health HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:25:07,848 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:25:00 -0600] "POST /heartbeat HTTP/1.1" 200 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:25:09,417 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:25:00 -0600] "POST /heartbeat HTTP/1.1" 200 1945 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:25:10,824 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:25:00 -0600] "POST /heartbeat HTTP/1.1" 200 1955 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:25:13,621 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:25:12 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:25:14,945 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:25:12 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:16,347 - aiohttp.access - INFO - 100.83.177.16 [13/Jan/2026:09:25:12 -0600] "POST /heartbeat HTTP/1.1" 200 1955 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:16,351 - aiohttp.access - INFO - fd7a:115c:a1e0::4f01:ae13 [13/Jan/2026:09:25:00 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:25:16,374 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:25:00 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:25:19,222 - aiohttp.access - INFO - 100.121.230.110 [13/Jan/2026:09:25:16 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:19,224 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:25:16 -0600] "GET /health HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:19,224 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:25:16 -0600] "GET /peers HTTP/1.1" 404 0 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:25:20,657 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:25:16 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:25:21,073 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-d8b0d554: selfplay (source: autonomous)
2026-01-13 09:25:21,073 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-d8b0d554: selfplay_enabled=false for this node
2026-01-13 09:25:22,769 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:25:22,773 - aiohttp.access - INFO - 100.83.177.16 [13/Jan/2026:09:25:00 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:22,910 - aiohttp.access - INFO - 100.71.89.91 [13/Jan/2026:09:25:22 -0600] "GET /health HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:24,405 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:25:22 -0600] "POST /heartbeat HTTP/1.1" 200 1953 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:24,704 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:25:16 -0600] "POST /gossip HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:24,813 - scripts.p2p.loops.http_server_health_loop - WARNING - [http_server_health] Health probe failed (consecutive: 2/4)
2026-01-13 09:25:26,022 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:25:26,058 - aiohttp.access - INFO - 100.71.89.91 [13/Jan/2026:09:25:12 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:27,080 - scripts.p2p.loops.data_loops - INFO - [data_management] Disk at 83.7% (warning: 70.0%), triggering cleanup
2026-01-13 09:25:27,081 - p2p_orchestrator - INFO - Running local disk cleanup...
Metrics Report: {'timestamp': 1768317927.146997, 'node_id': '0.0.0.0:7947', 'metrics': {'node_event': {'events': {'start': 1}}, 'ping_timeout': {'gauge': 0.5}, 'probe_result': {'counter': 57}, 'ping': {'events': {'failure': 11}}, 'peer_rtt': {'histogram': {'count': 11, 'min': 0.0014598369598388672, 'max': 234.6769700050354, 'mean': 22.978784322738647, 'stdev': 70.33821384640088, 'p95': 234.6769700050354, 'p99': 234.6769700050354}}, 'timeout_adjustment': {'events': {'1.000->0.500': 1}}, 'member_count': {'gauge': 8}, 'protocol_cycle_duration': {'histogram': {'count': 131, 'min': 6.29425048828125e-05, 'max': 318.1459758281708, 'mean': 4.057091521852799, 'stdev': 29.953392240321712, 'p95': 3.2960898876190186, 'p99': 100.23378777503967}}, 'protocol_period': {'gauge': 2.0}, 'suspect_timeout': {'gauge': 15.0, 'events': {'100.126.21.102:7947': 1, '100.109.195.71:7947': 1, '100.94.174.19:7947': 1, '100.68.208.43:7947': 1, '100.94.201.92:7947': 1, '100.107.168.125:7947': 1, '100.67.131.72:7947': 1}}, 'probe_count': {'gauge': 8}, 'indirect_probe': {'events': {'failure': 21}}}}
2026-01-13 09:25:29,353 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:25:32,944 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:25:32 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:25:32,946 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:25:32 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:25:33,664 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:25:33,667 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:25:16 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:34,596 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:25:34,597 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:25:16 -0600] "GET /status HTTP/1.1" 200 60532 "-" "curl/8.7.1"
2026-01-13 09:25:34,718 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:25:34 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:36,055 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:25:36,062 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:25:22 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:25:37,465 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:25:37,468 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:25:22 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:25:37,490 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:25:37 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:25:37,505 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-5a1eae27: selfplay (source: autonomous)
2026-01-13 09:25:37,521 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-5a1eae27: selfplay_enabled=false for this node
2026-01-13 09:25:40,298 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:25:40,301 - aiohttp.access - INFO - 100.127.168.116 [13/Jan/2026:09:25:32 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:41,968 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:25:38 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:25:41,983 - p2p_orchestrator - INFO - Voter lambda-gh200-training (key=lambda-gh200-training) NAT-blocked status cleared (heartbeat succeeded)
2026-01-13 09:25:45,077 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:25:45 -0600] "GET /health HTTP/1.1" 200 355 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:46,581 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:25:45 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:46,585 - scripts.p2p.loops.http_server_health_loop - INFO - [http_server_health] HTTP server recovered after 2 failures
2026-01-13 09:25:46,586 - aiohttp.access - INFO - fd7a:115c:a1e0::a001:a888 [13/Jan/2026:09:25:45 -0600] "POST /gossip HTTP/1.1" 200 5867 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:25:47,632 - p2p_orchestrator - INFO - [VoterHealth] Voter lambda-gh200-training came ONLINE (3/8 alive, quorum=3)
2026-01-13 09:25:47,632 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:25:47,635 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:25:45 -0600] "GET /status HTTP/1.1" 200 60898 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:25:49,153 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:25:49,154 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:25:45 -0600] "GET /status HTTP/1.1" 200 60897 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:25:49,252 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-a60ac899: selfplay (source: autonomous)
2026-01-13 09:25:49,252 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-a60ac899: selfplay_enabled=false for this node
2026-01-13 09:25:50,504 - p2p_orchestrator - INFO - Network partition detected: 33/42 peers unreachable (79%)
2026-01-13 09:25:50,505 - p2p_orchestrator - INFO - Enabling Tailscale-priority mode for partition recovery
[P2P] PARTITION: Enabling local election with 10 nodes: MacBook-Pro-5, hetzner-cpu1, aws-staging, lambda-gh200-8, 192-222-57-210, 192-222-51-29, 192-222-57-184, 192-222-58-171, 192-222-51-60, b148b1697229 (quorum=3)
2026-01-13 09:25:50,506 - p2p_orchestrator - INFO - Partition healed: restored original voters mac-studio, MacBook-Pro-5, lambda-gh200-training, hetzner-cpu1, hetzner-cpu2, hetzner-cpu3, vultr-a100-20gb, nebius-h100-3
2026-01-13 09:25:51,965 - p2p_orchestrator - INFO - Force-refreshing all IP sources for partition recovery...
2026-01-13 09:25:53,559 - p2p_orchestrator - INFO - LOCAL: Disk at 84% - triggering cleanup
2026-01-13 09:25:53,559 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:25:55,317 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:25:55,318 - p2p_orchestrator - WARNING - LOCAL: Memory CRITICAL at 90% - emergency cleanup
2026-01-13 09:25:56,362 - p2p_orchestrator - INFO - Restarting stuck local selfplay jobs...
2026-01-13 09:25:56,637 - p2p_orchestrator - INFO - Killed 3 processes, cleared 0 job records
2026-01-13 09:25:57,460 - p2p_orchestrator - INFO - Emergency memory cleanup: cleared 22 gossip states, 9 manifests, ran gc.collect()
2026-01-13 09:25:58,283 - p2p_orchestrator - INFO - LOCAL: Disk at 84% - skipping job starts
2026-01-13 09:25:58,283 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:25:59,082 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:25:59,083 - p2p_orchestrator - INFO - LOCAL: Memory at 89% - skipping GPU auto-scale
2026-01-13 09:26:01,042 - p2p_orchestrator - INFO - Reconnected to dead peer 46.62.217.168:7947 (was dead for 739s)
2026-01-13 09:26:01,929 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Cleared unhealthy status for 46.62.217.168:7947
2026-01-13 09:26:01,929 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 46.62.217.168:7947, invalidating cluster manifest
2026-01-13 09:26:01,930 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 46.62.217.168:7947, node available for jobs
2026-01-13 09:26:01,930 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:25:59 -0600] "GET /game_counts HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:01,931 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:25:59 -0600] "GET /game_counts HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:01,942 - app.coordination.sync_router - INFO - [SyncRouter] Added new node: 46.62.217.168
2026-01-13 09:26:01,959 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:26:01 -0600] "GET /health HTTP/1.1" 200 355 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:02,688 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:26:02,701 - aiohttp.access - INFO - 100.83.177.16 [13/Jan/2026:09:26:01 -0600] "GET /status HTTP/1.1" 200 0 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:02,703 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-d76dd790: selfplay (source: autonomous)
2026-01-13 09:26:02,703 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-d76dd790: selfplay_enabled=false for this node
2026-01-13 09:26:09,976 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:26:09 -0600] "POST /heartbeat HTTP/1.1" 200 1955 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:12,122 - aiohttp.access - INFO - fd7a:115c:a1e0::8c01:1567 [13/Jan/2026:09:26:11 -0600] "POST /gossip HTTP/1.1" 200 6031 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:12,709 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-b803fba7: selfplay (source: autonomous)
2026-01-13 09:26:12,709 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-b803fba7: selfplay_enabled=false for this node
2026-01-13 09:26:12,711 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:26:12 -0600] "GET /health HTTP/1.1" 200 355 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:13,517 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:26:13 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:13,517 - p2p_orchestrator - INFO - [P2P] Fetched 3 game counts from fallback MacBook-Pro-5
2026-01-13 09:26:17,918 - p2p_orchestrator - WARNING - [VoterHealth] Voter hetzner-cpu1 went OFFLINE (2/8 alive, quorum=3)
2026-01-13 09:26:18,001 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:26:18,036 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:26:16 -0600] "GET /status HTTP/1.1" 200 59008 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:18,750 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:26:18,752 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:26:16 -0600] "GET /status HTTP/1.1" 200 59008 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:19,068 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:26:19,070 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:26:16 -0600] "GET /status HTTP/1.1" 200 59010 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:19,370 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:26:19,371 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:26:16 -0600] "GET /status HTTP/1.1" 200 59008 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:19,687 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:26:19,689 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:26:16 -0600] "GET /status HTTP/1.1" 200 59009 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:20,121 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:26:20,123 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:26:16 -0600] "GET /status HTTP/1.1" 200 59009 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:20,430 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:26:20,431 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:26:16 -0600] "GET /status HTTP/1.1" 200 59008 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:20,729 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:26:20,730 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:26:16 -0600] "GET /status HTTP/1.1" 200 59011 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:21,095 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:26:21,111 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:26:16 -0600] "GET /status HTTP/1.1" 200 59010 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:21,464 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:26:21,469 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:26:16 -0600] "GET /status HTTP/1.1" 200 59010 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:23,137 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:26:23 -0600] "GET /peers HTTP/1.1" 404 174 "-" "curl/8.7.1"
2026-01-13 09:26:23,138 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-1c490ed5: selfplay (source: autonomous)
2026-01-13 09:26:23,138 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-1c490ed5: selfplay_enabled=false for this node
2026-01-13 09:26:23,139 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:26:23 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
Metrics Report: {'timestamp': 1768317987.1536572, 'node_id': '0.0.0.0:7947', 'metrics': {'node_event': {'events': {'start': 1}}, 'ping_timeout': {'gauge': 0.5}, 'probe_result': {'counter': 57}, 'ping': {'events': {'failure': 11}}, 'peer_rtt': {'histogram': {'count': 11, 'min': 0.0014598369598388672, 'max': 234.6769700050354, 'mean': 22.978784322738647, 'stdev': 70.33821384640088, 'p95': 234.6769700050354, 'p99': 234.6769700050354}}, 'timeout_adjustment': {'events': {'1.000->0.500': 1}}, 'member_count': {'gauge': 8}, 'protocol_cycle_duration': {'histogram': {'count': 147, 'min': 6.29425048828125e-05, 'max': 318.1459758281708, 'mean': 3.6155273508863384, 'stdev': 28.292916387335154, 'p95': 3.223060131072998, 'p99': 100.23378777503967}}, 'protocol_period': {'gauge': 2.0}, 'suspect_timeout': {'gauge': 15.0, 'events': {'100.126.21.102:7947': 1, '100.109.195.71:7947': 1, '100.94.174.19:7947': 1, '100.68.208.43:7947': 1, '100.94.201.92:7947': 1, '100.107.168.125:7947': 1, '100.67.131.72:7947': 1}}, 'probe_count': {'gauge': 8}, 'indirect_probe': {'events': {'failure': 21}}}}
2026-01-13 09:26:29,687 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:26:29,689 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:26:29 -0600] "GET /status HTTP/1.1" 200 57196 "-" "curl/8.7.1"
2026-01-13 09:26:30,838 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:26:30,840 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:26:30 -0600] "GET /status HTTP/1.1" 200 57186 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:31,096 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'hetzner-cpu3', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:26:31,097 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:26:30 -0600] "GET /status HTTP/1.1" 200 57185 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:33,141 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-41be8055: selfplay (source: autonomous)
2026-01-13 09:26:33,142 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-41be8055: selfplay_enabled=false for this node
2026-01-13 09:26:33,148 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:26:33 -0600] "GET /health HTTP/1.1" 200 355 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:33,260 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:26:33 -0600] "GET /health HTTP/1.1" 200 744 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:36,135 - aiohttp.access - INFO - 100.69.101.108 [13/Jan/2026:09:26:35 -0600] "POST /heartbeat HTTP/1.1" 200 1958 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:36,912 - aiohttp.access - INFO - fd7a:115c:a1e0::1d01:1390 [13/Jan/2026:09:26:36 -0600] "POST /gossip HTTP/1.1" 200 5948 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:36,949 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:26:36 -0600] "GET /work/queue HTTP/1.1" 404 174 "-" "curl/8.7.1"
2026-01-13 09:26:40,142 - aiohttp.access - INFO - 100.110.143.119 [13/Jan/2026:09:26:39 -0600] "POST /heartbeat HTTP/1.1" 200 1957 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:41,544 - p2p_orchestrator - INFO - [VoterHealth] Voter hetzner-cpu3 came ONLINE (3/8 alive, quorum=3)
2026-01-13 09:26:41,545 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:26:41,550 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:26:41 -0600] "GET /status HTTP/1.1" 200 62724 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:42,087 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:26:42,090 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:26:41 -0600] "GET /status HTTP/1.1" 200 62723 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:43,812 - p2p_orchestrator - INFO - LOCAL: Leader present but no work dispatched in 1249s (timeout=120s) - self-assigning
2026-01-13 09:26:45,096 - p2p_orchestrator - INFO - LOCAL: Disk at 84% - skipping job starts
2026-01-13 09:26:45,097 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:26:46,115 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:26:47,543 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:26:47 -0600] "GET / HTTP/1.1" 302 188 "-" "curl/8.7.1"
2026-01-13 09:26:47,544 - p2p_orchestrator - INFO - Detected symmetric NAT (multiple external IPs seen)
2026-01-13 09:26:47,544 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-d5162432: selfplay (source: autonomous)
2026-01-13 09:26:47,545 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-d5162432: selfplay_enabled=false for this node
2026-01-13 09:26:47,547 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:26:47 -0600] "GET /health HTTP/1.1" 200 355 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:47,634 - p2p_orchestrator - INFO - NAT-blocked peer lambda-gh200-training is now reachable at 100.68.208.43:8770
2026-01-13 09:26:49,945 - aiohttp.access - INFO - 100.68.208.43 [13/Jan/2026:09:26:49 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:51,648 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:26:51,651 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:26:51 -0600] "GET /status HTTP/1.1" 200 57310 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:26:52,209 - p2p_orchestrator - WARNING - [VoterHealth] Status: 3/8 voters alive, quorum=OK, offline: ['mac-studio', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:26:52,211 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:26:51 -0600] "GET /status HTTP/1.1" 200 57310 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:26:55,015 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:26:55 -0600] "POST /selfplay/dispatch HTTP/1.1" 404 174 "-" "curl/8.7.1"
2026-01-13 09:26:57,549 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-0de33d65: selfplay (source: autonomous)
2026-01-13 09:26:57,550 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-0de33d65: selfplay_enabled=false for this node
2026-01-13 09:26:57,552 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:26:57 -0600] "GET /health HTTP/1.1" 200 355 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:26:59,713 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:26:58 -0600] "POST /heartbeat HTTP/1.1" 200 1956 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:26:59,715 - p2p_orchestrator - INFO - [RelayHealthCheck] Relay hetzner-cpu1 unhealthy for hetzner-cpu2, switching to hetzner-cpu3
2026-01-13 09:27:00,807 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:26:59 -0600] "POST /heartbeat HTTP/1.1" 200 1955 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:27:00,810 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:27:00 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:02,010 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:27:00 -0600] "POST /heartbeat HTTP/1.1" 200 1956 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:27:04,137 - aiohttp.access - INFO - fd7a:115c:a1e0::8c01:1567 [13/Jan/2026:09:27:02 -0600] "POST /gossip HTTP/1.1" 200 6064 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:04,149 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:27:04 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:07,532 - aiohttp.access - INFO - fd7a:115c:a1e0::2e01:d06c [13/Jan/2026:09:27:06 -0600] "POST /gossip HTTP/1.1" 200 6113 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:07,556 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-e9312cb7: selfplay (source: autonomous)
2026-01-13 09:27:07,556 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-e9312cb7: selfplay_enabled=false for this node
2026-01-13 09:27:07,559 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:27:07 -0600] "GET /health HTTP/1.1" 200 355 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:11,606 - p2p_orchestrator - INFO - Voter mesh incomplete, missing: ['vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:27:13,725 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:27:13 -0600] "GET /health HTTP/1.1" 200 751 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:15,133 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:27:13 -0600] "GET /api/cluster/status HTTP/1.1" 200 24652 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:27:15,647 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:27:15 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:27:17,602 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-caf0432e: selfplay (source: autonomous)
2026-01-13 09:27:17,603 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-caf0432e: selfplay_enabled=false for this node
2026-01-13 09:27:17,606 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:27:17 -0600] "GET /health HTTP/1.1" 200 355 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:20,385 - aiohttp.access - INFO - fd7a:115c:a1e0::1d01:1390 [13/Jan/2026:09:27:19 -0600] "POST /gossip HTTP/1.1" 200 6100 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:21,091 - aiohttp.access - INFO - 100.107.168.125 [13/Jan/2026:09:27:21 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:27:21,270 - p2p_orchestrator - INFO - DB consolidation: 12 DBs with 75 games to merge
2026-01-13 09:27:21,295 - p2p_orchestrator - INFO - Started DB merge (PID: 63645)
2026-01-13 09:27:21,297 - p2p_orchestrator - INFO - LOCAL: Leader present but no work dispatched in 1287s (timeout=120s) - self-assigning
2026-01-13 09:27:22,437 - p2p_orchestrator - INFO - LOCAL: Disk at 84% - skipping job starts
2026-01-13 09:27:22,437 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:27:23,653 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:27:26,165 - aiohttp.access - INFO - 100.71.89.91 [13/Jan/2026:09:27:25 -0600] "POST /heartbeat HTTP/1.1" 200 1956 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:26,170 - p2p_orchestrator - INFO - Reconnected to dead peer 46.62.147.150:7947 (was dead for 700s)
2026-01-13 09:27:26,190 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Cleared unhealthy status for 46.62.147.150:7947
2026-01-13 09:27:26,190 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 46.62.147.150:7947, invalidating cluster manifest
2026-01-13 09:27:26,190 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 46.62.147.150:7947, node available for jobs
2026-01-13 09:27:26,195 - app.coordination.sync_router - INFO - [SyncRouter] Added new node: 46.62.147.150
2026-01-13 09:27:26,195 - aiohttp.access - INFO - 100.94.174.19 [13/Jan/2026:09:27:25 -0600] "GET /game_counts HTTP/1.1" 200 299 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:27:26,199 - aiohttp.access - INFO - ::1 [13/Jan/2026:09:27:26 -0600] "POST /dispatch_selfplay HTTP/1.1" 503 250 "-" "curl/8.7.1"
Metrics Report: {'timestamp': 1768318047.169224, 'node_id': '0.0.0.0:7947', 'metrics': {'node_event': {'events': {'start': 1}}, 'ping_timeout': {'gauge': 0.5}, 'probe_result': {'counter': 57}, 'ping': {'events': {'failure': 11}}, 'peer_rtt': {'histogram': {'count': 11, 'min': 0.0014598369598388672, 'max': 234.6769700050354, 'mean': 22.978784322738647, 'stdev': 70.33821384640088, 'p95': 234.6769700050354, 'p99': 234.6769700050354}}, 'timeout_adjustment': {'events': {'1.000->0.500': 1}}, 'member_count': {'gauge': 8}, 'protocol_cycle_duration': {'histogram': {'count': 171, 'min': 6.29425048828125e-05, 'max': 318.1459758281708, 'mean': 3.108113375323558, 'stdev': 26.25005072467907, 'p95': 1.3120718002319336, 'p99': 100.23378777503967}}, 'protocol_period': {'gauge': 2.0}, 'suspect_timeout': {'gauge': 15.0, 'events': {'100.126.21.102:7947': 1, '100.109.195.71:7947': 1, '100.94.174.19:7947': 1, '100.68.208.43:7947': 1, '100.94.201.92:7947': 1, '100.107.168.125:7947': 1, '100.67.131.72:7947': 1}}, 'probe_count': {'gauge': 8}, 'indirect_probe': {'events': {'failure': 21}}}}
2026-01-13 09:27:29,207 - p2p_orchestrator - WARNING - [VoterHealth] Voter lambda-gh200-training went OFFLINE (2/8 alive, quorum=3)
2026-01-13 09:27:29,208 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:27:29,240 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:27:26 -0600] "GET /status HTTP/1.1" 200 58847 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:29,987 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:27:29,991 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:27:26 -0600] "GET /status HTTP/1.1" 200 58846 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:30,759 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:27:30,763 - aiohttp.access - INFO - 100.69.164.58 [13/Jan/2026:09:27:26 -0600] "GET /status HTTP/1.1" 200 58842 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:31,616 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:27:31,618 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:27:26 -0600] "GET /status HTTP/1.1" 200 58759 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:32,331 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:27:32,332 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:27:26 -0600] "GET /status HTTP/1.1" 200 58740 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:33,181 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:27:33,184 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:27:26 -0600] "GET /status HTTP/1.1" 200 58738 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:33,826 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:27:33,829 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:27:26 -0600] "GET /status HTTP/1.1" 200 58741 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:34,366 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:27:34,370 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:27:26 -0600] "GET /status HTTP/1.1" 200 58741 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:35,100 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:27:35,102 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:27:26 -0600] "GET /status HTTP/1.1" 200 58741 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:35,637 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:27:35,639 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:27:26 -0600] "GET /status HTTP/1.1" 200 58742 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:36,968 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:27:36 -0600] "GET /health HTTP/1.1" 200 756 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:27:37,109 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:27:37 -0600] "GET /health HTTP/1.1" 200 355 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:38,030 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:27:38,071 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:27:36 -0600] "GET /status HTTP/1.1" 200 57230 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:39,152 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:27:39,154 - aiohttp.access - INFO - 100.100.19.96 [13/Jan/2026:09:27:36 -0600] "GET /status HTTP/1.1" 200 57230 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:43,675 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:27:43 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:45,616 - app.coordination.work_queue - INFO -  Added work training_hex8_2p_1768318065604: training (priority: 100)
2026-01-13 09:27:45,953 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-23862cde: selfplay (source: autonomous)
2026-01-13 09:27:45,953 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-23862cde: selfplay_enabled=false for this node
2026-01-13 09:27:46,388 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:27:46 -0600] "GET /peers HTTP/1.1" 404 174 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:27:49,179 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:27:49 -0600] "GET /health HTTP/1.1" 200 353 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:49,988 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:27:49,991 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:27:49 -0600] "GET /status HTTP/1.1" 200 55426 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:50,820 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:27:50,824 - aiohttp.access - INFO - 100.126.21.102 [13/Jan/2026:09:27:49 -0600] "GET /status HTTP/1.1" 200 55425 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:27:55,955 - scripts.p2p.loops.job_loops - INFO - [WorkerPull] Claimed work autonomous-4ead6e34: selfplay (source: autonomous)
2026-01-13 09:27:55,955 - p2p_orchestrator - INFO - Skipping selfplay work autonomous-4ead6e34: selfplay_enabled=false for this node
2026-01-13 09:27:58,918 - p2p_orchestrator - INFO - LOCAL: Leader present but no work dispatched in 1325s (timeout=120s) - self-assigning
2026-01-13 09:28:00,016 - p2p_orchestrator - INFO - LOCAL: Disk at 84% - skipping job starts
2026-01-13 09:28:00,017 - p2p_orchestrator - INFO - Running local disk cleanup...
2026-01-13 09:28:00,600 - p2p_orchestrator - INFO - Disk monitor cleanup failed: 
2026-01-13 09:28:00,601 - p2p_orchestrator - INFO - LOCAL: Memory at 95% - skipping GPU auto-scale
2026-01-13 09:28:01,442 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:28:01,443 - p2p_orchestrator - ERROR - [VoterHealth] QUORUM LOST: 2/8 voters alive, need 3
2026-01-13 09:28:01,491 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:28:01 -0600] "GET /health HTTP/1.1" 200 355 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:28:01,820 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:28:01,823 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:28:01 -0600] "GET /status HTTP/1.1" 200 55420 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:28:02,422 - p2p_orchestrator - WARNING - [VoterHealth] Status: 2/8 voters alive, quorum=LOST, offline: ['mac-studio', 'lambda-gh200-training', 'hetzner-cpu1', 'hetzner-cpu2', 'vultr-a100-20gb', 'nebius-h100-3']
2026-01-13 09:28:02,426 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:28:01 -0600] "GET /status HTTP/1.1" 200 55415 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:28:08,847 - aiohttp.access - INFO - fd7a:115c:a1e0::4f01:ae13 [13/Jan/2026:09:28:06 -0600] "POST /gossip HTTP/1.1" 200 6154 "-" "Python/3.10 aiohttp/3.12.14"
2026-01-13 09:28:09,095 - aiohttp.access - INFO - 100.115.97.24 [13/Jan/2026:09:28:09 -0600] "GET /health HTTP/1.1" 200 755 "-" "Python/3.11 aiohttp/3.12.14"
2026-01-13 09:28:10,067 - p2p_orchestrator - WARNING - Isolated: only 4 alive peers (need 5), attempting bootstrap...
2026-01-13 09:28:11,204 - p2p_orchestrator - INFO - Bootstrap from 100.126.21.102:8770: imported 43 peers
2026-01-13 09:28:11,205 - p2p_orchestrator - INFO - Bootstrap successful! Now have 9 alive peers
2026-01-13 09:28:12,702 - aiohttp.access - INFO - 127.0.0.1 [13/Jan/2026:09:28:12 -0600] "GET /health HTTP/1.1" 200 354 "-" "Python/3.10 aiohttp/3.13.2"
2026-01-13 09:28:13,276 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: 192-222-50-174, invalidating cluster manifest
2026-01-13 09:28:13,277 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: 192-222-50-174, node available for jobs
2026-01-13 09:28:13,278 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Cleared unhealthy status for lambda-gh200-training
2026-01-13 09:28:13,278 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-training, invalidating cluster manifest
2026-01-13 09:28:13,278 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-training, node available for jobs
2026-01-13 09:28:13,279 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: hetzner-cpu2, invalidating cluster manifest
2026-01-13 09:28:13,279 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: hetzner-cpu2, node available for jobs
2026-01-13 09:28:13,280 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-4, invalidating cluster manifest
2026-01-13 09:28:13,280 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-4, node available for jobs
2026-01-13 09:28:13,280 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-5, invalidating cluster manifest
2026-01-13 09:28:13,280 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-5, node available for jobs
2026-01-13 09:28:13,281 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Cleared unhealthy status for ringrift-gpu
2026-01-13 09:28:13,281 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: ringrift-gpu, invalidating cluster manifest
2026-01-13 09:28:13,281 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: ringrift-gpu, node available for jobs
2026-01-13 09:28:13,281 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-9, invalidating cluster manifest
2026-01-13 09:28:13,281 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-9, node available for jobs
2026-01-13 09:28:13,282 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: vultr-a100-20gb-2, invalidating cluster manifest
2026-01-13 09:28:13,282 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: vultr-a100-20gb-2, node available for jobs
2026-01-13 09:28:13,282 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-10, invalidating cluster manifest
2026-01-13 09:28:13,282 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-10, node available for jobs
2026-01-13 09:28:13,283 - scripts.p2p.managers.node_selector - INFO - [NodeSelector] Cleared unhealthy status for lambda-gh200-11
2026-01-13 09:28:13,283 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: lambda-gh200-11, invalidating cluster manifest
2026-01-13 09:28:13,283 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: lambda-gh200-11, node available for jobs
2026-01-13 09:28:13,284 - scripts.p2p.p2p_mixin_base - INFO - [sync_planner] HOST_ONLINE: vultr-a100-20gb, invalidating cluster manifest
2026-01-13 09:28:13,284 - scripts.p2p.p2p_mixin_base - INFO - [job_manager] HOST_ONLINE: vultr-a100-20gb, node available for jobs
