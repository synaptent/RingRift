"""Multi-Armed Bandit for Selfplay Engine Selection.

December 2025: Uses Thompson Sampling to learn which selfplay engine produces
the best training data for each config. Estimated +15-30 Elo improvement.

The bandit tracks:
- Elo improvement per engine per config
- Number of games generated by each engine
- Downstream model performance after training

Engine options:
- heuristic-only: Fast, no GPU required
- policy-only: Uses neural policy only (no search)
- gumbel-mcts: Full Gumbel MCTS search (highest quality, slowest)
- mcts: Standard MCTS search
- mixed: Mixed opponent pool (random, heuristic, MCTS)

Usage:
    from app.coordination.selfplay_engine_bandit import (
        get_selfplay_engine_bandit,
        SelfplayEngineBandit,
    )

    # Get singleton
    bandit = get_selfplay_engine_bandit()

    # Select best engine for a config
    engine = bandit.select_engine("hex8_2p")

    # Record feedback after training
    bandit.record_feedback("hex8_2p", "gumbel-mcts", elo_gain=15.0, games=500)
"""

from __future__ import annotations

import json
import logging
import random
import threading
import time
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any

import numpy as np

logger = logging.getLogger(__name__)


# Available engines for selfplay
# Jan 1, 2026: Re-enabled gumbel-mcts - now uses per-node config to decide GPU tree mode
# Nodes with disable_gpu_tree: true in distributed_hosts.yaml will use --no-gpu-tree
# Other nodes (GH200, H100, etc.) will use GPU tree for 170x speedup
# Jan 17, 2026: Added diverse harnesses for NN/NNUE training variety
AVAILABLE_ENGINES: list[str] = [
    # Basic engines
    "heuristic-only",   # Fast baseline, no GPU required
    "policy-only",      # Neural policy network only (no search)
    "mixed",            # Mixed opponent pool for variety
    # Search-based engines (high quality)
    "gumbel-mcts",      # Full Gumbel MCTS search (highest quality, GPU-accelerated)
    "nnue-guided",      # NNUE evaluation with search (fast + strong)
    "descent-only",     # Gradient descent on position (fast)
    "brs",              # Best Response Search (good for multiplayer)
    # Multiplayer-specific engines
    "maxn",             # MaxN search for multiplayer (3-4 player)
    "paranoid",         # Paranoid minimax (assumes all opponents cooperate against us)
]

# Legacy list including all engines (for reference)
ALL_ENGINES: list[str] = [
    "heuristic-only",
    "policy-only",
    "gumbel-mcts",      # Re-enabled Jan 1, 2026
    "nnue-guided",      # Added Jan 17, 2026
    "descent-only",     # Added Jan 17, 2026
    "brs",              # Added Jan 17, 2026
    "maxn",             # Added Jan 17, 2026
    "paranoid",         # Added Jan 17, 2026
    "mcts",             # Still disabled: use gumbel-mcts instead
    "mixed",
]

# Default engine when no data available
# Jan 1, 2026: Use gumbel-mcts for high quality training data
# Nodes without GPU tree support will still work (slower CPU tree)
DEFAULT_ENGINE = "gumbel-mcts"

# Minimum games before engine can be selected by exploitation
MIN_GAMES_FOR_EXPLOITATION = 100


@dataclass
class EngineStats:
    """Statistics for a single engine on a single config."""

    engine: str
    config_key: str

    # Beta distribution parameters for Thompson Sampling
    # We model "success" as positive Elo improvement
    alpha: float = 1.0  # Prior successes
    beta: float = 1.0  # Prior failures

    # Tracking data
    total_games: int = 0
    total_elo_gain: float = 0.0
    observation_count: int = 0

    # Historical observations
    elo_gains: list[float] = field(default_factory=list)
    timestamps: list[float] = field(default_factory=list)

    @property
    def mean_elo_per_game(self) -> float:
        """Average Elo gain per game generated."""
        if self.total_games == 0:
            return 0.0
        return self.total_elo_gain / self.total_games

    @property
    def success_rate(self) -> float:
        """Estimated success rate (positive Elo gain)."""
        return self.alpha / (self.alpha + self.beta)

    def sample_thompson(self) -> float:
        """Sample from posterior distribution for Thompson Sampling.

        Returns sampled success probability from Beta distribution.
        """
        return np.random.beta(self.alpha, self.beta)

    def update(self, elo_gain: float, games: int) -> None:
        """Update statistics after observing training outcome.

        Args:
            elo_gain: Elo improvement from training on this engine's data
            games: Number of games that contributed to this training
        """
        self.total_games += games
        self.total_elo_gain += elo_gain
        self.observation_count += 1

        # Update Beta distribution
        # Treat positive Elo gain as success, negative as failure
        # Scale by magnitude: large gains give more alpha, large losses give more beta
        if elo_gain > 0:
            # Success - more alpha
            self.alpha += min(elo_gain / 10.0, 5.0)  # Cap at +5 per observation
        else:
            # Failure - more beta
            self.beta += min(abs(elo_gain) / 10.0, 5.0)

        self.elo_gains.append(elo_gain)
        self.timestamps.append(time.time())

        # Keep only last 50 observations
        if len(self.elo_gains) > 50:
            self.elo_gains = self.elo_gains[-50:]
            self.timestamps = self.timestamps[-50:]

    def to_dict(self) -> dict[str, Any]:
        """Serialize to dictionary."""
        return {
            "engine": self.engine,
            "config_key": self.config_key,
            "alpha": self.alpha,
            "beta": self.beta,
            "total_games": self.total_games,
            "total_elo_gain": self.total_elo_gain,
            "observation_count": self.observation_count,
            "elo_gains": self.elo_gains,
            "timestamps": self.timestamps,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> EngineStats:
        """Deserialize from dictionary."""
        return cls(
            engine=data["engine"],
            config_key=data["config_key"],
            alpha=data.get("alpha", 1.0),
            beta=data.get("beta", 1.0),
            total_games=data.get("total_games", 0),
            total_elo_gain=data.get("total_elo_gain", 0.0),
            observation_count=data.get("observation_count", 0),
            elo_gains=data.get("elo_gains", []),
            timestamps=data.get("timestamps", []),
        )


class SelfplayEngineBandit:
    """Multi-armed bandit for selfplay engine selection.

    Uses Thompson Sampling to balance exploration (trying different engines)
    with exploitation (using the best-known engine).

    The bandit maintains per-config statistics, since different configs may
    benefit from different engines (e.g., small boards may do better with
    pure policy, large boards may need full MCTS).
    """

    def __init__(
        self,
        state_path: str | Path | None = None,
        exploration_bonus: float = 0.1,
        decay_rate: float = 0.001,
        forced_diversity_prob: float = 0.15,
    ):
        """Initialize the bandit.

        Args:
            state_path: Path to persist state (default: coordination_state/engine_bandit.json)
            exploration_bonus: Bonus to UCB for exploration (default: 0.1)
            decay_rate: Decay rate for old observations (default: 0.001 per hour)
            forced_diversity_prob: Probability of forcing a random underused engine (default: 0.15)
        """
        self._lock = threading.Lock()

        # State path
        if state_path is None:
            from app.utils.paths import DATA_DIR

            state_path = DATA_DIR / "coordination_state" / "engine_bandit.json"
        self._state_path = Path(state_path)

        # Configuration
        self._exploration_bonus = exploration_bonus
        self._decay_rate = decay_rate
        self._forced_diversity_prob = forced_diversity_prob

        # Per-config per-engine statistics
        self._stats: dict[str, dict[str, EngineStats]] = {}

        # Load persisted state
        self._load_state()

        logger.info(
            f"[EngineBandit] Initialized with {len(self._stats)} configs, "
            f"exploration_bonus={exploration_bonus}, "
            f"forced_diversity_prob={forced_diversity_prob}"
        )

    def _load_state(self) -> None:
        """Load persisted state from disk."""
        if not self._state_path.exists():
            return

        try:
            with open(self._state_path, encoding="utf-8") as f:
                data = json.load(f)

            for config_key, engines_data in data.get("stats", {}).items():
                self._stats[config_key] = {}
                for engine, stats_data in engines_data.items():
                    self._stats[config_key][engine] = EngineStats.from_dict(stats_data)

            logger.info(f"[EngineBandit] Loaded state for {len(self._stats)} configs")
        except (json.JSONDecodeError, OSError, KeyError) as e:
            logger.warning(f"[EngineBandit] Failed to load state: {e}")

    def _save_state(self) -> None:
        """Persist state to disk."""
        try:
            self._state_path.parent.mkdir(parents=True, exist_ok=True)

            data = {
                "stats": {
                    config_key: {
                        engine: stats.to_dict() for engine, stats in engines.items()
                    }
                    for config_key, engines in self._stats.items()
                },
                "updated_at": time.time(),
            }

            with open(self._state_path, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=2)

        except OSError as e:
            logger.warning(f"[EngineBandit] Failed to save state: {e}")

    def _get_or_create_stats(self, config_key: str, engine: str) -> EngineStats:
        """Get or create stats for a config/engine pair."""
        if config_key not in self._stats:
            self._stats[config_key] = {}

        if engine not in self._stats[config_key]:
            self._stats[config_key][engine] = EngineStats(
                engine=engine, config_key=config_key
            )

        return self._stats[config_key][engine]

    def select_engine(
        self,
        config_key: str,
        available_engines: list[str] | None = None,
        num_players: int = 2,
    ) -> str:
        """Select the best engine for a config using Thompson Sampling.

        Args:
            config_key: The config key (e.g., "hex8_2p")
            available_engines: Optional list of available engines (filters AVAILABLE_ENGINES)
            num_players: Number of players (affects which engines are suitable)

        Returns:
            Selected engine mode string
        """
        with self._lock:
            engines = available_engines or AVAILABLE_ENGINES

            # Filter engines by player count suitability
            # Jan 17, 2026: maxn/brs/paranoid are best for 3-4 player games
            if num_players >= 3:
                # Prefer multiplayer-optimized engines
                multiplayer_engines = {"maxn", "brs", "paranoid", "gumbel-mcts", "mixed"}
                suitable_engines = [e for e in engines if e in multiplayer_engines or e in {"heuristic-only", "policy-only", "descent-only"}]
                if suitable_engines:
                    engines = suitable_engines
            else:
                # For 2-player, avoid pure multiplayer engines
                two_player_engines = [e for e in engines if e not in {"maxn", "paranoid"}]
                if two_player_engines:
                    engines = two_player_engines

            # Jan 17, 2026: Forced diversity - randomly select underused engine
            # This ensures all engines get explored, even if Thompson Sampling
            # would otherwise always pick the same engine
            if random.random() < self._forced_diversity_prob:
                # Find engines with fewer than MIN_GAMES_FOR_EXPLOITATION games
                underused = [
                    e for e in engines
                    if self._get_or_create_stats(config_key, e).total_games < MIN_GAMES_FOR_EXPLOITATION
                ]
                if underused:
                    forced_engine = random.choice(underused)
                    logger.info(
                        f"[EngineBandit] {config_key}: Forced diversity -> {forced_engine} "
                        f"(underused engines: {len(underused)})"
                    )
                    return forced_engine

            # Get Thompson samples for each engine
            samples: dict[str, float] = {}
            for engine in engines:
                stats = self._get_or_create_stats(config_key, engine)

                # If not enough data, boost exploration
                if stats.total_games < MIN_GAMES_FOR_EXPLOITATION:
                    # Add exploration bonus based on how underexplored
                    exploration_factor = 1.0 + self._exploration_bonus * (
                        1.0 - stats.total_games / MIN_GAMES_FOR_EXPLOITATION
                    )
                    sample = stats.sample_thompson() * exploration_factor
                else:
                    sample = stats.sample_thompson()

                # Add small noise to break ties
                sample += random.random() * 0.001
                samples[engine] = sample

            # Select engine with highest sample
            best_engine = max(samples, key=lambda e: samples[e])

            logger.debug(
                f"[EngineBandit] {config_key}: Selected {best_engine} "
                f"(samples: {', '.join(f'{e}={s:.3f}' for e, s in samples.items())})"
            )

            return best_engine

    def record_feedback(
        self,
        config_key: str,
        engine: str,
        elo_gain: float,
        games: int,
    ) -> None:
        """Record feedback after training with data from this engine.

        Args:
            config_key: The config key (e.g., "hex8_2p")
            engine: The engine that generated the training data
            elo_gain: Elo improvement from this training session
            games: Number of games that contributed
        """
        with self._lock:
            stats = self._get_or_create_stats(config_key, engine)
            stats.update(elo_gain, games)

            logger.info(
                f"[EngineBandit] {config_key}/{engine}: "
                f"elo_gain={elo_gain:+.1f}, games={games}, "
                f"total_games={stats.total_games}, "
                f"success_rate={stats.success_rate:.2f}"
            )

            self._save_state()

    def get_stats(self, config_key: str) -> dict[str, dict[str, Any]]:
        """Get all engine stats for a config.

        Returns:
            Dict mapping engine -> stats dict
        """
        with self._lock:
            if config_key not in self._stats:
                return {}

            return {
                engine: stats.to_dict()
                for engine, stats in self._stats[config_key].items()
            }

    def get_best_engine(self, config_key: str) -> str | None:
        """Get the empirically best engine for a config (by mean Elo/game).

        Returns:
            Best engine name or None if no data
        """
        with self._lock:
            if config_key not in self._stats:
                return None

            best_engine = None
            best_mean = float("-inf")

            for engine, stats in self._stats[config_key].items():
                if stats.total_games >= MIN_GAMES_FOR_EXPLOITATION:
                    if stats.mean_elo_per_game > best_mean:
                        best_mean = stats.mean_elo_per_game
                        best_engine = engine

            return best_engine

    def get_summary(self) -> dict[str, Any]:
        """Get summary of all bandit statistics.

        Returns:
            Summary dict with per-config stats
        """
        with self._lock:
            summary = {
                "configs": {},
                "total_observations": 0,
                "total_games": 0,
            }

            for config_key, engines in self._stats.items():
                config_summary = {}
                for engine, stats in engines.items():
                    config_summary[engine] = {
                        "games": stats.total_games,
                        "observations": stats.observation_count,
                        "mean_elo": stats.mean_elo_per_game,
                        "success_rate": stats.success_rate,
                    }
                    summary["total_observations"] += stats.observation_count
                    summary["total_games"] += stats.total_games

                summary["configs"][config_key] = config_summary

            return summary


# Singleton instance
_bandit_instance: SelfplayEngineBandit | None = None
_bandit_lock = threading.Lock()


def get_selfplay_engine_bandit() -> SelfplayEngineBandit:
    """Get the singleton SelfplayEngineBandit instance."""
    global _bandit_instance
    with _bandit_lock:
        if _bandit_instance is None:
            _bandit_instance = SelfplayEngineBandit()
        return _bandit_instance


def reset_selfplay_engine_bandit() -> None:
    """Reset the singleton instance (for testing)."""
    global _bandit_instance
    with _bandit_lock:
        _bandit_instance = None


__all__ = [
    "AVAILABLE_ENGINES",
    "DEFAULT_ENGINE",
    "EngineStats",
    "SelfplayEngineBandit",
    "get_selfplay_engine_bandit",
    "reset_selfplay_engine_bandit",
]
